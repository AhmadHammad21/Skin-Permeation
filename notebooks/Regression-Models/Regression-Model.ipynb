{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents:\n",
    "- [1. Import Libraries & Data](#import-libraries)\n",
    "- [2. Data Preprocessing](#data-preprocessing)\n",
    "- [3. Models Experiments](#models)\n",
    "    - [3.1 All Features](#All-Features)\n",
    "    - [3.2 Feature-Selection](#Feature-Selection)\n",
    "    - [3.3 Feature Selection using PCA](#Feature-Selection-PCA)\n",
    "- [4. ANN](#ann)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"import-libraries\"></a>\n",
    "# 1. Import Libraries & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import random\n",
    "SEED = 1\n",
    "np.random.seed(SEED)\n",
    "\n",
    "#warnings.filterwarnings('ignore')\n",
    "\n",
    "# preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# models \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn. linear_model import Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# evaluation\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../../data/final/clean_trial4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logkpl</th>\n",
       "      <th>Compound</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>Texpi</th>\n",
       "      <th>ALogp2</th>\n",
       "      <th>nAcid</th>\n",
       "      <th>nAromBond</th>\n",
       "      <th>ATSc2</th>\n",
       "      <th>ATSc3</th>\n",
       "      <th>ATSc4</th>\n",
       "      <th>...</th>\n",
       "      <th>nRings9</th>\n",
       "      <th>TopoPSA</th>\n",
       "      <th>VAdjMat</th>\n",
       "      <th>WTPT-2</th>\n",
       "      <th>WTPT-3</th>\n",
       "      <th>WTPT-4</th>\n",
       "      <th>WTPT-5</th>\n",
       "      <th>WPATH</th>\n",
       "      <th>XLogP</th>\n",
       "      <th>Zagreb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.55</td>\n",
       "      <td>Urea</td>\n",
       "      <td>C(=O)(N)N</td>\n",
       "      <td>312</td>\n",
       "      <td>1.085972</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.116019</td>\n",
       "      <td>0.023614</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>69.11</td>\n",
       "      <td>2.584963</td>\n",
       "      <td>1.683013</td>\n",
       "      <td>6.732051</td>\n",
       "      <td>2.244017</td>\n",
       "      <td>4.488034</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-1.686</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.69</td>\n",
       "      <td>Urea</td>\n",
       "      <td>C(=O)(N)N</td>\n",
       "      <td>312</td>\n",
       "      <td>1.085972</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.116019</td>\n",
       "      <td>0.023614</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>69.11</td>\n",
       "      <td>2.584963</td>\n",
       "      <td>1.683013</td>\n",
       "      <td>6.732051</td>\n",
       "      <td>2.244017</td>\n",
       "      <td>4.488034</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-1.686</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 149 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   logkpl Compound     SMILES  Texpi    ALogp2  nAcid  nAromBond     ATSc2  \\\n",
       "0   -3.55     Urea  C(=O)(N)N    312  1.085972      0          0 -0.116019   \n",
       "1   -3.69     Urea  C(=O)(N)N    312  1.085972      0          0 -0.116019   \n",
       "\n",
       "      ATSc3  ATSc4  ...  nRings9  TopoPSA   VAdjMat    WTPT-2    WTPT-3  \\\n",
       "0  0.023614    0.0  ...        0    69.11  2.584963  1.683013  6.732051   \n",
       "1  0.023614    0.0  ...        0    69.11  2.584963  1.683013  6.732051   \n",
       "\n",
       "     WTPT-4    WTPT-5  WPATH  XLogP  Zagreb  \n",
       "0  2.244017  4.488034    9.0 -1.686    12.0  \n",
       "1  2.244017  4.488034    9.0 -1.686    12.0  \n",
       "\n",
       "[2 rows x 149 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMILES</th>\n",
       "      <th>Compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C(=O)(N)N</td>\n",
       "      <td>Urea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C(=O)(N)N</td>\n",
       "      <td>Urea</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      SMILES Compound\n",
       "0  C(=O)(N)N     Urea\n",
       "1  C(=O)(N)N     Urea"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smiles_df = data[['SMILES', 'Compound']]\n",
    "smiles_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(417, 149)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logkpl</th>\n",
       "      <th>Compound</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>Texpi</th>\n",
       "      <th>ALogp2</th>\n",
       "      <th>nAcid</th>\n",
       "      <th>nAromBond</th>\n",
       "      <th>ATSc2</th>\n",
       "      <th>ATSc3</th>\n",
       "      <th>ATSc4</th>\n",
       "      <th>...</th>\n",
       "      <th>nRings9</th>\n",
       "      <th>TopoPSA</th>\n",
       "      <th>VAdjMat</th>\n",
       "      <th>WTPT-2</th>\n",
       "      <th>WTPT-3</th>\n",
       "      <th>WTPT-4</th>\n",
       "      <th>WTPT-5</th>\n",
       "      <th>WPATH</th>\n",
       "      <th>XLogP</th>\n",
       "      <th>Zagreb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 149 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [logkpl, Compound, SMILES, Texpi, ALogp2, nAcid, nAromBond, ATSc2, ATSc3, ATSc4, ATSc5, ATSm1, BCUTw-1l, BCUTw-1h, BCUTc-1l, BCUTc-1h, BCUTp-1l, BCUTp-1h, nBase, C2SP1, C1SP2, C2SP2, C3SP2, C1SP3, C2SP3, SC-4, FMF, nHBAcc, nHBDon, HybRatio, JPLogP, Kier2, Kier3, khs.sLi, khs.ssBe, khs.ssBH, khs.sssB, khs.sCH3, khs.dCH2, khs.ssCH2, khs.tCH, khs.dsCH, khs.aaCH, khs.sssCH, khs.ddC, khs.dssC, khs.aasC, khs.aaaC, khs.sNH3, khs.sNH2, khs.ssNH2, khs.dNH, khs.ssNH, khs.aaNH, khs.tN, khs.dsN, khs.aaN, khs.sssN, khs.ddsN, khs.aasN, khs.ssssN, khs.sOH, khs.dO, khs.ssO, khs.aaO, khs.sF, khs.sSiH3, khs.ssSiH2, khs.sssSiH, khs.ssssSi, khs.sPH2, khs.ssPH, khs.sssP, khs.dsssP, khs.sssssP, khs.sSH, khs.dS, khs.ssS, khs.aaS, khs.dssS, khs.ddssS, khs.sCl, khs.sGeH3, khs.ssGeH2, khs.sssGeH, khs.ssssGe, khs.sAsH2, khs.ssAsH, khs.sssAs, khs.sssdAs, khs.sssssAs, khs.sSeH, khs.dSe, khs.ssSe, khs.aaSe, khs.dssSe, khs.ddssSe, khs.sBr, khs.sSnH3, khs.ssSnH2, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 149 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no missing values\n",
    "data.isna().sum().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data-preprocessing\"></a>\n",
    "# 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = data.drop([\"SMILES\", 'Compound'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (354, 146) \t Shape of y_train: (354,)\n",
      "Shape of X_test: (63, 146) \t Shape of y_test: (63,)\n"
     ]
    }
   ],
   "source": [
    "X = model_data.drop([\"logkpl\"], axis=1)\n",
    "y = model_data['logkpl']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.15, random_state=SEED)\n",
    "\n",
    "print(\"Shape of X_train: {} \\t Shape of y_train: {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Shape of X_test: {} \\t Shape of y_test: {}\".format(X_test.shape, y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../../models/scaler.pkl', 'wb') as file:\n",
    "    pickle.dump(scaler, file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"models\"></a>\n",
    "# 3. Models Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(model, cols, model_name, slice=20):\n",
    "    importances = model.feature_importances_\n",
    "    feature_names = cols#X.columns#selected_features_X.columns #\n",
    "\n",
    "    # Create a pandas DataFrame with the feature importances\n",
    "    df = pd.DataFrame({\"feature\": feature_names, \"importance\": importances})\n",
    "\n",
    "    # Sort the DataFrame by importance score\n",
    "    df = df.sort_values(\"importance\", ascending=False).reset_index(drop=True)\n",
    "    # df[:slice].to_excel(\"../../results/Feature Importance/{}_feature_importance.xlsx\".format(model_name), index=False)\n",
    "\n",
    "    # Create a bar plot using Seaborn\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.barplot(x=\"importance\", y=\"feature\", data=df[:slice])\n",
    "    plt.title(\"Top 20 Feature Importances {}\".format(model_name))\n",
    "    plt.ylabel(\"Feature Name\")\n",
    "    plt.xlabel(\"Importance\")\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"All-Features\"></a>\n",
    "### 3.1 All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ANN_model(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    model = tf.keras.Sequential([\n",
    "\n",
    "    tf.keras.layers.Dense(256, input_shape=[X_train.shape[1]]),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(128),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(64),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(32),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(8),\n",
    "    tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.0001), loss=\"mean_absolute_error\")\n",
    "\n",
    "    history = model.fit(X_train, y_train, epochs=2500, validation_data=(X_test, y_test), verbose=2)\n",
    "\n",
    "    plt.title('Learning Curves')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.plot(history.history['loss'], label='train')\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    # MAE, MSE, RMSE\n",
    "    print(\"MAE: {}\".format(mean_absolute_error(y_test, predictions)))\n",
    "    print(\"MSE: {}\".format(mean_squared_error(y_test, predictions)))\n",
    "    print(\"RMSE: {}\".format(mean_squared_error(y_test, predictions, squared=False)))\n",
    "    print(\"MAPE: {}\".format(mean_absolute_percentage_error(y_test, predictions)))\n",
    "    print(\"R2: {}\".format(r2_score(y_test, predictions)))\n",
    "\n",
    "    final_result = pd.DataFrame({\"predicted\": model.predict(X_test).reshape(X_test.shape[0],), \n",
    "              \"actual\": y_test})\n",
    "    \n",
    "    # saving the model\n",
    "\n",
    "# serialize model to JSON\n",
    "    model_json = model.to_json()\n",
    "    # with open(\"../../models/ANN_model.json\", \"w\") as json_file:\n",
    "    #     json_file.write(model_json)\n",
    "    # # serialize weights to HDF5\n",
    "    # model.save_weights(\"../../models/ANN_model.h5\")\n",
    "    print(\"Saved model to disk\")\n",
    "\n",
    "    # load json and create model\n",
    "# json_file = open('model.json', 'r')\n",
    "# loaded_model_json = json_file.read()\n",
    "# json_file.close()\n",
    "# loaded_model = model_from_json(loaded_model_json)\n",
    "# # load weights into new model\n",
    "# loaded_model.load_weights(\"model.h5\")\n",
    "# loaded_model.predict(X_test[0].reshape((1, 512, 512, 1))).argmax(axis=1)\n",
    "# print(\"Loaded model from disk\")\n",
    "    \n",
    "    return final_result.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model_df, i, model_name, model, X_train, y_train, X_test, y_test):\n",
    "    \"\"\"\n",
    "    this function is for regression takes the model with the data and calculate\n",
    "    the scores, with cross validation techniques, in addition to MAE, MSE, RMSE, MAPE\n",
    "    R Squared and Adjusted R Squared\n",
    "\n",
    "    :param model: model\n",
    "    :param X_train, X_test, y_train, y_test: data that was used\n",
    "    \"\"\"\n",
    "\n",
    "    # cross validation with 5 folds\n",
    "    all_cv_5 = cross_val_score(model, X_train, y_train, cv=5, scoring=\"neg_mean_absolute_error\")\n",
    "    #print(\"all CV 5: {}\".format(all_cv_5))\n",
    "    # print(\"Mean Cross-Validation score: {}\".format(all_cv_5.mean()))\n",
    "\n",
    "    # predictions from our model\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "\n",
    "    # calculating R squared and Adjusted R squared\n",
    "    r_sqre = r2_score(y_test, predictions)\n",
    "    n = len(y_test)\n",
    "    p = X_test.shape[1] # number of independant features\n",
    "\n",
    "    Adj_r2 = 1 - ((1 - r_sqre) * (n - 1) / (n - 1 - p))\n",
    "    \n",
    "    test_mae = mean_absolute_error(y_test, predictions)\n",
    "\n",
    "    test_mse = mean_squared_error(y_test, predictions)\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "    \n",
    "    # Plotting\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.scatter(y_test, predictions, color='blue', label='Predicted vs Actual')\n",
    "    plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--', label='Perfect Prediction')\n",
    "    plt.xlabel('Actual')\n",
    "    plt.ylabel('Predicted')\n",
    "    plt.title('Predicted vs Actual {}'.format(model_name))\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    #print(\"=\" * 40)\n",
    "    model_df.loc[i] = [model_name, all_cv_5.mean(),\n",
    "                    test_mae, mean_absolute_percentage_error(y_test, predictions),\n",
    "                   test_mse, test_rmse, r_sqre, Adj_r2]\n",
    "\n",
    "    return model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evalute(X_train, X_test, y_train, y_test, metric):\n",
    "    np.random.seed(SEED)\n",
    "    # scaler = StandardScaler()\n",
    "    # X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.25, random_state=42)\n",
    "\n",
    "    # print(\"Shape of X_train: {} \\t Shape of y_train: {}\".format(X_train.shape, y_train.shape))\n",
    "    # print(\"Shape of X_test: {} \\t Shape of y_test: {}\".format(X_test.shape, y_test.shape))\n",
    "\n",
    "    # Building pipelins of standard scaler and model for varios regressors.\n",
    "\n",
    "    lr = LinearRegression()\n",
    "\n",
    "    lasso = Lasso()\n",
    "\n",
    "    dt = DecisionTreeRegressor()\n",
    "\n",
    "    rf = RandomForestRegressor()\n",
    "\n",
    "    xgb = XGBRegressor()\n",
    "\n",
    "    gbr = GradientBoostingRegressor()\n",
    "\n",
    "    eln = ElasticNet()\n",
    "\n",
    "    br = BayesianRidge()\n",
    "\n",
    "    cat = CatBoostRegressor(allow_writing_files=False, verbose=0, task_type=\"GPU\")\n",
    "\n",
    "    lgbm = LGBMRegressor()\n",
    "\n",
    "\n",
    "\n",
    "    # List of all the pipelines\n",
    "    pipelines = [lr, lasso, dt, rf, xgb, gbr,\n",
    "                eln, br, cat, lgbm] # \n",
    "\n",
    "    # Dictionary of pipelines and model types for ease of reference\n",
    "    ml_dict = {0: \"LinearRegression\", 1: \"Lasso\", 2: \"DecisionTree\", 3: \"RandomForest\", 4: \"XGBRegressor\", 5: \"GradientBoostingRegressor\",\n",
    "                    6: \"Elastic Net\", 7:\"BayesianRidge\", 8: \"CatBoostRegressor\", 9: \"LGBMRegressor\"}\n",
    "        #, \n",
    "\n",
    "    models_scores_df = pd.DataFrame(columns=[\"model\", \"Mean CV\", \"MAE\",\n",
    "                                            \"MAPE\", \"MSE\", \"RMSE\", \"R_Squared\", \"Adjusted_R_Squared\"])\n",
    "\n",
    "\n",
    "\n",
    "    # Fit the pipelines and display the scores with Cross validation\n",
    "    for i, pipe in enumerate(pipelines):\n",
    "        # getting the name of our model\n",
    "        model_name = ml_dict[i]\n",
    "        print(model_name)\n",
    "        \n",
    "        # fitting our data\n",
    "        pipe.fit(X_train, y_train)\n",
    "        \n",
    "        evaluate_model(models_scores_df, i, model_name, pipe, X_train, y_train, X_test, y_test)\n",
    "\n",
    "\n",
    "    # selecting top 3 score based on metric\n",
    "    filtered_models_scores_df =  models_scores_df.sort_values(metric).iloc[:3, :]\n",
    "\n",
    "    results_df = pd.DataFrame({\"actual\": y_test})\n",
    "    selected_compounds = smiles_df.iloc[results_df.index]\n",
    "    results_df['Compound'] = selected_compounds['Compound']\n",
    "    results_df['SMILES'] = selected_compounds['SMILES']\n",
    "\n",
    "    results_df = results_df.reset_index(drop=True)\n",
    "    li = []\n",
    "\n",
    "    for i in filtered_models_scores_df.index:\n",
    "        predictions = pipelines[i].predict(X_test)\n",
    "        \n",
    "        predictions_df = pd.DataFrame({\"predictions_{}\".format(ml_dict[i]): predictions})\n",
    "        li.append(predictions_df)\n",
    "        plot_feature_importance(pipelines[i],  X.columns, ml_dict[i])\n",
    "\n",
    "        # save the model to disk\n",
    "        # filename = '../../models/{}_model.sav'.format(ml_dict[i])\n",
    "        # pickle.dump(pipelines[i], open(filename, 'wb'))\n",
    "\n",
    "    li_df = pd.concat(li, axis=1)\n",
    "\n",
    "    return models_scores_df, pd.concat([results_df, li_df], axis=1)\n",
    "# load the model from disk\n",
    "# loaded_model = pickle.load(open(filename, 'rb'))\n",
    "# result = loaded_model.score(X_test, Y_test)\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features, results_scores = train_and_evalute(X_train, X_test, y_train, y_test, metric=\"MAE\")\n",
    "all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ann\"></a>\n",
    "# 4. ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_result = ANN_model(X_train, X_test, y_train, y_test)\n",
    "final_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14272\\2042521271.py:26: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasRegressor(build_fn=create_model, epochs=2500, batch_size=32, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters:  {'dropout_rate': 0.2, 'learning_rate': 0.001}\n",
      "Best MAE:  0.5309096061913982\n",
      "Test MAE:  0.36325776433187823\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# Function to create the Keras model\n",
    "def create_model(learning_rate=0.0001, dropout_rate=0.2):\n",
    "    model = Sequential([\n",
    "        Dense(256, input_shape=[X_train.shape[1]]),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(128),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(64),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(32),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(8),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss=\"mean_absolute_error\")\n",
    "    return model\n",
    "\n",
    "# Create KerasRegressor\n",
    "model = KerasRegressor(build_fn=create_model, epochs=2500, batch_size=32, verbose=0)\n",
    "\n",
    "# Define the grid search parameters\n",
    "param_grid = {\n",
    "    'learning_rate': [0.0001, 0.001, 0.01],\n",
    "    'dropout_rate': [0.2, 0.3, 0.4]\n",
    "}\n",
    "\n",
    "# Use KFold cross-validation\n",
    "kf = KFold(n_splits=3, shuffle=True, random_state=1)\n",
    "\n",
    "# Create and fit the GridSearchCV\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='neg_mean_absolute_error', cv=kf)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# Print the results\n",
    "print(\"Best Parameters: \", grid_result.best_params_)\n",
    "print(\"Best MAE: \", -grid_result.best_score_)\n",
    "print(\"Test MAE: \", -grid_result.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "328543c14e67749527378fd9d598798d406739103cb7dff262233cddae2d7f33"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
