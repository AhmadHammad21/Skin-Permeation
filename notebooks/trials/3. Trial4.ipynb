{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents:\n",
    "- [1. Import Libraries & Data](#import-libraries)\n",
    "- [2. Data Preprocessing](#data-preprocessing)\n",
    "- [3. Models Experiments](#models)\n",
    "    - [3.1 All Features](#All-Features)\n",
    "    - [3.2 Feature-Selection](#Feature-Selection)\n",
    "    - [3.3 Feature Selection using PCA](#Feature-Selection-PCA)\n",
    "- [4. ANN](#ann)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"import-libraries\"></a>\n",
    "# 1. Import Libraries & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "#warnings.filterwarnings('ignore')\n",
    "\n",
    "# preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# models \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn. linear_model import Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# evaluation\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../../data/processed/trial4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>logkpl</th>\n",
       "      <th>Texpi</th>\n",
       "      <th>ALogP</th>\n",
       "      <th>ALogp2</th>\n",
       "      <th>AMR</th>\n",
       "      <th>apol</th>\n",
       "      <th>nAcid</th>\n",
       "      <th>naAromAtom</th>\n",
       "      <th>nAromBond</th>\n",
       "      <th>nAtom</th>\n",
       "      <th>...</th>\n",
       "      <th>MW</th>\n",
       "      <th>WTPT-1</th>\n",
       "      <th>WTPT-2</th>\n",
       "      <th>WTPT-3</th>\n",
       "      <th>WTPT-4</th>\n",
       "      <th>WTPT-5</th>\n",
       "      <th>WPATH</th>\n",
       "      <th>WPOL</th>\n",
       "      <th>XLogP</th>\n",
       "      <th>Zagreb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.25</td>\n",
       "      <td>298</td>\n",
       "      <td>1.4570</td>\n",
       "      <td>2.122849</td>\n",
       "      <td>35.0768</td>\n",
       "      <td>17.399965</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>139.109037</td>\n",
       "      <td>19.385708</td>\n",
       "      <td>1.938571</td>\n",
       "      <td>10.344796</td>\n",
       "      <td>7.326862</td>\n",
       "      <td>3.017933</td>\n",
       "      <td>120.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.508</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.95</td>\n",
       "      <td>310</td>\n",
       "      <td>3.6304</td>\n",
       "      <td>13.179804</td>\n",
       "      <td>49.4776</td>\n",
       "      <td>32.539860</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>172.264984</td>\n",
       "      <td>22.661828</td>\n",
       "      <td>1.888486</td>\n",
       "      <td>4.763098</td>\n",
       "      <td>4.763098</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>277.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.156</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 224 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   logkpl  Texpi   ALogP     ALogp2      AMR       apol  nAcid  naAromAtom  \\\n",
       "0   -2.25    298  1.4570   2.122849  35.0768  17.399965      0           6   \n",
       "1   -2.95    310  3.6304  13.179804  49.4776  32.539860      1           0   \n",
       "\n",
       "   nAromBond  nAtom  ...          MW     WTPT-1    WTPT-2     WTPT-3  \\\n",
       "0          6     15  ...  139.109037  19.385708  1.938571  10.344796   \n",
       "1          0     32  ...  172.264984  22.661828  1.888486   4.763098   \n",
       "\n",
       "     WTPT-4    WTPT-5  WPATH  WPOL  XLogP  Zagreb  \n",
       "0  7.326862  3.017933  120.0  11.0  1.508    46.0  \n",
       "1  4.763098  0.000000  277.0   9.0  4.156    44.0  \n",
       "\n",
       "[2 rows x 224 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(450, 224)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no missing values\n",
    "data.isna().sum().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data-preprocessing\"></a>\n",
    "# 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (337, 223) \t Shape of y_train: (337,)\n",
      "Shape of X_test: (113, 223) \t Shape of y_test: (113,)\n"
     ]
    }
   ],
   "source": [
    "X = model_data.drop([\"logkpl\"], axis=1)\n",
    "y = model_data['logkpl']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.25)\n",
    "\n",
    "print(\"Shape of X_train: {} \\t Shape of y_train: {}\".format(X_train.shape, y_train.shape))\n",
    "print(\"Shape of X_test: {} \\t Shape of y_test: {}\".format(X_test.shape, y_test.shape))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"models\"></a>\n",
    "# 3. Models Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_importance(model, cols, model_name, slice=20):\n",
    "    importances = model.feature_importances_\n",
    "    feature_names = cols#X.columns#selected_features_X.columns #\n",
    "\n",
    "    # Create a pandas DataFrame with the feature importances\n",
    "    df = pd.DataFrame({\"feature\": feature_names, \"importance\": importances})\n",
    "\n",
    "    # Sort the DataFrame by importance score\n",
    "    df = df.sort_values(\"importance\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "    # Create a bar plot using Seaborn\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    sns.barplot(x=\"importance\", y=\"feature\", data=df[:slice])\n",
    "    plt.title(\"Top 20 Feature Importances {}\".format(model_name))\n",
    "    plt.ylabel(\"Feature Name\")\n",
    "    plt.xlabel(\"Importance\")\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"All-Features\"></a>\n",
    "### 3.1 All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model_df, i, model_name, model, X, y, X_test, y_test):\n",
    "    \"\"\"\n",
    "    this function is for regression takes the model with the data and calculate\n",
    "    the scores, with cross validation techniques, in addition to MAE, MSE, RMSE, MAPE\n",
    "    R Squared and Adjusted R Squared\n",
    "\n",
    "    :param model: model\n",
    "    :param X_train, X_test, y_train, y_test: data that was used\n",
    "    \"\"\"\n",
    "\n",
    "    # cross validation with 5 folds\n",
    "    all_cv_5 = cross_val_score(model, X, y, cv=5, scoring=\"neg_mean_absolute_percentage_error\")\n",
    "    #print(\"all CV 5: {}\".format(all_cv_5))\n",
    "    # print(\"Mean Cross-Validation score: {}\".format(all_cv_5.mean()))\n",
    "\n",
    "    # predictions from our model\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "\n",
    "    # calculating R squared and Adjusted R squared\n",
    "    r_sqre = r2_score(y_test, predictions)\n",
    "    n = len(y_test)\n",
    "    p = X_test.shape[1] # number of independant features\n",
    "\n",
    "    Adj_r2 = 1 - ((1 - r_sqre) * (n - 1) / (n - 1 - p))\n",
    "    \n",
    "    test_mae = mean_absolute_error(y_test, predictions)\n",
    "\n",
    "    test_mse = mean_squared_error(y_test, predictions)\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    #print(\"=\" * 40)\n",
    "    model_df.loc[i] = [model_name, all_cv_5.mean(),\n",
    "                    test_mae, mean_absolute_percentage_error(y_test, predictions),\n",
    "                   test_mse, test_rmse, r_sqre, Adj_r2]\n",
    "\n",
    "    return model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evalute(X, y, metric):\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.25, random_state=42)\n",
    "\n",
    "    print(\"Shape of X_train: {} \\t Shape of y_train: {}\".format(X_train.shape, y_train.shape))\n",
    "    print(\"Shape of X_test: {} \\t Shape of y_test: {}\".format(X_test.shape, y_test.shape))\n",
    "\n",
    "    # Building pipelins of standard scaler and model for varios regressors.\n",
    "\n",
    "    lr = LinearRegression()\n",
    "\n",
    "    lasso = Lasso()\n",
    "\n",
    "    dt = DecisionTreeRegressor()\n",
    "\n",
    "    rf = RandomForestRegressor()\n",
    "\n",
    "    xgb = XGBRegressor()\n",
    "\n",
    "    gbr = GradientBoostingRegressor()\n",
    "\n",
    "    eln = ElasticNet()\n",
    "\n",
    "    br = BayesianRidge()\n",
    "\n",
    "    cat = CatBoostRegressor(allow_writing_files=False, verbose=0, task_type=\"GPU\")\n",
    "\n",
    "    lgbm = LGBMRegressor()\n",
    "\n",
    "\n",
    "\n",
    "    # List of all the pipelines\n",
    "    pipelines = [lr, lasso, dt, rf, xgb, gbr,\n",
    "                eln, br, cat, lgbm] # \n",
    "\n",
    "    # Dictionary of pipelines and model types for ease of reference\n",
    "    ml_dict = {0: \"LinearRegression\", 1: \"Lasso\", 2: \"DecisionTree\", 3: \"RandomForest\", 4: \"XGBRegressor\", 5: \"GradientBoostingRegressor\",\n",
    "                    6: \"Elastic Net\", 7:\"BayesianRidge\", 8: \"CatBoostRegressor\", 9: \"LGBMRegressor\"}\n",
    "        #, \n",
    "\n",
    "    models_scores_df = pd.DataFrame(columns=[\"model\", \"Mean CV\", \"MAE\",\n",
    "                                            \"MAPE\", \"MSE\", \"RMSE\", \"R_Squared\", \"Adjusted_R_Squared\"])\n",
    "\n",
    "\n",
    "\n",
    "    # Fit the pipelines and display the scores with Cross validation\n",
    "    for i, pipe in enumerate(pipelines):\n",
    "        # getting the name of our model\n",
    "        model_name = ml_dict[i]\n",
    "        print(model_name)\n",
    "        \n",
    "        # fitting our data\n",
    "        pipe.fit(X_train, y_train)\n",
    "        \n",
    "        evaluate_model(models_scores_df, i, model_name, pipe, X, y, X_test, y_test)\n",
    "\n",
    "\n",
    "    # selecting top 3 score based on metric\n",
    "    filtered_models_scores_df =  models_scores_df.sort_values(metric).iloc[:3, :]\n",
    "\n",
    "    for i in filtered_models_scores_df.index:\n",
    "        plot_feature_importance(pipelines[i],  X.columns, ml_dict[i])\n",
    "\n",
    "    return models_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (337, 223) \t Shape of y_train: (337,)\n",
      "Shape of X_test: (113, 223) \t Shape of y_test: (113,)\n",
      "LinearRegression\n",
      "Lasso\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.451e+00, tolerance: 5.008e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.813e-01, tolerance: 3.921e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.423e-01, tolerance: 4.703e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.702e-01, tolerance: 4.572e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree\n",
      "RandomForest\n",
      "XGBRegressor\n",
      "GradientBoostingRegressor\n",
      "Elastic Net\n",
      "BayesianRidge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.873e+00, tolerance: 4.524e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.355e+01, tolerance: 5.008e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.174e+01, tolerance: 3.921e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.210e+00, tolerance: 4.703e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.741e+01, tolerance: 4.572e-02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoostRegressor\n",
      "LGBMRegressor\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Mean CV</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R_Squared</th>\n",
       "      <th>Adjusted_R_Squared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>-2.723782e+08</td>\n",
       "      <td>3.080510e+10</td>\n",
       "      <td>1.309154e+10</td>\n",
       "      <td>2.007174e+22</td>\n",
       "      <td>1.416748e+11</td>\n",
       "      <td>-1.482863e+22</td>\n",
       "      <td>1.496222e+22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>-4.091867e-01</td>\n",
       "      <td>9.734274e-01</td>\n",
       "      <td>7.433510e-01</td>\n",
       "      <td>1.354955e+00</td>\n",
       "      <td>1.164025e+00</td>\n",
       "      <td>-1.015262e-03</td>\n",
       "      <td>2.010033e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>-2.947590e-01</td>\n",
       "      <td>5.146232e-01</td>\n",
       "      <td>3.384617e-01</td>\n",
       "      <td>5.087949e-01</td>\n",
       "      <td>7.132986e-01</td>\n",
       "      <td>6.241117e-01</td>\n",
       "      <td>1.379275e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>-2.443297e-01</td>\n",
       "      <td>4.668781e-01</td>\n",
       "      <td>3.901657e-01</td>\n",
       "      <td>4.203261e-01</td>\n",
       "      <td>6.483256e-01</td>\n",
       "      <td>6.894709e-01</td>\n",
       "      <td>1.313327e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>-2.483595e-01</td>\n",
       "      <td>4.979689e-01</td>\n",
       "      <td>3.626972e-01</td>\n",
       "      <td>4.753140e-01</td>\n",
       "      <td>6.894302e-01</td>\n",
       "      <td>6.488469e-01</td>\n",
       "      <td>1.354317e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>-2.351166e-01</td>\n",
       "      <td>4.758395e-01</td>\n",
       "      <td>4.092906e-01</td>\n",
       "      <td>4.444153e-01</td>\n",
       "      <td>6.666448e-01</td>\n",
       "      <td>6.716742e-01</td>\n",
       "      <td>1.331284e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Elastic Net</td>\n",
       "      <td>-3.945067e-01</td>\n",
       "      <td>9.047934e-01</td>\n",
       "      <td>7.004029e-01</td>\n",
       "      <td>1.163201e+00</td>\n",
       "      <td>1.078518e+00</td>\n",
       "      <td>1.406485e-01</td>\n",
       "      <td>1.867093e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BayesianRidge</td>\n",
       "      <td>-3.161020e-01</td>\n",
       "      <td>5.044380e-01</td>\n",
       "      <td>4.072736e-01</td>\n",
       "      <td>5.351598e-01</td>\n",
       "      <td>7.315462e-01</td>\n",
       "      <td>6.046339e-01</td>\n",
       "      <td>1.398928e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CatBoostRegressor</td>\n",
       "      <td>-2.474699e-01</td>\n",
       "      <td>4.757227e-01</td>\n",
       "      <td>4.000842e-01</td>\n",
       "      <td>4.397612e-01</td>\n",
       "      <td>6.631450e-01</td>\n",
       "      <td>6.751126e-01</td>\n",
       "      <td>1.327814e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>-2.546325e-01</td>\n",
       "      <td>4.782828e-01</td>\n",
       "      <td>4.060710e-01</td>\n",
       "      <td>4.656290e-01</td>\n",
       "      <td>6.823702e-01</td>\n",
       "      <td>6.560019e-01</td>\n",
       "      <td>1.347097e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model       Mean CV           MAE          MAPE  \\\n",
       "0           LinearRegression -2.723782e+08  3.080510e+10  1.309154e+10   \n",
       "1                      Lasso -4.091867e-01  9.734274e-01  7.433510e-01   \n",
       "2               DecisionTree -2.947590e-01  5.146232e-01  3.384617e-01   \n",
       "3               RandomForest -2.443297e-01  4.668781e-01  3.901657e-01   \n",
       "4               XGBRegressor -2.483595e-01  4.979689e-01  3.626972e-01   \n",
       "5  GradientBoostingRegressor -2.351166e-01  4.758395e-01  4.092906e-01   \n",
       "6                Elastic Net -3.945067e-01  9.047934e-01  7.004029e-01   \n",
       "7              BayesianRidge -3.161020e-01  5.044380e-01  4.072736e-01   \n",
       "8          CatBoostRegressor -2.474699e-01  4.757227e-01  4.000842e-01   \n",
       "9              LGBMRegressor -2.546325e-01  4.782828e-01  4.060710e-01   \n",
       "\n",
       "            MSE          RMSE     R_Squared  Adjusted_R_Squared  \n",
       "0  2.007174e+22  1.416748e+11 -1.482863e+22        1.496222e+22  \n",
       "1  1.354955e+00  1.164025e+00 -1.015262e-03        2.010033e+00  \n",
       "2  5.087949e-01  7.132986e-01  6.241117e-01        1.379275e+00  \n",
       "3  4.203261e-01  6.483256e-01  6.894709e-01        1.313327e+00  \n",
       "4  4.753140e-01  6.894302e-01  6.488469e-01        1.354317e+00  \n",
       "5  4.444153e-01  6.666448e-01  6.716742e-01        1.331284e+00  \n",
       "6  1.163201e+00  1.078518e+00  1.406485e-01        1.867093e+00  \n",
       "7  5.351598e-01  7.315462e-01  6.046339e-01        1.398928e+00  \n",
       "8  4.397612e-01  6.631450e-01  6.751126e-01        1.327814e+00  \n",
       "9  4.656290e-01  6.823702e-01  6.560019e-01        1.347097e+00  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_features = train_and_evalute(X, y, metric=\"MAPE\")\n",
    "all_features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Feature-Selection\"></a>\n",
    "### 3.2 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "# Import library for VIF\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "def calc_vif(X):\n",
    "\n",
    "    # Calculating VIF\n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"variables\"] = X.columns\n",
    "    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "    return(vif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "\n",
    "sfs1 = SFS(GradientBoostingRegressor(), \n",
    "           k_features=15,\n",
    "           forward=True, \n",
    "           floating=False, \n",
    "           verbose=0,\n",
    "           scoring=\"neg_mean_absolute_percentage_error\",\n",
    "           cv=0)\n",
    "\n",
    "sfs1 = sfs1.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('nAtom',\n",
       " 'ATSc3',\n",
       " 'ATSc4',\n",
       " 'ATSm5',\n",
       " 'ATSp5',\n",
       " 'BCUTp-1l',\n",
       " 'SCH-7',\n",
       " 'VC-6',\n",
       " 'VP-4',\n",
       " 'VP-6',\n",
       " 'FMF',\n",
       " 'JPLogP',\n",
       " 'MDEC-12',\n",
       " 'TopoPSA',\n",
       " 'XLogP')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try selecting more features\n",
    "sfs1.k_feature_names_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\_methods.py:264: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\core\\_methods.py:256: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_idx</th>\n",
       "      <th>cv_scores</th>\n",
       "      <th>avg_score</th>\n",
       "      <th>feature_names</th>\n",
       "      <th>ci_bound</th>\n",
       "      <th>std_dev</th>\n",
       "      <th>std_err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(78,)</td>\n",
       "      <td>[-0.20010936681143557]</td>\n",
       "      <td>-0.200109</td>\n",
       "      <td>(VP-4,)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(78, 210)</td>\n",
       "      <td>[-0.15591571330861745]</td>\n",
       "      <td>-0.155916</td>\n",
       "      <td>(VP-4, TopoPSA)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(12, 78, 210)</td>\n",
       "      <td>[-0.1459545645465073]</td>\n",
       "      <td>-0.145955</td>\n",
       "      <td>(ATSc4, VP-4, TopoPSA)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(12, 78, 210, 221)</td>\n",
       "      <td>[-0.14275823637857804]</td>\n",
       "      <td>-0.142758</td>\n",
       "      <td>(ATSc4, VP-4, TopoPSA, XLogP)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(12, 78, 80, 210, 221)</td>\n",
       "      <td>[-0.13841826267534424]</td>\n",
       "      <td>-0.138418</td>\n",
       "      <td>(ATSc4, VP-4, VP-6, TopoPSA, XLogP)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(11, 12, 78, 80, 210, 221)</td>\n",
       "      <td>[-0.13764980640131905]</td>\n",
       "      <td>-0.13765</td>\n",
       "      <td>(ATSc3, ATSc4, VP-4, VP-6, TopoPSA, XLogP)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(11, 12, 28, 78, 80, 210, 221)</td>\n",
       "      <td>[-0.13497015931569553]</td>\n",
       "      <td>-0.13497</td>\n",
       "      <td>(ATSc3, ATSc4, BCUTp-1l, VP-4, VP-6, TopoPSA, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(11, 12, 28, 78, 80, 89, 210, 221)</td>\n",
       "      <td>[-0.13128494025202264]</td>\n",
       "      <td>-0.131285</td>\n",
       "      <td>(ATSc3, ATSc4, BCUTp-1l, VP-4, VP-6, JPLogP, T...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(11, 12, 28, 78, 80, 89, 176, 210, 221)</td>\n",
       "      <td>[-0.1301085265214019]</td>\n",
       "      <td>-0.130109</td>\n",
       "      <td>(ATSc3, ATSc4, BCUTp-1l, VP-4, VP-6, JPLogP, M...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(11, 12, 28, 78, 80, 83, 89, 176, 210, 221)</td>\n",
       "      <td>[-0.12939687333513109]</td>\n",
       "      <td>-0.129397</td>\n",
       "      <td>(ATSc3, ATSc4, BCUTp-1l, VP-4, VP-6, FMF, JPLo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(11, 12, 28, 46, 78, 80, 83, 89, 176, 210, 221)</td>\n",
       "      <td>[-0.129250694655125]</td>\n",
       "      <td>-0.129251</td>\n",
       "      <td>(ATSc3, ATSc4, BCUTp-1l, SCH-7, VP-4, VP-6, FM...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(11, 12, 23, 28, 46, 78, 80, 83, 89, 176, 210,...</td>\n",
       "      <td>[-0.12892992227837646]</td>\n",
       "      <td>-0.12893</td>\n",
       "      <td>(ATSc3, ATSc4, ATSp5, BCUTp-1l, SCH-7, VP-4, V...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(11, 12, 18, 23, 28, 46, 78, 80, 83, 89, 176, ...</td>\n",
       "      <td>[-0.1285651979392716]</td>\n",
       "      <td>-0.128565</td>\n",
       "      <td>(ATSc3, ATSc4, ATSm5, ATSp5, BCUTp-1l, SCH-7, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(8, 11, 12, 18, 23, 28, 46, 78, 80, 83, 89, 17...</td>\n",
       "      <td>[-0.12784518856792015]</td>\n",
       "      <td>-0.127845</td>\n",
       "      <td>(nAtom, ATSc3, ATSc4, ATSm5, ATSp5, BCUTp-1l, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(8, 11, 12, 18, 23, 28, 46, 59, 78, 80, 83, 89...</td>\n",
       "      <td>[-0.12722225530887304]</td>\n",
       "      <td>-0.127222</td>\n",
       "      <td>(nAtom, ATSc3, ATSc4, ATSm5, ATSp5, BCUTp-1l, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          feature_idx               cv_scores  \\\n",
       "1                                               (78,)  [-0.20010936681143557]   \n",
       "2                                           (78, 210)  [-0.15591571330861745]   \n",
       "3                                       (12, 78, 210)   [-0.1459545645465073]   \n",
       "4                                  (12, 78, 210, 221)  [-0.14275823637857804]   \n",
       "5                              (12, 78, 80, 210, 221)  [-0.13841826267534424]   \n",
       "6                          (11, 12, 78, 80, 210, 221)  [-0.13764980640131905]   \n",
       "7                      (11, 12, 28, 78, 80, 210, 221)  [-0.13497015931569553]   \n",
       "8                  (11, 12, 28, 78, 80, 89, 210, 221)  [-0.13128494025202264]   \n",
       "9             (11, 12, 28, 78, 80, 89, 176, 210, 221)   [-0.1301085265214019]   \n",
       "10        (11, 12, 28, 78, 80, 83, 89, 176, 210, 221)  [-0.12939687333513109]   \n",
       "11    (11, 12, 28, 46, 78, 80, 83, 89, 176, 210, 221)    [-0.129250694655125]   \n",
       "12  (11, 12, 23, 28, 46, 78, 80, 83, 89, 176, 210,...  [-0.12892992227837646]   \n",
       "13  (11, 12, 18, 23, 28, 46, 78, 80, 83, 89, 176, ...   [-0.1285651979392716]   \n",
       "14  (8, 11, 12, 18, 23, 28, 46, 78, 80, 83, 89, 17...  [-0.12784518856792015]   \n",
       "15  (8, 11, 12, 18, 23, 28, 46, 59, 78, 80, 83, 89...  [-0.12722225530887304]   \n",
       "\n",
       "   avg_score                                      feature_names ci_bound  \\\n",
       "1  -0.200109                                            (VP-4,)      NaN   \n",
       "2  -0.155916                                    (VP-4, TopoPSA)      NaN   \n",
       "3  -0.145955                             (ATSc4, VP-4, TopoPSA)      NaN   \n",
       "4  -0.142758                      (ATSc4, VP-4, TopoPSA, XLogP)      NaN   \n",
       "5  -0.138418                (ATSc4, VP-4, VP-6, TopoPSA, XLogP)      NaN   \n",
       "6   -0.13765         (ATSc3, ATSc4, VP-4, VP-6, TopoPSA, XLogP)      NaN   \n",
       "7   -0.13497  (ATSc3, ATSc4, BCUTp-1l, VP-4, VP-6, TopoPSA, ...      NaN   \n",
       "8  -0.131285  (ATSc3, ATSc4, BCUTp-1l, VP-4, VP-6, JPLogP, T...      NaN   \n",
       "9  -0.130109  (ATSc3, ATSc4, BCUTp-1l, VP-4, VP-6, JPLogP, M...      NaN   \n",
       "10 -0.129397  (ATSc3, ATSc4, BCUTp-1l, VP-4, VP-6, FMF, JPLo...      NaN   \n",
       "11 -0.129251  (ATSc3, ATSc4, BCUTp-1l, SCH-7, VP-4, VP-6, FM...      NaN   \n",
       "12  -0.12893  (ATSc3, ATSc4, ATSp5, BCUTp-1l, SCH-7, VP-4, V...      NaN   \n",
       "13 -0.128565  (ATSc3, ATSc4, ATSm5, ATSp5, BCUTp-1l, SCH-7, ...      NaN   \n",
       "14 -0.127845  (nAtom, ATSc3, ATSc4, ATSm5, ATSp5, BCUTp-1l, ...      NaN   \n",
       "15 -0.127222  (nAtom, ATSc3, ATSc4, ATSm5, ATSp5, BCUTp-1l, ...      NaN   \n",
       "\n",
       "   std_dev std_err  \n",
       "1      0.0     NaN  \n",
       "2      0.0     NaN  \n",
       "3      0.0     NaN  \n",
       "4      0.0     NaN  \n",
       "5      0.0     NaN  \n",
       "6      0.0     NaN  \n",
       "7      0.0     NaN  \n",
       "8      0.0     NaN  \n",
       "9      0.0     NaN  \n",
       "10     0.0     NaN  \n",
       "11     0.0     NaN  \n",
       "12     0.0     NaN  \n",
       "13     0.0     NaN  \n",
       "14     0.0     NaN  \n",
       "15     0.0     NaN  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(sfs1.get_metric_dict()).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (337, 15) \t Shape of y_train: (337,)\n",
      "Shape of X_test: (113, 15) \t Shape of y_test: (113,)\n",
      "LinearRegression\n",
      "Lasso\n",
      "DecisionTree\n",
      "RandomForest\n",
      "XGBRegressor\n",
      "GradientBoostingRegressor\n",
      "Elastic Net\n",
      "BayesianRidge\n",
      "CatBoostRegressor\n",
      "LGBMRegressor\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Mean CV</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R_Squared</th>\n",
       "      <th>Adjusted_R_Squared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>-0.415662</td>\n",
       "      <td>0.699380</td>\n",
       "      <td>0.532875</td>\n",
       "      <td>0.857600</td>\n",
       "      <td>0.926067</td>\n",
       "      <td>0.366421</td>\n",
       "      <td>0.268445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>-0.423370</td>\n",
       "      <td>0.973427</td>\n",
       "      <td>0.743351</td>\n",
       "      <td>1.354955</td>\n",
       "      <td>1.164025</td>\n",
       "      <td>-0.001015</td>\n",
       "      <td>-0.155811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>-0.302107</td>\n",
       "      <td>0.530928</td>\n",
       "      <td>0.389821</td>\n",
       "      <td>0.566712</td>\n",
       "      <td>0.752803</td>\n",
       "      <td>0.581324</td>\n",
       "      <td>0.516580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>-0.257463</td>\n",
       "      <td>0.460777</td>\n",
       "      <td>0.368172</td>\n",
       "      <td>0.421407</td>\n",
       "      <td>0.649158</td>\n",
       "      <td>0.688673</td>\n",
       "      <td>0.640529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>-0.262768</td>\n",
       "      <td>0.473859</td>\n",
       "      <td>0.357891</td>\n",
       "      <td>0.452601</td>\n",
       "      <td>0.672756</td>\n",
       "      <td>0.665627</td>\n",
       "      <td>0.613920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>-0.250169</td>\n",
       "      <td>0.468296</td>\n",
       "      <td>0.389406</td>\n",
       "      <td>0.467399</td>\n",
       "      <td>0.683666</td>\n",
       "      <td>0.654695</td>\n",
       "      <td>0.601297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Elastic Net</td>\n",
       "      <td>-0.415209</td>\n",
       "      <td>0.918350</td>\n",
       "      <td>0.710563</td>\n",
       "      <td>1.198713</td>\n",
       "      <td>1.094858</td>\n",
       "      <td>0.114413</td>\n",
       "      <td>-0.022533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BayesianRidge</td>\n",
       "      <td>-0.407000</td>\n",
       "      <td>0.697958</td>\n",
       "      <td>0.534132</td>\n",
       "      <td>0.832778</td>\n",
       "      <td>0.912567</td>\n",
       "      <td>0.384759</td>\n",
       "      <td>0.289618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CatBoostRegressor</td>\n",
       "      <td>-0.253290</td>\n",
       "      <td>0.484504</td>\n",
       "      <td>0.402669</td>\n",
       "      <td>0.452396</td>\n",
       "      <td>0.672604</td>\n",
       "      <td>0.665778</td>\n",
       "      <td>0.614095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LGBMRegressor</td>\n",
       "      <td>-0.254476</td>\n",
       "      <td>0.446234</td>\n",
       "      <td>0.364477</td>\n",
       "      <td>0.405658</td>\n",
       "      <td>0.636913</td>\n",
       "      <td>0.700307</td>\n",
       "      <td>0.653963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       model   Mean CV       MAE      MAPE       MSE  \\\n",
       "0           LinearRegression -0.415662  0.699380  0.532875  0.857600   \n",
       "1                      Lasso -0.423370  0.973427  0.743351  1.354955   \n",
       "2               DecisionTree -0.302107  0.530928  0.389821  0.566712   \n",
       "3               RandomForest -0.257463  0.460777  0.368172  0.421407   \n",
       "4               XGBRegressor -0.262768  0.473859  0.357891  0.452601   \n",
       "5  GradientBoostingRegressor -0.250169  0.468296  0.389406  0.467399   \n",
       "6                Elastic Net -0.415209  0.918350  0.710563  1.198713   \n",
       "7              BayesianRidge -0.407000  0.697958  0.534132  0.832778   \n",
       "8          CatBoostRegressor -0.253290  0.484504  0.402669  0.452396   \n",
       "9              LGBMRegressor -0.254476  0.446234  0.364477  0.405658   \n",
       "\n",
       "       RMSE  R_Squared  Adjusted_R_Squared  \n",
       "0  0.926067   0.366421            0.268445  \n",
       "1  1.164025  -0.001015           -0.155811  \n",
       "2  0.752803   0.581324            0.516580  \n",
       "3  0.649158   0.688673            0.640529  \n",
       "4  0.672756   0.665627            0.613920  \n",
       "5  0.683666   0.654695            0.601297  \n",
       "6  1.094858   0.114413           -0.022533  \n",
       "7  0.912567   0.384759            0.289618  \n",
       "8  0.672604   0.665778            0.614095  \n",
       "9  0.636913   0.700307            0.653963  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features_X = X.iloc[:, list(sfs1.k_feature_idx_)]\n",
    "y = model_data['logkpl']\n",
    "\n",
    "train_and_evalute(selected_features_X, y, metric=\"MAPE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variables</th>\n",
       "      <th>VIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nAtom</td>\n",
       "      <td>131.890992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATSc3</td>\n",
       "      <td>6.296528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ATSc4</td>\n",
       "      <td>4.628750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ATSm5</td>\n",
       "      <td>132.665400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ATSp5</td>\n",
       "      <td>200.105858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BCUTp-1l</td>\n",
       "      <td>33.861533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SCH-7</td>\n",
       "      <td>49.246722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>VC-6</td>\n",
       "      <td>18.231877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>VP-4</td>\n",
       "      <td>1187.995026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>VP-6</td>\n",
       "      <td>846.353572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>FMF</td>\n",
       "      <td>13.280614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>JPLogP</td>\n",
       "      <td>78.455993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MDEC-12</td>\n",
       "      <td>13.887652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>TopoPSA</td>\n",
       "      <td>29.497566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>XLogP</td>\n",
       "      <td>47.229743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   variables          VIF\n",
       "0      nAtom   131.890992\n",
       "1      ATSc3     6.296528\n",
       "2      ATSc4     4.628750\n",
       "3      ATSm5   132.665400\n",
       "4      ATSp5   200.105858\n",
       "5   BCUTp-1l    33.861533\n",
       "6      SCH-7    49.246722\n",
       "7       VC-6    18.231877\n",
       "8       VP-4  1187.995026\n",
       "9       VP-6   846.353572\n",
       "10       FMF    13.280614\n",
       "11    JPLogP    78.455993\n",
       "12   MDEC-12    13.887652\n",
       "13   TopoPSA    29.497566\n",
       "14     XLogP    47.229743"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_vif(selected_features_X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Feature-Selection-PCA\"></a>\n",
    "### 3.3 Feature Selection using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Components by PCA 36\n",
      "Explained Variance Ratio 0.9910016806575245\n"
     ]
    }
   ],
   "source": [
    "X = model_data.drop([\"logkpl\"], axis=1)\n",
    "y = model_data['logkpl']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "# initilizing and fitting the pca\n",
    "pca = PCA(n_components=0.99)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "print(\"Number of Components by PCA\", X_pca.shape[1])\n",
    "print(\"Explained Variance Ratio\", pca.explained_variance_ratio_.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.components_.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (223, 36), indices imply (36, 36)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\user\\Desktop\\Skin Permeation\\Skin-Permeation\\notebooks\\trials\\3. Trial4.ipynb Cell 27\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/Skin%20Permeation/Skin-Permeation/notebooks/trials/3.%20Trial4.ipynb#X62sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m test_ \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame(pca\u001b[39m.\u001b[39;49mcomponents_\u001b[39m.\u001b[39;49mT, index \u001b[39m=\u001b[39;49m {\u001b[39m'\u001b[39;49m\u001b[39mPC\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49mformat(i\u001b[39m+\u001b[39;49m\u001b[39m1\u001b[39;49m) \u001b[39mfor\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(X_pca\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m])})\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:694\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    684\u001b[0m         mgr \u001b[39m=\u001b[39m dict_to_mgr(\n\u001b[0;32m    685\u001b[0m             \u001b[39m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[0;32m    686\u001b[0m             \u001b[39m# attribute \"name\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    691\u001b[0m             typ\u001b[39m=\u001b[39mmanager,\n\u001b[0;32m    692\u001b[0m         )\n\u001b[0;32m    693\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 694\u001b[0m         mgr \u001b[39m=\u001b[39m ndarray_to_mgr(\n\u001b[0;32m    695\u001b[0m             data,\n\u001b[0;32m    696\u001b[0m             index,\n\u001b[0;32m    697\u001b[0m             columns,\n\u001b[0;32m    698\u001b[0m             dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    699\u001b[0m             copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m    700\u001b[0m             typ\u001b[39m=\u001b[39;49mmanager,\n\u001b[0;32m    701\u001b[0m         )\n\u001b[0;32m    703\u001b[0m \u001b[39m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[0;32m    704\u001b[0m \u001b[39melif\u001b[39;00m is_list_like(data):\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\construction.py:351\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[1;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[0;32m    346\u001b[0m \u001b[39m# _prep_ndarray ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[0;32m    347\u001b[0m index, columns \u001b[39m=\u001b[39m _get_axes(\n\u001b[0;32m    348\u001b[0m     values\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], values\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], index\u001b[39m=\u001b[39mindex, columns\u001b[39m=\u001b[39mcolumns\n\u001b[0;32m    349\u001b[0m )\n\u001b[1;32m--> 351\u001b[0m _check_values_indices_shape_match(values, index, columns)\n\u001b[0;32m    353\u001b[0m \u001b[39mif\u001b[39;00m typ \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39marray\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    355\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(values\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype, \u001b[39mstr\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\internals\\construction.py:422\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[1;34m(values, index, columns)\u001b[0m\n\u001b[0;32m    420\u001b[0m passed \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mshape\n\u001b[0;32m    421\u001b[0m implied \u001b[39m=\u001b[39m (\u001b[39mlen\u001b[39m(index), \u001b[39mlen\u001b[39m(columns))\n\u001b[1;32m--> 422\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mShape of passed values is \u001b[39m\u001b[39m{\u001b[39;00mpassed\u001b[39m}\u001b[39;00m\u001b[39m, indices imply \u001b[39m\u001b[39m{\u001b[39;00mimplied\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Shape of passed values is (223, 36), indices imply (36, 36)"
     ]
    }
   ],
   "source": [
    "test_ = pd.DataFrame(pca.components_.T, index = {'PC{}'.format(i+1) for i in range(X_pca.shape[1])}) #columns=X.columns,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Texpi</th>\n",
       "      <th>ALogP</th>\n",
       "      <th>ALogp2</th>\n",
       "      <th>AMR</th>\n",
       "      <th>apol</th>\n",
       "      <th>nAcid</th>\n",
       "      <th>naAromAtom</th>\n",
       "      <th>nAromBond</th>\n",
       "      <th>nAtom</th>\n",
       "      <th>ATSc1</th>\n",
       "      <th>...</th>\n",
       "      <th>MW</th>\n",
       "      <th>WTPT-1</th>\n",
       "      <th>WTPT-2</th>\n",
       "      <th>WTPT-3</th>\n",
       "      <th>WTPT-4</th>\n",
       "      <th>WTPT-5</th>\n",
       "      <th>WPATH</th>\n",
       "      <th>WPOL</th>\n",
       "      <th>XLogP</th>\n",
       "      <th>Zagreb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PC22</th>\n",
       "      <td>-0.031134</td>\n",
       "      <td>0.030326</td>\n",
       "      <td>0.029669</td>\n",
       "      <td>0.114115</td>\n",
       "      <td>0.115273</td>\n",
       "      <td>-0.010320</td>\n",
       "      <td>-0.029310</td>\n",
       "      <td>-0.028832</td>\n",
       "      <td>0.114519</td>\n",
       "      <td>0.052669</td>\n",
       "      <td>...</td>\n",
       "      <td>0.101812</td>\n",
       "      <td>0.115455</td>\n",
       "      <td>0.064667</td>\n",
       "      <td>0.032302</td>\n",
       "      <td>0.060440</td>\n",
       "      <td>-0.018330</td>\n",
       "      <td>0.103617</td>\n",
       "      <td>0.117898</td>\n",
       "      <td>0.023811</td>\n",
       "      <td>0.117122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC26</th>\n",
       "      <td>0.010533</td>\n",
       "      <td>0.008850</td>\n",
       "      <td>0.010250</td>\n",
       "      <td>-0.002350</td>\n",
       "      <td>-0.004319</td>\n",
       "      <td>-0.001354</td>\n",
       "      <td>0.021178</td>\n",
       "      <td>0.022900</td>\n",
       "      <td>-0.004386</td>\n",
       "      <td>-0.006872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.069261</td>\n",
       "      <td>-0.012309</td>\n",
       "      <td>0.096491</td>\n",
       "      <td>0.133848</td>\n",
       "      <td>-0.005664</td>\n",
       "      <td>0.005569</td>\n",
       "      <td>-0.007815</td>\n",
       "      <td>-0.007042</td>\n",
       "      <td>-0.006046</td>\n",
       "      <td>-0.007859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC18</th>\n",
       "      <td>0.051618</td>\n",
       "      <td>-0.196747</td>\n",
       "      <td>0.021007</td>\n",
       "      <td>-0.016240</td>\n",
       "      <td>-0.003918</td>\n",
       "      <td>0.019890</td>\n",
       "      <td>-0.137567</td>\n",
       "      <td>-0.136193</td>\n",
       "      <td>0.017040</td>\n",
       "      <td>0.199363</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022298</td>\n",
       "      <td>0.006382</td>\n",
       "      <td>-0.075486</td>\n",
       "      <td>0.122665</td>\n",
       "      <td>0.199015</td>\n",
       "      <td>0.005294</td>\n",
       "      <td>0.056777</td>\n",
       "      <td>0.005852</td>\n",
       "      <td>-0.188817</td>\n",
       "      <td>-0.003149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC5</th>\n",
       "      <td>0.100162</td>\n",
       "      <td>-0.031766</td>\n",
       "      <td>0.043603</td>\n",
       "      <td>0.046351</td>\n",
       "      <td>0.021389</td>\n",
       "      <td>0.057670</td>\n",
       "      <td>0.202798</td>\n",
       "      <td>0.203425</td>\n",
       "      <td>0.009061</td>\n",
       "      <td>0.114939</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072590</td>\n",
       "      <td>0.061656</td>\n",
       "      <td>0.090736</td>\n",
       "      <td>0.128473</td>\n",
       "      <td>0.064389</td>\n",
       "      <td>0.185328</td>\n",
       "      <td>0.068606</td>\n",
       "      <td>0.021310</td>\n",
       "      <td>-0.029105</td>\n",
       "      <td>0.044390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC19</th>\n",
       "      <td>0.013156</td>\n",
       "      <td>0.169669</td>\n",
       "      <td>0.171723</td>\n",
       "      <td>0.068874</td>\n",
       "      <td>0.071087</td>\n",
       "      <td>0.008856</td>\n",
       "      <td>0.064905</td>\n",
       "      <td>0.063447</td>\n",
       "      <td>0.075688</td>\n",
       "      <td>-0.055343</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063525</td>\n",
       "      <td>0.028867</td>\n",
       "      <td>0.056302</td>\n",
       "      <td>-0.024750</td>\n",
       "      <td>-0.046111</td>\n",
       "      <td>-0.050427</td>\n",
       "      <td>0.030127</td>\n",
       "      <td>-0.031660</td>\n",
       "      <td>0.162314</td>\n",
       "      <td>-0.012495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC3</th>\n",
       "      <td>-0.038630</td>\n",
       "      <td>0.022768</td>\n",
       "      <td>-0.123096</td>\n",
       "      <td>0.029593</td>\n",
       "      <td>0.026201</td>\n",
       "      <td>0.075240</td>\n",
       "      <td>-0.064603</td>\n",
       "      <td>-0.062018</td>\n",
       "      <td>0.029834</td>\n",
       "      <td>0.011610</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035915</td>\n",
       "      <td>0.010416</td>\n",
       "      <td>-0.123941</td>\n",
       "      <td>0.006293</td>\n",
       "      <td>-0.069951</td>\n",
       "      <td>0.210349</td>\n",
       "      <td>0.058728</td>\n",
       "      <td>0.006815</td>\n",
       "      <td>0.005178</td>\n",
       "      <td>0.014053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC20</th>\n",
       "      <td>0.074036</td>\n",
       "      <td>0.065755</td>\n",
       "      <td>0.129346</td>\n",
       "      <td>0.029632</td>\n",
       "      <td>0.037801</td>\n",
       "      <td>-0.014044</td>\n",
       "      <td>0.073475</td>\n",
       "      <td>0.070509</td>\n",
       "      <td>0.040948</td>\n",
       "      <td>-0.033702</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069635</td>\n",
       "      <td>0.018906</td>\n",
       "      <td>-0.120407</td>\n",
       "      <td>-0.075146</td>\n",
       "      <td>0.036866</td>\n",
       "      <td>-0.091467</td>\n",
       "      <td>0.038523</td>\n",
       "      <td>0.024288</td>\n",
       "      <td>0.084629</td>\n",
       "      <td>0.035862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC11</th>\n",
       "      <td>-0.027987</td>\n",
       "      <td>-0.031357</td>\n",
       "      <td>-0.119799</td>\n",
       "      <td>-0.006994</td>\n",
       "      <td>-0.010037</td>\n",
       "      <td>-0.038942</td>\n",
       "      <td>-0.035307</td>\n",
       "      <td>-0.038564</td>\n",
       "      <td>-0.012992</td>\n",
       "      <td>-0.002797</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015015</td>\n",
       "      <td>-0.010449</td>\n",
       "      <td>-0.052940</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>-0.021083</td>\n",
       "      <td>0.030460</td>\n",
       "      <td>-0.003296</td>\n",
       "      <td>-0.000883</td>\n",
       "      <td>-0.045563</td>\n",
       "      <td>-0.002798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC12</th>\n",
       "      <td>0.075948</td>\n",
       "      <td>0.004944</td>\n",
       "      <td>0.053060</td>\n",
       "      <td>-0.003113</td>\n",
       "      <td>0.005771</td>\n",
       "      <td>0.138356</td>\n",
       "      <td>0.012995</td>\n",
       "      <td>0.019829</td>\n",
       "      <td>0.015674</td>\n",
       "      <td>-0.013816</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019384</td>\n",
       "      <td>0.013657</td>\n",
       "      <td>0.028088</td>\n",
       "      <td>-0.035190</td>\n",
       "      <td>-0.022426</td>\n",
       "      <td>0.063407</td>\n",
       "      <td>0.027432</td>\n",
       "      <td>0.010967</td>\n",
       "      <td>-0.028877</td>\n",
       "      <td>0.007813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC13</th>\n",
       "      <td>-0.106433</td>\n",
       "      <td>0.033448</td>\n",
       "      <td>-0.016095</td>\n",
       "      <td>0.010013</td>\n",
       "      <td>-0.000685</td>\n",
       "      <td>0.189053</td>\n",
       "      <td>-0.025590</td>\n",
       "      <td>-0.023749</td>\n",
       "      <td>-0.008754</td>\n",
       "      <td>-0.007759</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012833</td>\n",
       "      <td>0.015194</td>\n",
       "      <td>-0.008154</td>\n",
       "      <td>-0.005839</td>\n",
       "      <td>-0.007580</td>\n",
       "      <td>-0.028162</td>\n",
       "      <td>0.083090</td>\n",
       "      <td>-0.001552</td>\n",
       "      <td>0.021814</td>\n",
       "      <td>0.005351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC16</th>\n",
       "      <td>-0.024160</td>\n",
       "      <td>-0.037733</td>\n",
       "      <td>-0.082037</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>-0.001584</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.013810</td>\n",
       "      <td>0.013108</td>\n",
       "      <td>-0.001437</td>\n",
       "      <td>-0.001574</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006637</td>\n",
       "      <td>-0.000595</td>\n",
       "      <td>-0.014606</td>\n",
       "      <td>0.000973</td>\n",
       "      <td>-0.009761</td>\n",
       "      <td>0.020692</td>\n",
       "      <td>0.014883</td>\n",
       "      <td>-0.003327</td>\n",
       "      <td>-0.054030</td>\n",
       "      <td>-0.000261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC27</th>\n",
       "      <td>0.040169</td>\n",
       "      <td>0.094654</td>\n",
       "      <td>0.176209</td>\n",
       "      <td>-0.001935</td>\n",
       "      <td>-0.000090</td>\n",
       "      <td>-0.023089</td>\n",
       "      <td>-0.082017</td>\n",
       "      <td>-0.085205</td>\n",
       "      <td>-0.004987</td>\n",
       "      <td>0.074251</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002445</td>\n",
       "      <td>0.005331</td>\n",
       "      <td>0.025443</td>\n",
       "      <td>-0.006169</td>\n",
       "      <td>0.024947</td>\n",
       "      <td>-0.063560</td>\n",
       "      <td>-0.002133</td>\n",
       "      <td>0.010923</td>\n",
       "      <td>0.136784</td>\n",
       "      <td>0.001804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC30</th>\n",
       "      <td>-0.029679</td>\n",
       "      <td>-0.014519</td>\n",
       "      <td>-0.068333</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>-0.004482</td>\n",
       "      <td>0.115438</td>\n",
       "      <td>0.060124</td>\n",
       "      <td>0.066535</td>\n",
       "      <td>-0.008399</td>\n",
       "      <td>-0.051195</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004233</td>\n",
       "      <td>-0.008705</td>\n",
       "      <td>-0.042696</td>\n",
       "      <td>-0.006499</td>\n",
       "      <td>-0.036438</td>\n",
       "      <td>0.099545</td>\n",
       "      <td>0.022315</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>-0.045915</td>\n",
       "      <td>-0.004260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC36</th>\n",
       "      <td>0.035436</td>\n",
       "      <td>-0.022509</td>\n",
       "      <td>0.073719</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.013214</td>\n",
       "      <td>-0.134064</td>\n",
       "      <td>-0.073024</td>\n",
       "      <td>-0.073349</td>\n",
       "      <td>0.020417</td>\n",
       "      <td>-0.043346</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004885</td>\n",
       "      <td>-0.005689</td>\n",
       "      <td>0.013212</td>\n",
       "      <td>0.002041</td>\n",
       "      <td>-0.129302</td>\n",
       "      <td>0.177240</td>\n",
       "      <td>-0.021119</td>\n",
       "      <td>-0.018696</td>\n",
       "      <td>-0.001367</td>\n",
       "      <td>-0.002919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC29</th>\n",
       "      <td>-0.098841</td>\n",
       "      <td>0.074548</td>\n",
       "      <td>-0.006581</td>\n",
       "      <td>-0.013119</td>\n",
       "      <td>-0.016133</td>\n",
       "      <td>0.088695</td>\n",
       "      <td>0.033715</td>\n",
       "      <td>0.037289</td>\n",
       "      <td>-0.025512</td>\n",
       "      <td>-0.027366</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003448</td>\n",
       "      <td>-0.019462</td>\n",
       "      <td>-0.011014</td>\n",
       "      <td>0.010395</td>\n",
       "      <td>-0.003951</td>\n",
       "      <td>-0.048172</td>\n",
       "      <td>0.004431</td>\n",
       "      <td>-0.008512</td>\n",
       "      <td>0.057590</td>\n",
       "      <td>-0.013224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC1</th>\n",
       "      <td>-0.185272</td>\n",
       "      <td>-0.018505</td>\n",
       "      <td>-0.124613</td>\n",
       "      <td>-0.009987</td>\n",
       "      <td>-0.020965</td>\n",
       "      <td>-0.001843</td>\n",
       "      <td>0.045386</td>\n",
       "      <td>0.049865</td>\n",
       "      <td>-0.025050</td>\n",
       "      <td>0.043105</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015658</td>\n",
       "      <td>-0.012999</td>\n",
       "      <td>-0.028868</td>\n",
       "      <td>-0.029042</td>\n",
       "      <td>-0.017439</td>\n",
       "      <td>-0.000964</td>\n",
       "      <td>0.073216</td>\n",
       "      <td>0.004413</td>\n",
       "      <td>-0.062048</td>\n",
       "      <td>-0.016474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC33</th>\n",
       "      <td>-0.051700</td>\n",
       "      <td>-0.019953</td>\n",
       "      <td>-0.014658</td>\n",
       "      <td>0.023568</td>\n",
       "      <td>0.006289</td>\n",
       "      <td>-0.059643</td>\n",
       "      <td>-0.030274</td>\n",
       "      <td>-0.036246</td>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.019598</td>\n",
       "      <td>...</td>\n",
       "      <td>0.038043</td>\n",
       "      <td>0.014948</td>\n",
       "      <td>0.007622</td>\n",
       "      <td>0.080504</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>0.112427</td>\n",
       "      <td>-0.010666</td>\n",
       "      <td>0.016750</td>\n",
       "      <td>-0.038729</td>\n",
       "      <td>0.007993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC24</th>\n",
       "      <td>0.367531</td>\n",
       "      <td>-0.078163</td>\n",
       "      <td>-0.136711</td>\n",
       "      <td>-0.001511</td>\n",
       "      <td>0.001794</td>\n",
       "      <td>0.028835</td>\n",
       "      <td>0.001717</td>\n",
       "      <td>-0.008521</td>\n",
       "      <td>0.005482</td>\n",
       "      <td>0.015830</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020396</td>\n",
       "      <td>0.006605</td>\n",
       "      <td>-0.052944</td>\n",
       "      <td>-0.015676</td>\n",
       "      <td>0.037017</td>\n",
       "      <td>0.009528</td>\n",
       "      <td>-0.024909</td>\n",
       "      <td>-0.002041</td>\n",
       "      <td>-0.068576</td>\n",
       "      <td>0.004920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC2</th>\n",
       "      <td>0.000668</td>\n",
       "      <td>-0.074318</td>\n",
       "      <td>-0.050300</td>\n",
       "      <td>0.007543</td>\n",
       "      <td>0.011789</td>\n",
       "      <td>0.026008</td>\n",
       "      <td>0.047217</td>\n",
       "      <td>0.050880</td>\n",
       "      <td>0.011681</td>\n",
       "      <td>-0.001224</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>0.005750</td>\n",
       "      <td>0.021135</td>\n",
       "      <td>-0.020320</td>\n",
       "      <td>-0.007507</td>\n",
       "      <td>-0.043512</td>\n",
       "      <td>0.016801</td>\n",
       "      <td>0.012265</td>\n",
       "      <td>-0.093543</td>\n",
       "      <td>0.002162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC32</th>\n",
       "      <td>-0.239073</td>\n",
       "      <td>-0.037706</td>\n",
       "      <td>-0.101855</td>\n",
       "      <td>0.003938</td>\n",
       "      <td>0.007683</td>\n",
       "      <td>-0.097813</td>\n",
       "      <td>-0.051766</td>\n",
       "      <td>-0.042184</td>\n",
       "      <td>0.001993</td>\n",
       "      <td>0.030119</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007713</td>\n",
       "      <td>0.004392</td>\n",
       "      <td>0.028280</td>\n",
       "      <td>-0.002757</td>\n",
       "      <td>-0.007800</td>\n",
       "      <td>-0.028650</td>\n",
       "      <td>0.006550</td>\n",
       "      <td>-0.004309</td>\n",
       "      <td>-0.036865</td>\n",
       "      <td>0.002201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC6</th>\n",
       "      <td>-0.072137</td>\n",
       "      <td>0.034161</td>\n",
       "      <td>0.060950</td>\n",
       "      <td>0.007441</td>\n",
       "      <td>-0.002258</td>\n",
       "      <td>-0.361454</td>\n",
       "      <td>-0.016970</td>\n",
       "      <td>-0.009341</td>\n",
       "      <td>0.007113</td>\n",
       "      <td>-0.047996</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011951</td>\n",
       "      <td>0.006808</td>\n",
       "      <td>0.032534</td>\n",
       "      <td>0.033435</td>\n",
       "      <td>0.002047</td>\n",
       "      <td>0.136396</td>\n",
       "      <td>-0.025411</td>\n",
       "      <td>0.002968</td>\n",
       "      <td>0.083020</td>\n",
       "      <td>0.008100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC9</th>\n",
       "      <td>0.128207</td>\n",
       "      <td>-0.022174</td>\n",
       "      <td>-0.082979</td>\n",
       "      <td>0.009797</td>\n",
       "      <td>-0.001953</td>\n",
       "      <td>0.054362</td>\n",
       "      <td>-0.020570</td>\n",
       "      <td>-0.022754</td>\n",
       "      <td>-0.008278</td>\n",
       "      <td>0.035694</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011730</td>\n",
       "      <td>0.007794</td>\n",
       "      <td>0.026916</td>\n",
       "      <td>0.025499</td>\n",
       "      <td>0.055581</td>\n",
       "      <td>-0.062498</td>\n",
       "      <td>-0.078428</td>\n",
       "      <td>0.004845</td>\n",
       "      <td>-0.071234</td>\n",
       "      <td>0.008117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC7</th>\n",
       "      <td>-0.100963</td>\n",
       "      <td>-0.033207</td>\n",
       "      <td>0.025519</td>\n",
       "      <td>0.017866</td>\n",
       "      <td>0.015301</td>\n",
       "      <td>-0.243088</td>\n",
       "      <td>-0.033744</td>\n",
       "      <td>-0.030470</td>\n",
       "      <td>0.019879</td>\n",
       "      <td>0.000760</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003207</td>\n",
       "      <td>0.011614</td>\n",
       "      <td>-0.026872</td>\n",
       "      <td>-0.005591</td>\n",
       "      <td>-0.049099</td>\n",
       "      <td>0.108010</td>\n",
       "      <td>-0.001399</td>\n",
       "      <td>0.020721</td>\n",
       "      <td>-0.068408</td>\n",
       "      <td>0.007586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC14</th>\n",
       "      <td>0.321346</td>\n",
       "      <td>0.009518</td>\n",
       "      <td>0.177112</td>\n",
       "      <td>-0.005440</td>\n",
       "      <td>-0.002732</td>\n",
       "      <td>-0.011383</td>\n",
       "      <td>-0.021534</td>\n",
       "      <td>-0.016535</td>\n",
       "      <td>-0.007470</td>\n",
       "      <td>-0.015799</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003768</td>\n",
       "      <td>-0.015527</td>\n",
       "      <td>-0.049301</td>\n",
       "      <td>-0.014735</td>\n",
       "      <td>-0.101273</td>\n",
       "      <td>0.047315</td>\n",
       "      <td>0.015798</td>\n",
       "      <td>-0.005740</td>\n",
       "      <td>0.002527</td>\n",
       "      <td>-0.007190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC4</th>\n",
       "      <td>-0.013300</td>\n",
       "      <td>-0.028283</td>\n",
       "      <td>-0.075141</td>\n",
       "      <td>0.014726</td>\n",
       "      <td>0.013393</td>\n",
       "      <td>-0.137686</td>\n",
       "      <td>-0.021528</td>\n",
       "      <td>-0.012555</td>\n",
       "      <td>0.011184</td>\n",
       "      <td>-0.024851</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010287</td>\n",
       "      <td>0.004172</td>\n",
       "      <td>0.092154</td>\n",
       "      <td>-0.003127</td>\n",
       "      <td>-0.003586</td>\n",
       "      <td>-0.014331</td>\n",
       "      <td>-0.027642</td>\n",
       "      <td>-0.024996</td>\n",
       "      <td>-0.000793</td>\n",
       "      <td>-0.003996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC8</th>\n",
       "      <td>-0.047033</td>\n",
       "      <td>0.054066</td>\n",
       "      <td>0.233897</td>\n",
       "      <td>-0.014562</td>\n",
       "      <td>-0.009978</td>\n",
       "      <td>0.553997</td>\n",
       "      <td>-0.071840</td>\n",
       "      <td>-0.082075</td>\n",
       "      <td>-0.008873</td>\n",
       "      <td>-0.042517</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004842</td>\n",
       "      <td>-0.012249</td>\n",
       "      <td>-0.077975</td>\n",
       "      <td>0.006352</td>\n",
       "      <td>-0.027064</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>0.072843</td>\n",
       "      <td>-0.015010</td>\n",
       "      <td>0.120930</td>\n",
       "      <td>-0.003968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC31</th>\n",
       "      <td>0.064535</td>\n",
       "      <td>-0.009429</td>\n",
       "      <td>-0.159236</td>\n",
       "      <td>-0.020531</td>\n",
       "      <td>-0.014778</td>\n",
       "      <td>0.178947</td>\n",
       "      <td>0.048282</td>\n",
       "      <td>0.051457</td>\n",
       "      <td>-0.013662</td>\n",
       "      <td>-0.001548</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014197</td>\n",
       "      <td>-0.002174</td>\n",
       "      <td>-0.001275</td>\n",
       "      <td>0.022172</td>\n",
       "      <td>0.026159</td>\n",
       "      <td>0.015689</td>\n",
       "      <td>0.002319</td>\n",
       "      <td>0.014855</td>\n",
       "      <td>0.050391</td>\n",
       "      <td>0.003615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC34</th>\n",
       "      <td>0.014729</td>\n",
       "      <td>-0.022557</td>\n",
       "      <td>-0.156807</td>\n",
       "      <td>-0.014083</td>\n",
       "      <td>-0.013435</td>\n",
       "      <td>0.041562</td>\n",
       "      <td>0.027163</td>\n",
       "      <td>0.026322</td>\n",
       "      <td>-0.015152</td>\n",
       "      <td>0.037280</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002893</td>\n",
       "      <td>-0.006823</td>\n",
       "      <td>-0.019377</td>\n",
       "      <td>-0.000236</td>\n",
       "      <td>0.024341</td>\n",
       "      <td>-0.035079</td>\n",
       "      <td>0.005337</td>\n",
       "      <td>0.005971</td>\n",
       "      <td>-0.049483</td>\n",
       "      <td>-0.004872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC17</th>\n",
       "      <td>0.192437</td>\n",
       "      <td>0.009609</td>\n",
       "      <td>0.151587</td>\n",
       "      <td>0.000932</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>-0.054660</td>\n",
       "      <td>-0.002844</td>\n",
       "      <td>-0.009741</td>\n",
       "      <td>0.005733</td>\n",
       "      <td>-0.048301</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017496</td>\n",
       "      <td>-0.002765</td>\n",
       "      <td>-0.032543</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>0.015521</td>\n",
       "      <td>-0.008679</td>\n",
       "      <td>0.053111</td>\n",
       "      <td>0.008933</td>\n",
       "      <td>-0.041076</td>\n",
       "      <td>-0.005051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC15</th>\n",
       "      <td>-0.046574</td>\n",
       "      <td>-0.066867</td>\n",
       "      <td>0.031460</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>-0.001906</td>\n",
       "      <td>0.304731</td>\n",
       "      <td>-0.045656</td>\n",
       "      <td>-0.021781</td>\n",
       "      <td>-0.001383</td>\n",
       "      <td>-0.035326</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031126</td>\n",
       "      <td>-0.007064</td>\n",
       "      <td>0.080796</td>\n",
       "      <td>-0.038302</td>\n",
       "      <td>-0.052324</td>\n",
       "      <td>0.054879</td>\n",
       "      <td>-0.138246</td>\n",
       "      <td>-0.006459</td>\n",
       "      <td>0.015680</td>\n",
       "      <td>0.000427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC35</th>\n",
       "      <td>-0.001325</td>\n",
       "      <td>-0.025378</td>\n",
       "      <td>-0.069678</td>\n",
       "      <td>0.022180</td>\n",
       "      <td>-0.003749</td>\n",
       "      <td>-0.072834</td>\n",
       "      <td>-0.004113</td>\n",
       "      <td>-0.026442</td>\n",
       "      <td>-0.014596</td>\n",
       "      <td>-0.001603</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006482</td>\n",
       "      <td>0.009019</td>\n",
       "      <td>-0.074357</td>\n",
       "      <td>-0.000288</td>\n",
       "      <td>-0.033305</td>\n",
       "      <td>0.023689</td>\n",
       "      <td>0.055107</td>\n",
       "      <td>0.004922</td>\n",
       "      <td>-0.058378</td>\n",
       "      <td>0.007925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC10</th>\n",
       "      <td>-0.026487</td>\n",
       "      <td>0.008262</td>\n",
       "      <td>0.179626</td>\n",
       "      <td>-0.016608</td>\n",
       "      <td>-0.023543</td>\n",
       "      <td>-0.228798</td>\n",
       "      <td>0.025300</td>\n",
       "      <td>0.033793</td>\n",
       "      <td>-0.032265</td>\n",
       "      <td>-0.011384</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.030009</td>\n",
       "      <td>-0.015418</td>\n",
       "      <td>-0.126470</td>\n",
       "      <td>-0.013341</td>\n",
       "      <td>0.004777</td>\n",
       "      <td>-0.049852</td>\n",
       "      <td>-0.016910</td>\n",
       "      <td>0.014048</td>\n",
       "      <td>-0.064023</td>\n",
       "      <td>-0.002321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC21</th>\n",
       "      <td>0.515822</td>\n",
       "      <td>-0.005165</td>\n",
       "      <td>0.007256</td>\n",
       "      <td>0.001169</td>\n",
       "      <td>-0.012987</td>\n",
       "      <td>0.013008</td>\n",
       "      <td>-0.000266</td>\n",
       "      <td>0.024363</td>\n",
       "      <td>-0.024487</td>\n",
       "      <td>0.022926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014976</td>\n",
       "      <td>0.002098</td>\n",
       "      <td>-0.026459</td>\n",
       "      <td>0.009043</td>\n",
       "      <td>-0.036775</td>\n",
       "      <td>0.009511</td>\n",
       "      <td>0.027508</td>\n",
       "      <td>-0.009576</td>\n",
       "      <td>-0.018066</td>\n",
       "      <td>-0.002493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC28</th>\n",
       "      <td>-0.161869</td>\n",
       "      <td>-0.009141</td>\n",
       "      <td>0.078020</td>\n",
       "      <td>-0.004289</td>\n",
       "      <td>-0.005797</td>\n",
       "      <td>0.127818</td>\n",
       "      <td>0.056186</td>\n",
       "      <td>0.085211</td>\n",
       "      <td>-0.013051</td>\n",
       "      <td>0.006585</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015562</td>\n",
       "      <td>0.000780</td>\n",
       "      <td>-0.134436</td>\n",
       "      <td>0.010222</td>\n",
       "      <td>-0.019741</td>\n",
       "      <td>-0.021512</td>\n",
       "      <td>0.104383</td>\n",
       "      <td>0.018890</td>\n",
       "      <td>-0.018417</td>\n",
       "      <td>-0.001353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC23</th>\n",
       "      <td>-0.120955</td>\n",
       "      <td>-0.062796</td>\n",
       "      <td>0.213229</td>\n",
       "      <td>0.003885</td>\n",
       "      <td>0.000560</td>\n",
       "      <td>-0.186510</td>\n",
       "      <td>0.030863</td>\n",
       "      <td>0.035922</td>\n",
       "      <td>-0.005717</td>\n",
       "      <td>0.005686</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009423</td>\n",
       "      <td>0.003035</td>\n",
       "      <td>-0.147413</td>\n",
       "      <td>0.004058</td>\n",
       "      <td>-0.041675</td>\n",
       "      <td>0.050647</td>\n",
       "      <td>0.091695</td>\n",
       "      <td>0.001286</td>\n",
       "      <td>0.018615</td>\n",
       "      <td>-0.000856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC25</th>\n",
       "      <td>0.206507</td>\n",
       "      <td>-0.000722</td>\n",
       "      <td>0.018294</td>\n",
       "      <td>-0.001228</td>\n",
       "      <td>-0.000281</td>\n",
       "      <td>-0.104022</td>\n",
       "      <td>0.013958</td>\n",
       "      <td>0.005190</td>\n",
       "      <td>-0.007229</td>\n",
       "      <td>-0.018290</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000485</td>\n",
       "      <td>0.000744</td>\n",
       "      <td>-0.004894</td>\n",
       "      <td>-0.016388</td>\n",
       "      <td>-0.014157</td>\n",
       "      <td>-0.032413</td>\n",
       "      <td>0.147584</td>\n",
       "      <td>-0.019944</td>\n",
       "      <td>-0.047566</td>\n",
       "      <td>-0.001376</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36 rows Ã— 223 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Texpi     ALogP    ALogp2       AMR      apol     nAcid  naAromAtom  \\\n",
       "PC22 -0.031134  0.030326  0.029669  0.114115  0.115273 -0.010320   -0.029310   \n",
       "PC26  0.010533  0.008850  0.010250 -0.002350 -0.004319 -0.001354    0.021178   \n",
       "PC18  0.051618 -0.196747  0.021007 -0.016240 -0.003918  0.019890   -0.137567   \n",
       "PC5   0.100162 -0.031766  0.043603  0.046351  0.021389  0.057670    0.202798   \n",
       "PC19  0.013156  0.169669  0.171723  0.068874  0.071087  0.008856    0.064905   \n",
       "PC3  -0.038630  0.022768 -0.123096  0.029593  0.026201  0.075240   -0.064603   \n",
       "PC20  0.074036  0.065755  0.129346  0.029632  0.037801 -0.014044    0.073475   \n",
       "PC11 -0.027987 -0.031357 -0.119799 -0.006994 -0.010037 -0.038942   -0.035307   \n",
       "PC12  0.075948  0.004944  0.053060 -0.003113  0.005771  0.138356    0.012995   \n",
       "PC13 -0.106433  0.033448 -0.016095  0.010013 -0.000685  0.189053   -0.025590   \n",
       "PC16 -0.024160 -0.037733 -0.082037  0.000704 -0.001584  0.000119    0.013810   \n",
       "PC27  0.040169  0.094654  0.176209 -0.001935 -0.000090 -0.023089   -0.082017   \n",
       "PC30 -0.029679 -0.014519 -0.068333  0.000469 -0.004482  0.115438    0.060124   \n",
       "PC36  0.035436 -0.022509  0.073719  0.000005  0.013214 -0.134064   -0.073024   \n",
       "PC29 -0.098841  0.074548 -0.006581 -0.013119 -0.016133  0.088695    0.033715   \n",
       "PC1  -0.185272 -0.018505 -0.124613 -0.009987 -0.020965 -0.001843    0.045386   \n",
       "PC33 -0.051700 -0.019953 -0.014658  0.023568  0.006289 -0.059643   -0.030274   \n",
       "PC24  0.367531 -0.078163 -0.136711 -0.001511  0.001794  0.028835    0.001717   \n",
       "PC2   0.000668 -0.074318 -0.050300  0.007543  0.011789  0.026008    0.047217   \n",
       "PC32 -0.239073 -0.037706 -0.101855  0.003938  0.007683 -0.097813   -0.051766   \n",
       "PC6  -0.072137  0.034161  0.060950  0.007441 -0.002258 -0.361454   -0.016970   \n",
       "PC9   0.128207 -0.022174 -0.082979  0.009797 -0.001953  0.054362   -0.020570   \n",
       "PC7  -0.100963 -0.033207  0.025519  0.017866  0.015301 -0.243088   -0.033744   \n",
       "PC14  0.321346  0.009518  0.177112 -0.005440 -0.002732 -0.011383   -0.021534   \n",
       "PC4  -0.013300 -0.028283 -0.075141  0.014726  0.013393 -0.137686   -0.021528   \n",
       "PC8  -0.047033  0.054066  0.233897 -0.014562 -0.009978  0.553997   -0.071840   \n",
       "PC31  0.064535 -0.009429 -0.159236 -0.020531 -0.014778  0.178947    0.048282   \n",
       "PC34  0.014729 -0.022557 -0.156807 -0.014083 -0.013435  0.041562    0.027163   \n",
       "PC17  0.192437  0.009609  0.151587  0.000932  0.000218 -0.054660   -0.002844   \n",
       "PC15 -0.046574 -0.066867  0.031460  0.002200 -0.001906  0.304731   -0.045656   \n",
       "PC35 -0.001325 -0.025378 -0.069678  0.022180 -0.003749 -0.072834   -0.004113   \n",
       "PC10 -0.026487  0.008262  0.179626 -0.016608 -0.023543 -0.228798    0.025300   \n",
       "PC21  0.515822 -0.005165  0.007256  0.001169 -0.012987  0.013008   -0.000266   \n",
       "PC28 -0.161869 -0.009141  0.078020 -0.004289 -0.005797  0.127818    0.056186   \n",
       "PC23 -0.120955 -0.062796  0.213229  0.003885  0.000560 -0.186510    0.030863   \n",
       "PC25  0.206507 -0.000722  0.018294 -0.001228 -0.000281 -0.104022    0.013958   \n",
       "\n",
       "      nAromBond     nAtom     ATSc1  ...        MW    WTPT-1    WTPT-2  \\\n",
       "PC22  -0.028832  0.114519  0.052669  ...  0.101812  0.115455  0.064667   \n",
       "PC26   0.022900 -0.004386 -0.006872  ...  0.069261 -0.012309  0.096491   \n",
       "PC18  -0.136193  0.017040  0.199363  ...  0.022298  0.006382 -0.075486   \n",
       "PC5    0.203425  0.009061  0.114939  ...  0.072590  0.061656  0.090736   \n",
       "PC19   0.063447  0.075688 -0.055343  ...  0.063525  0.028867  0.056302   \n",
       "PC3   -0.062018  0.029834  0.011610  ... -0.035915  0.010416 -0.123941   \n",
       "PC20   0.070509  0.040948 -0.033702  ... -0.069635  0.018906 -0.120407   \n",
       "PC11  -0.038564 -0.012992 -0.002797  ... -0.015015 -0.010449 -0.052940   \n",
       "PC12   0.019829  0.015674 -0.013816  ... -0.019384  0.013657  0.028088   \n",
       "PC13  -0.023749 -0.008754 -0.007759  ...  0.012833  0.015194 -0.008154   \n",
       "PC16   0.013108 -0.001437 -0.001574  ... -0.006637 -0.000595 -0.014606   \n",
       "PC27  -0.085205 -0.004987  0.074251  ...  0.002445  0.005331  0.025443   \n",
       "PC30   0.066535 -0.008399 -0.051195  ...  0.004233 -0.008705 -0.042696   \n",
       "PC36  -0.073349  0.020417 -0.043346  ... -0.004885 -0.005689  0.013212   \n",
       "PC29   0.037289 -0.025512 -0.027366  ...  0.003448 -0.019462 -0.011014   \n",
       "PC1    0.049865 -0.025050  0.043105  ... -0.015658 -0.012999 -0.028868   \n",
       "PC33  -0.036246 -0.001882 -0.019598  ...  0.038043  0.014948  0.007622   \n",
       "PC24  -0.008521  0.005482  0.015830  ... -0.020396  0.006605 -0.052944   \n",
       "PC2    0.050880  0.011681 -0.001224  ...  0.000748  0.005750  0.021135   \n",
       "PC32  -0.042184  0.001993  0.030119  ...  0.007713  0.004392  0.028280   \n",
       "PC6   -0.009341  0.007113 -0.047996  ... -0.011951  0.006808  0.032534   \n",
       "PC9   -0.022754 -0.008278  0.035694  ...  0.011730  0.007794  0.026916   \n",
       "PC7   -0.030470  0.019879  0.000760  ...  0.003207  0.011614 -0.026872   \n",
       "PC14  -0.016535 -0.007470 -0.015799  ... -0.003768 -0.015527 -0.049301   \n",
       "PC4   -0.012555  0.011184 -0.024851  ...  0.010287  0.004172  0.092154   \n",
       "PC8   -0.082075 -0.008873 -0.042517  ... -0.004842 -0.012249 -0.077975   \n",
       "PC31   0.051457 -0.013662 -0.001548  ... -0.014197 -0.002174 -0.001275   \n",
       "PC34   0.026322 -0.015152  0.037280  ...  0.002893 -0.006823 -0.019377   \n",
       "PC17  -0.009741  0.005733 -0.048301  ...  0.017496 -0.002765 -0.032543   \n",
       "PC15  -0.021781 -0.001383 -0.035326  ... -0.031126 -0.007064  0.080796   \n",
       "PC35  -0.026442 -0.014596 -0.001603  ...  0.006482  0.009019 -0.074357   \n",
       "PC10   0.033793 -0.032265 -0.011384  ... -0.030009 -0.015418 -0.126470   \n",
       "PC21   0.024363 -0.024487  0.022926  ...  0.014976  0.002098 -0.026459   \n",
       "PC28   0.085211 -0.013051  0.006585  ...  0.015562  0.000780 -0.134436   \n",
       "PC23   0.035922 -0.005717  0.005686  ...  0.009423  0.003035 -0.147413   \n",
       "PC25   0.005190 -0.007229 -0.018290  ... -0.000485  0.000744 -0.004894   \n",
       "\n",
       "        WTPT-3    WTPT-4    WTPT-5     WPATH      WPOL     XLogP    Zagreb  \n",
       "PC22  0.032302  0.060440 -0.018330  0.103617  0.117898  0.023811  0.117122  \n",
       "PC26  0.133848 -0.005664  0.005569 -0.007815 -0.007042 -0.006046 -0.007859  \n",
       "PC18  0.122665  0.199015  0.005294  0.056777  0.005852 -0.188817 -0.003149  \n",
       "PC5   0.128473  0.064389  0.185328  0.068606  0.021310 -0.029105  0.044390  \n",
       "PC19 -0.024750 -0.046111 -0.050427  0.030127 -0.031660  0.162314 -0.012495  \n",
       "PC3   0.006293 -0.069951  0.210349  0.058728  0.006815  0.005178  0.014053  \n",
       "PC20 -0.075146  0.036866 -0.091467  0.038523  0.024288  0.084629  0.035862  \n",
       "PC11 -0.000013 -0.021083  0.030460 -0.003296 -0.000883 -0.045563 -0.002798  \n",
       "PC12 -0.035190 -0.022426  0.063407  0.027432  0.010967 -0.028877  0.007813  \n",
       "PC13 -0.005839 -0.007580 -0.028162  0.083090 -0.001552  0.021814  0.005351  \n",
       "PC16  0.000973 -0.009761  0.020692  0.014883 -0.003327 -0.054030 -0.000261  \n",
       "PC27 -0.006169  0.024947 -0.063560 -0.002133  0.010923  0.136784  0.001804  \n",
       "PC30 -0.006499 -0.036438  0.099545  0.022315  0.000716 -0.045915 -0.004260  \n",
       "PC36  0.002041 -0.129302  0.177240 -0.021119 -0.018696 -0.001367 -0.002919  \n",
       "PC29  0.010395 -0.003951 -0.048172  0.004431 -0.008512  0.057590 -0.013224  \n",
       "PC1  -0.029042 -0.017439 -0.000964  0.073216  0.004413 -0.062048 -0.016474  \n",
       "PC33  0.080504  0.000394  0.112427 -0.010666  0.016750 -0.038729  0.007993  \n",
       "PC24 -0.015676  0.037017  0.009528 -0.024909 -0.002041 -0.068576  0.004920  \n",
       "PC2  -0.020320 -0.007507 -0.043512  0.016801  0.012265 -0.093543  0.002162  \n",
       "PC32 -0.002757 -0.007800 -0.028650  0.006550 -0.004309 -0.036865  0.002201  \n",
       "PC6   0.033435  0.002047  0.136396 -0.025411  0.002968  0.083020  0.008100  \n",
       "PC9   0.025499  0.055581 -0.062498 -0.078428  0.004845 -0.071234  0.008117  \n",
       "PC7  -0.005591 -0.049099  0.108010 -0.001399  0.020721 -0.068408  0.007586  \n",
       "PC14 -0.014735 -0.101273  0.047315  0.015798 -0.005740  0.002527 -0.007190  \n",
       "PC4  -0.003127 -0.003586 -0.014331 -0.027642 -0.024996 -0.000793 -0.003996  \n",
       "PC8   0.006352 -0.027064  0.044000  0.072843 -0.015010  0.120930 -0.003968  \n",
       "PC31  0.022172  0.026159  0.015689  0.002319  0.014855  0.050391  0.003615  \n",
       "PC34 -0.000236  0.024341 -0.035079  0.005337  0.005971 -0.049483 -0.004872  \n",
       "PC17  0.000240  0.015521 -0.008679  0.053111  0.008933 -0.041076 -0.005051  \n",
       "PC15 -0.038302 -0.052324  0.054879 -0.138246 -0.006459  0.015680  0.000427  \n",
       "PC35 -0.000288 -0.033305  0.023689  0.055107  0.004922 -0.058378  0.007925  \n",
       "PC10 -0.013341  0.004777 -0.049852 -0.016910  0.014048 -0.064023 -0.002321  \n",
       "PC21  0.009043 -0.036775  0.009511  0.027508 -0.009576 -0.018066 -0.002493  \n",
       "PC28  0.010222 -0.019741 -0.021512  0.104383  0.018890 -0.018417 -0.001353  \n",
       "PC23  0.004058 -0.041675  0.050647  0.091695  0.001286  0.018615 -0.000856  \n",
       "PC25 -0.016388 -0.014157 -0.032413  0.147584 -0.019944 -0.047566 -0.001376  \n",
       "\n",
       "[36 rows x 223 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_pcs= pca.components_.shape[0]\n",
    "\n",
    "# get the index of the most important feature on EACH component i.e. largest absolute value\n",
    "# using LIST COMPREHENSION HERE\n",
    "most_important = [np.abs(pca.components_[i]).argmax() for i in range(n_pcs)]\n",
    "\n",
    "initial_feature_names = X.columns\n",
    "\n",
    "# get the names\n",
    "most_important_names = [initial_feature_names[most_important[i]] for i in range(n_pcs)]\n",
    "\n",
    "\n",
    "X_pca_df = pd.DataFrame(X_pca, columns=most_important_names)\n",
    "\n",
    "# using LIST COMPREHENSION HERE AGAIN\n",
    "dic = {'PC{}'.format(i+1): most_important_names[i] for i in range(n_pcs)}\n",
    "\n",
    "# build the dataframe\n",
    "df = pd.DataFrame(sorted(dic.items()))\n",
    "df[1].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(223,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20,\n",
       " 205,\n",
       " 185,\n",
       " 200,\n",
       " 92,\n",
       " 218,\n",
       " 168,\n",
       " 203,\n",
       " 25,\n",
       " 124,\n",
       " 33,\n",
       " 116,\n",
       " 162,\n",
       " 143,\n",
       " 138,\n",
       " 145,\n",
       " 146,\n",
       " 0,\n",
       " 141,\n",
       " 129,\n",
       " 123,\n",
       " 129,\n",
       " 100,\n",
       " 113,\n",
       " 100,\n",
       " 5,\n",
       " 100,\n",
       " 162,\n",
       " 13,\n",
       " 103,\n",
       " 103,\n",
       " 145,\n",
       " 0,\n",
       " 110,\n",
       " 13,\n",
       " 190]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (337, 36) \t Shape of y_train: (337,)\n",
      "Shape of X_test: (113, 36) \t Shape of y_test: (113,)\n",
      "LinearRegression\n",
      "Lasso\n",
      "DecisionTree\n",
      "RandomForest\n",
      "XGBRegressor\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n    return f(**kwargs)\n  File \"c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\sklearn.py\", line 931, in fit\n    train_dmatrix, evals = _wrap_evaluation_matrices(\n  File \"c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\sklearn.py\", line 401, in _wrap_evaluation_matrices\n    train_dmatrix = create_dmatrix(\n  File \"c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\sklearn.py\", line 945, in <lambda>\n    create_dmatrix=lambda **kwargs: DMatrix(nthread=self.n_jobs, **kwargs),\n  File \"c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n    return f(**kwargs)\n  File \"c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py\", line 666, in __init__\n    self.feature_names = feature_names\n  File \"c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py\", line 1035, in feature_names\n    raise ValueError('feature_names must be unique')\nValueError: feature_names must be unique\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\user\\Desktop\\Skin Permeation\\Skin-Permeation\\notebooks\\trials\\3. Trial4.ipynb Cell 28\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/Skin%20Permeation/Skin-Permeation/notebooks/trials/3.%20Trial4.ipynb#X46sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m pca_features \u001b[39m=\u001b[39m train_and_evalute(X_pca_df, y, metric\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mMAPE\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/Skin%20Permeation/Skin-Permeation/notebooks/trials/3.%20Trial4.ipynb#X46sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m pca_features\n",
      "\u001b[1;32mc:\\Users\\user\\Desktop\\Skin Permeation\\Skin-Permeation\\notebooks\\trials\\3. Trial4.ipynb Cell 28\u001b[0m in \u001b[0;36mtrain_and_evalute\u001b[1;34m(X, y, metric)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/Skin%20Permeation/Skin-Permeation/notebooks/trials/3.%20Trial4.ipynb#X46sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m     \u001b[39m# fitting our data\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/Skin%20Permeation/Skin-Permeation/notebooks/trials/3.%20Trial4.ipynb#X46sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m     pipe\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/Skin%20Permeation/Skin-Permeation/notebooks/trials/3.%20Trial4.ipynb#X46sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m     evaluate_model(models_scores_df, i, model_name, pipe, X, y, X_test, y_test)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/Skin%20Permeation/Skin-Permeation/notebooks/trials/3.%20Trial4.ipynb#X46sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m \u001b[39m# selecting top 3 score based on metric\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/Skin%20Permeation/Skin-Permeation/notebooks/trials/3.%20Trial4.ipynb#X46sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m filtered_models_scores_df \u001b[39m=\u001b[39m  models_scores_df\u001b[39m.\u001b[39msort_values(metric)\u001b[39m.\u001b[39miloc[:\u001b[39m3\u001b[39m, :]\n",
      "\u001b[1;32mc:\\Users\\user\\Desktop\\Skin Permeation\\Skin-Permeation\\notebooks\\trials\\3. Trial4.ipynb Cell 28\u001b[0m in \u001b[0;36mevaluate_model\u001b[1;34m(model_df, i, model_name, model, X, y, X_test, y_test)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/Skin%20Permeation/Skin-Permeation/notebooks/trials/3.%20Trial4.ipynb#X46sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/Skin%20Permeation/Skin-Permeation/notebooks/trials/3.%20Trial4.ipynb#X46sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mthis function is for regression takes the model with the data and calculate\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/Skin%20Permeation/Skin-Permeation/notebooks/trials/3.%20Trial4.ipynb#X46sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mthe scores, with cross validation techniques, in addition to MAE, MSE, RMSE, MAPE\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/Skin%20Permeation/Skin-Permeation/notebooks/trials/3.%20Trial4.ipynb#X46sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m:param X_train, X_test, y_train, y_test: data that was used\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/Skin%20Permeation/Skin-Permeation/notebooks/trials/3.%20Trial4.ipynb#X46sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/Skin%20Permeation/Skin-Permeation/notebooks/trials/3.%20Trial4.ipynb#X46sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# cross validation with 5 folds\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/Skin%20Permeation/Skin-Permeation/notebooks/trials/3.%20Trial4.ipynb#X46sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m all_cv_5 \u001b[39m=\u001b[39m cross_val_score(model, X, y, cv\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, scoring\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mneg_mean_absolute_percentage_error\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/Skin%20Permeation/Skin-Permeation/notebooks/trials/3.%20Trial4.ipynb#X46sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m#print(\"all CV 5: {}\".format(all_cv_5))\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/Skin%20Permeation/Skin-Permeation/notebooks/trials/3.%20Trial4.ipynb#X46sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# print(\"Mean Cross-Validation score: {}\".format(all_cv_5.mean()))\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/Skin%20Permeation/Skin-Permeation/notebooks/trials/3.%20Trial4.ipynb#X46sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/Skin%20Permeation/Skin-Permeation/notebooks/trials/3.%20Trial4.ipynb#X46sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# predictions from our model\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/user/Desktop/Skin%20Permeation/Skin-Permeation/notebooks/trials/3.%20Trial4.ipynb#X46sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m predictions \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:515\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[39m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    513\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(estimator, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[1;32m--> 515\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(\n\u001b[0;32m    516\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m    517\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m    518\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    519\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[0;32m    520\u001b[0m     scoring\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m\"\u001b[39;49m: scorer},\n\u001b[0;32m    521\u001b[0m     cv\u001b[39m=\u001b[39;49mcv,\n\u001b[0;32m    522\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    523\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    524\u001b[0m     fit_params\u001b[39m=\u001b[39;49mfit_params,\n\u001b[0;32m    525\u001b[0m     pre_dispatch\u001b[39m=\u001b[39;49mpre_dispatch,\n\u001b[0;32m    526\u001b[0m     error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[0;32m    527\u001b[0m )\n\u001b[0;32m    528\u001b[0m \u001b[39mreturn\u001b[39;00m cv_results[\u001b[39m\"\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:285\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    265\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[0;32m    266\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    268\u001b[0m         clone(estimator),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    282\u001b[0m     \u001b[39mfor\u001b[39;00m train, test \u001b[39min\u001b[39;00m cv\u001b[39m.\u001b[39msplit(X, y, groups)\n\u001b[0;32m    283\u001b[0m )\n\u001b[1;32m--> 285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    287\u001b[0m \u001b[39m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[39mif\u001b[39;00m callable(scoring):\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[39mif\u001b[39;00m num_failed_fits \u001b[39m==\u001b[39m num_fits:\n\u001b[0;32m    361\u001b[0m     all_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[0;32m    362\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mAll the \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIt is very likely that your model is misconfigured.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    364\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou can try to debug the error by setting error_score=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    366\u001b[0m     )\n\u001b[1;32m--> 367\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    369\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    370\u001b[0m     some_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[0;32m    371\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mnum_failed_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed out of a total of \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    372\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe score on these train-test partitions for these parameters\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    377\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n    return f(**kwargs)\n  File \"c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\sklearn.py\", line 931, in fit\n    train_dmatrix, evals = _wrap_evaluation_matrices(\n  File \"c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\sklearn.py\", line 401, in _wrap_evaluation_matrices\n    train_dmatrix = create_dmatrix(\n  File \"c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\sklearn.py\", line 945, in <lambda>\n    create_dmatrix=lambda **kwargs: DMatrix(nthread=self.n_jobs, **kwargs),\n  File \"c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py\", line 532, in inner_f\n    return f(**kwargs)\n  File \"c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py\", line 666, in __init__\n    self.feature_names = feature_names\n  File \"c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py\", line 1035, in feature_names\n    raise ValueError('feature_names must be unique')\nValueError: feature_names must be unique\n"
     ]
    }
   ],
   "source": [
    "pca_features = train_and_evalute(X_pca_df, y, metric=\"MAPE\")\n",
    "pca_features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"ann\"></a>\n",
    "# 4. ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = model_data.drop([\"logkpl\"], axis=1)\n",
    "y = model_data['logkpl']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "\n",
    "tf.keras.layers.Dense(256, input_shape=[X.shape[1]]),\n",
    "tf.keras.layers.Dropout(0.2),\n",
    "tf.keras.layers.Dense(128),\n",
    "tf.keras.layers.Dropout(0.2),\n",
    "tf.keras.layers.Dense(64),\n",
    "tf.keras.layers.Dropout(0.2),\n",
    "tf.keras.layers.Dense(32),\n",
    "tf.keras.layers.Dropout(0.2),\n",
    "tf.keras.layers.Dense(8),\n",
    "tf.keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.0001), loss=\"mean_absolute_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 256)               57344     \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 8)                 264       \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 100,849\n",
      "Trainable params: 100,849\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2500\n",
      "11/11 - 0s - loss: 3.9091 - val_loss: 2.9746 - 360ms/epoch - 33ms/step\n",
      "Epoch 2/2500\n",
      "11/11 - 0s - loss: 3.4759 - val_loss: 2.6915 - 29ms/epoch - 3ms/step\n",
      "Epoch 3/2500\n",
      "11/11 - 0s - loss: 3.3654 - val_loss: 2.6072 - 30ms/epoch - 3ms/step\n",
      "Epoch 4/2500\n",
      "11/11 - 0s - loss: 3.0269 - val_loss: 2.5554 - 32ms/epoch - 3ms/step\n",
      "Epoch 5/2500\n",
      "11/11 - 0s - loss: 2.8466 - val_loss: 2.4987 - 32ms/epoch - 3ms/step\n",
      "Epoch 6/2500\n",
      "11/11 - 0s - loss: 2.8627 - val_loss: 2.4583 - 33ms/epoch - 3ms/step\n",
      "Epoch 7/2500\n",
      "11/11 - 0s - loss: 2.7404 - val_loss: 2.3424 - 30ms/epoch - 3ms/step\n",
      "Epoch 8/2500\n",
      "11/11 - 0s - loss: 2.3637 - val_loss: 2.2188 - 31ms/epoch - 3ms/step\n",
      "Epoch 9/2500\n",
      "11/11 - 0s - loss: 2.5620 - val_loss: 2.2084 - 31ms/epoch - 3ms/step\n",
      "Epoch 10/2500\n",
      "11/11 - 0s - loss: 2.5035 - val_loss: 2.0589 - 30ms/epoch - 3ms/step\n",
      "Epoch 11/2500\n",
      "11/11 - 0s - loss: 2.5770 - val_loss: 1.9591 - 31ms/epoch - 3ms/step\n",
      "Epoch 12/2500\n",
      "11/11 - 0s - loss: 2.3962 - val_loss: 1.9314 - 30ms/epoch - 3ms/step\n",
      "Epoch 13/2500\n",
      "11/11 - 0s - loss: 2.5841 - val_loss: 1.9085 - 31ms/epoch - 3ms/step\n",
      "Epoch 14/2500\n",
      "11/11 - 0s - loss: 2.1893 - val_loss: 1.9227 - 31ms/epoch - 3ms/step\n",
      "Epoch 15/2500\n",
      "11/11 - 0s - loss: 2.0654 - val_loss: 1.8383 - 30ms/epoch - 3ms/step\n",
      "Epoch 16/2500\n",
      "11/11 - 0s - loss: 2.1561 - val_loss: 1.7017 - 37ms/epoch - 3ms/step\n",
      "Epoch 17/2500\n",
      "11/11 - 0s - loss: 2.0833 - val_loss: 1.6293 - 35ms/epoch - 3ms/step\n",
      "Epoch 18/2500\n",
      "11/11 - 0s - loss: 2.1841 - val_loss: 1.5565 - 31ms/epoch - 3ms/step\n",
      "Epoch 19/2500\n",
      "11/11 - 0s - loss: 2.0232 - val_loss: 1.5581 - 31ms/epoch - 3ms/step\n",
      "Epoch 20/2500\n",
      "11/11 - 0s - loss: 1.8360 - val_loss: 1.6239 - 30ms/epoch - 3ms/step\n",
      "Epoch 21/2500\n",
      "11/11 - 0s - loss: 1.8480 - val_loss: 1.5236 - 36ms/epoch - 3ms/step\n",
      "Epoch 22/2500\n",
      "11/11 - 0s - loss: 1.8136 - val_loss: 1.4523 - 32ms/epoch - 3ms/step\n",
      "Epoch 23/2500\n",
      "11/11 - 0s - loss: 1.8758 - val_loss: 1.4691 - 30ms/epoch - 3ms/step\n",
      "Epoch 24/2500\n",
      "11/11 - 0s - loss: 1.7451 - val_loss: 1.4000 - 30ms/epoch - 3ms/step\n",
      "Epoch 25/2500\n",
      "11/11 - 0s - loss: 1.7388 - val_loss: 1.3444 - 31ms/epoch - 3ms/step\n",
      "Epoch 26/2500\n",
      "11/11 - 0s - loss: 1.7363 - val_loss: 1.3882 - 30ms/epoch - 3ms/step\n",
      "Epoch 27/2500\n",
      "11/11 - 0s - loss: 1.6906 - val_loss: 1.2927 - 31ms/epoch - 3ms/step\n",
      "Epoch 28/2500\n",
      "11/11 - 0s - loss: 1.7075 - val_loss: 1.2865 - 30ms/epoch - 3ms/step\n",
      "Epoch 29/2500\n",
      "11/11 - 0s - loss: 1.6139 - val_loss: 1.3008 - 30ms/epoch - 3ms/step\n",
      "Epoch 30/2500\n",
      "11/11 - 0s - loss: 1.6672 - val_loss: 1.2874 - 30ms/epoch - 3ms/step\n",
      "Epoch 31/2500\n",
      "11/11 - 0s - loss: 1.6186 - val_loss: 1.2029 - 30ms/epoch - 3ms/step\n",
      "Epoch 32/2500\n",
      "11/11 - 0s - loss: 1.4186 - val_loss: 1.1908 - 30ms/epoch - 3ms/step\n",
      "Epoch 33/2500\n",
      "11/11 - 0s - loss: 1.5652 - val_loss: 1.2238 - 30ms/epoch - 3ms/step\n",
      "Epoch 34/2500\n",
      "11/11 - 0s - loss: 1.5616 - val_loss: 1.2385 - 30ms/epoch - 3ms/step\n",
      "Epoch 35/2500\n",
      "11/11 - 0s - loss: 1.6068 - val_loss: 1.1269 - 33ms/epoch - 3ms/step\n",
      "Epoch 36/2500\n",
      "11/11 - 0s - loss: 1.6763 - val_loss: 1.1487 - 30ms/epoch - 3ms/step\n",
      "Epoch 37/2500\n",
      "11/11 - 0s - loss: 1.6495 - val_loss: 1.0924 - 31ms/epoch - 3ms/step\n",
      "Epoch 38/2500\n",
      "11/11 - 0s - loss: 1.5489 - val_loss: 1.0405 - 30ms/epoch - 3ms/step\n",
      "Epoch 39/2500\n",
      "11/11 - 0s - loss: 1.6115 - val_loss: 0.9756 - 31ms/epoch - 3ms/step\n",
      "Epoch 40/2500\n",
      "11/11 - 0s - loss: 1.4130 - val_loss: 0.9960 - 33ms/epoch - 3ms/step\n",
      "Epoch 41/2500\n",
      "11/11 - 0s - loss: 1.3886 - val_loss: 0.9648 - 33ms/epoch - 3ms/step\n",
      "Epoch 42/2500\n",
      "11/11 - 0s - loss: 1.3917 - val_loss: 0.9396 - 42ms/epoch - 4ms/step\n",
      "Epoch 43/2500\n",
      "11/11 - 0s - loss: 1.4898 - val_loss: 0.9229 - 36ms/epoch - 3ms/step\n",
      "Epoch 44/2500\n",
      "11/11 - 0s - loss: 1.2705 - val_loss: 0.9604 - 32ms/epoch - 3ms/step\n",
      "Epoch 45/2500\n",
      "11/11 - 0s - loss: 1.4812 - val_loss: 0.9040 - 33ms/epoch - 3ms/step\n",
      "Epoch 46/2500\n",
      "11/11 - 0s - loss: 1.4328 - val_loss: 0.8969 - 30ms/epoch - 3ms/step\n",
      "Epoch 47/2500\n",
      "11/11 - 0s - loss: 1.2350 - val_loss: 0.8833 - 33ms/epoch - 3ms/step\n",
      "Epoch 48/2500\n",
      "11/11 - 0s - loss: 1.3191 - val_loss: 0.8780 - 31ms/epoch - 3ms/step\n",
      "Epoch 49/2500\n",
      "11/11 - 0s - loss: 1.3875 - val_loss: 0.8467 - 32ms/epoch - 3ms/step\n",
      "Epoch 50/2500\n",
      "11/11 - 0s - loss: 1.1987 - val_loss: 0.8510 - 31ms/epoch - 3ms/step\n",
      "Epoch 51/2500\n",
      "11/11 - 0s - loss: 1.3544 - val_loss: 0.8922 - 32ms/epoch - 3ms/step\n",
      "Epoch 52/2500\n",
      "11/11 - 0s - loss: 1.3274 - val_loss: 0.8715 - 33ms/epoch - 3ms/step\n",
      "Epoch 53/2500\n",
      "11/11 - 0s - loss: 1.2043 - val_loss: 0.8643 - 34ms/epoch - 3ms/step\n",
      "Epoch 54/2500\n",
      "11/11 - 0s - loss: 1.2628 - val_loss: 0.8546 - 33ms/epoch - 3ms/step\n",
      "Epoch 55/2500\n",
      "11/11 - 0s - loss: 1.2143 - val_loss: 0.8455 - 31ms/epoch - 3ms/step\n",
      "Epoch 56/2500\n",
      "11/11 - 0s - loss: 1.2190 - val_loss: 0.8374 - 30ms/epoch - 3ms/step\n",
      "Epoch 57/2500\n",
      "11/11 - 0s - loss: 1.1939 - val_loss: 0.7831 - 29ms/epoch - 3ms/step\n",
      "Epoch 58/2500\n",
      "11/11 - 0s - loss: 1.1652 - val_loss: 0.7680 - 30ms/epoch - 3ms/step\n",
      "Epoch 59/2500\n",
      "11/11 - 0s - loss: 1.1971 - val_loss: 0.8056 - 28ms/epoch - 3ms/step\n",
      "Epoch 60/2500\n",
      "11/11 - 0s - loss: 1.1022 - val_loss: 0.7928 - 30ms/epoch - 3ms/step\n",
      "Epoch 61/2500\n",
      "11/11 - 0s - loss: 1.1577 - val_loss: 0.7212 - 30ms/epoch - 3ms/step\n",
      "Epoch 62/2500\n",
      "11/11 - 0s - loss: 1.0834 - val_loss: 0.7323 - 30ms/epoch - 3ms/step\n",
      "Epoch 63/2500\n",
      "11/11 - 0s - loss: 1.2386 - val_loss: 0.7433 - 30ms/epoch - 3ms/step\n",
      "Epoch 64/2500\n",
      "11/11 - 0s - loss: 1.1067 - val_loss: 0.6933 - 28ms/epoch - 3ms/step\n",
      "Epoch 65/2500\n",
      "11/11 - 0s - loss: 1.2918 - val_loss: 0.6910 - 30ms/epoch - 3ms/step\n",
      "Epoch 66/2500\n",
      "11/11 - 0s - loss: 1.1345 - val_loss: 0.7553 - 30ms/epoch - 3ms/step\n",
      "Epoch 67/2500\n",
      "11/11 - 0s - loss: 1.1054 - val_loss: 0.6769 - 29ms/epoch - 3ms/step\n",
      "Epoch 68/2500\n",
      "11/11 - 0s - loss: 1.0153 - val_loss: 0.6870 - 43ms/epoch - 4ms/step\n",
      "Epoch 69/2500\n",
      "11/11 - 0s - loss: 1.0000 - val_loss: 0.6719 - 40ms/epoch - 4ms/step\n",
      "Epoch 70/2500\n",
      "11/11 - 0s - loss: 1.0981 - val_loss: 0.6544 - 32ms/epoch - 3ms/step\n",
      "Epoch 71/2500\n",
      "11/11 - 0s - loss: 1.1154 - val_loss: 0.6864 - 35ms/epoch - 3ms/step\n",
      "Epoch 72/2500\n",
      "11/11 - 0s - loss: 1.0641 - val_loss: 0.7057 - 34ms/epoch - 3ms/step\n",
      "Epoch 73/2500\n",
      "11/11 - 0s - loss: 1.0000 - val_loss: 0.7128 - 34ms/epoch - 3ms/step\n",
      "Epoch 74/2500\n",
      "11/11 - 0s - loss: 1.0468 - val_loss: 0.6686 - 45ms/epoch - 4ms/step\n",
      "Epoch 75/2500\n",
      "11/11 - 0s - loss: 0.9956 - val_loss: 0.6952 - 37ms/epoch - 3ms/step\n",
      "Epoch 76/2500\n",
      "11/11 - 0s - loss: 1.0612 - val_loss: 0.7269 - 42ms/epoch - 4ms/step\n",
      "Epoch 77/2500\n",
      "11/11 - 0s - loss: 1.0969 - val_loss: 0.6646 - 32ms/epoch - 3ms/step\n",
      "Epoch 78/2500\n",
      "11/11 - 0s - loss: 1.1218 - val_loss: 0.6729 - 30ms/epoch - 3ms/step\n",
      "Epoch 79/2500\n",
      "11/11 - 0s - loss: 0.9906 - val_loss: 0.6953 - 31ms/epoch - 3ms/step\n",
      "Epoch 80/2500\n",
      "11/11 - 0s - loss: 0.9982 - val_loss: 0.6772 - 33ms/epoch - 3ms/step\n",
      "Epoch 81/2500\n",
      "11/11 - 0s - loss: 1.0084 - val_loss: 0.6617 - 31ms/epoch - 3ms/step\n",
      "Epoch 82/2500\n",
      "11/11 - 0s - loss: 1.0102 - val_loss: 0.6602 - 38ms/epoch - 3ms/step\n",
      "Epoch 83/2500\n",
      "11/11 - 0s - loss: 0.9799 - val_loss: 0.6655 - 34ms/epoch - 3ms/step\n",
      "Epoch 84/2500\n",
      "11/11 - 0s - loss: 1.0206 - val_loss: 0.6488 - 33ms/epoch - 3ms/step\n",
      "Epoch 85/2500\n",
      "11/11 - 0s - loss: 1.0439 - val_loss: 0.6429 - 31ms/epoch - 3ms/step\n",
      "Epoch 86/2500\n",
      "11/11 - 0s - loss: 1.0193 - val_loss: 0.6361 - 31ms/epoch - 3ms/step\n",
      "Epoch 87/2500\n",
      "11/11 - 0s - loss: 1.0617 - val_loss: 0.6476 - 29ms/epoch - 3ms/step\n",
      "Epoch 88/2500\n",
      "11/11 - 0s - loss: 0.9349 - val_loss: 0.6280 - 31ms/epoch - 3ms/step\n",
      "Epoch 89/2500\n",
      "11/11 - 0s - loss: 0.9620 - val_loss: 0.6153 - 30ms/epoch - 3ms/step\n",
      "Epoch 90/2500\n",
      "11/11 - 0s - loss: 0.9620 - val_loss: 0.6288 - 32ms/epoch - 3ms/step\n",
      "Epoch 91/2500\n",
      "11/11 - 0s - loss: 0.9702 - val_loss: 0.6245 - 30ms/epoch - 3ms/step\n",
      "Epoch 92/2500\n",
      "11/11 - 0s - loss: 0.9166 - val_loss: 0.6251 - 30ms/epoch - 3ms/step\n",
      "Epoch 93/2500\n",
      "11/11 - 0s - loss: 0.8940 - val_loss: 0.6041 - 30ms/epoch - 3ms/step\n",
      "Epoch 94/2500\n",
      "11/11 - 0s - loss: 0.9989 - val_loss: 0.6284 - 29ms/epoch - 3ms/step\n",
      "Epoch 95/2500\n",
      "11/11 - 0s - loss: 0.9910 - val_loss: 0.5805 - 31ms/epoch - 3ms/step\n",
      "Epoch 96/2500\n",
      "11/11 - 0s - loss: 0.9457 - val_loss: 0.5833 - 30ms/epoch - 3ms/step\n",
      "Epoch 97/2500\n",
      "11/11 - 0s - loss: 0.9742 - val_loss: 0.6103 - 30ms/epoch - 3ms/step\n",
      "Epoch 98/2500\n",
      "11/11 - 0s - loss: 0.9199 - val_loss: 0.6248 - 29ms/epoch - 3ms/step\n",
      "Epoch 99/2500\n",
      "11/11 - 0s - loss: 0.9314 - val_loss: 0.6190 - 30ms/epoch - 3ms/step\n",
      "Epoch 100/2500\n",
      "11/11 - 0s - loss: 0.8789 - val_loss: 0.6272 - 30ms/epoch - 3ms/step\n",
      "Epoch 101/2500\n",
      "11/11 - 0s - loss: 0.9058 - val_loss: 0.6362 - 30ms/epoch - 3ms/step\n",
      "Epoch 102/2500\n",
      "11/11 - 0s - loss: 0.8633 - val_loss: 0.6218 - 29ms/epoch - 3ms/step\n",
      "Epoch 103/2500\n",
      "11/11 - 0s - loss: 0.8919 - val_loss: 0.6072 - 43ms/epoch - 4ms/step\n",
      "Epoch 104/2500\n",
      "11/11 - 0s - loss: 0.8929 - val_loss: 0.6147 - 29ms/epoch - 3ms/step\n",
      "Epoch 105/2500\n",
      "11/11 - 0s - loss: 0.9392 - val_loss: 0.5871 - 29ms/epoch - 3ms/step\n",
      "Epoch 106/2500\n",
      "11/11 - 0s - loss: 0.8386 - val_loss: 0.5860 - 30ms/epoch - 3ms/step\n",
      "Epoch 107/2500\n",
      "11/11 - 0s - loss: 0.9003 - val_loss: 0.5632 - 30ms/epoch - 3ms/step\n",
      "Epoch 108/2500\n",
      "11/11 - 0s - loss: 0.9410 - val_loss: 0.5652 - 30ms/epoch - 3ms/step\n",
      "Epoch 109/2500\n",
      "11/11 - 0s - loss: 0.8920 - val_loss: 0.5914 - 30ms/epoch - 3ms/step\n",
      "Epoch 110/2500\n",
      "11/11 - 0s - loss: 0.9599 - val_loss: 0.5869 - 29ms/epoch - 3ms/step\n",
      "Epoch 111/2500\n",
      "11/11 - 0s - loss: 0.9203 - val_loss: 0.5869 - 29ms/epoch - 3ms/step\n",
      "Epoch 112/2500\n",
      "11/11 - 0s - loss: 0.8288 - val_loss: 0.6139 - 30ms/epoch - 3ms/step\n",
      "Epoch 113/2500\n",
      "11/11 - 0s - loss: 0.9072 - val_loss: 0.6152 - 29ms/epoch - 3ms/step\n",
      "Epoch 114/2500\n",
      "11/11 - 0s - loss: 0.8610 - val_loss: 0.5886 - 30ms/epoch - 3ms/step\n",
      "Epoch 115/2500\n",
      "11/11 - 0s - loss: 0.8210 - val_loss: 0.5883 - 31ms/epoch - 3ms/step\n",
      "Epoch 116/2500\n",
      "11/11 - 0s - loss: 0.8529 - val_loss: 0.5824 - 38ms/epoch - 3ms/step\n",
      "Epoch 117/2500\n",
      "11/11 - 0s - loss: 0.8205 - val_loss: 0.5871 - 31ms/epoch - 3ms/step\n",
      "Epoch 118/2500\n",
      "11/11 - 0s - loss: 0.8072 - val_loss: 0.5949 - 29ms/epoch - 3ms/step\n",
      "Epoch 119/2500\n",
      "11/11 - 0s - loss: 0.8465 - val_loss: 0.5621 - 29ms/epoch - 3ms/step\n",
      "Epoch 120/2500\n",
      "11/11 - 0s - loss: 0.8261 - val_loss: 0.5579 - 29ms/epoch - 3ms/step\n",
      "Epoch 121/2500\n",
      "11/11 - 0s - loss: 0.8605 - val_loss: 0.5855 - 31ms/epoch - 3ms/step\n",
      "Epoch 122/2500\n",
      "11/11 - 0s - loss: 0.8409 - val_loss: 0.6169 - 30ms/epoch - 3ms/step\n",
      "Epoch 123/2500\n",
      "11/11 - 0s - loss: 0.8262 - val_loss: 0.5987 - 31ms/epoch - 3ms/step\n",
      "Epoch 124/2500\n",
      "11/11 - 0s - loss: 0.7868 - val_loss: 0.5885 - 32ms/epoch - 3ms/step\n",
      "Epoch 125/2500\n",
      "11/11 - 0s - loss: 0.8577 - val_loss: 0.5947 - 33ms/epoch - 3ms/step\n",
      "Epoch 126/2500\n",
      "11/11 - 0s - loss: 0.8703 - val_loss: 0.5764 - 30ms/epoch - 3ms/step\n",
      "Epoch 127/2500\n",
      "11/11 - 0s - loss: 0.9058 - val_loss: 0.5547 - 30ms/epoch - 3ms/step\n",
      "Epoch 128/2500\n",
      "11/11 - 0s - loss: 0.8426 - val_loss: 0.5648 - 31ms/epoch - 3ms/step\n",
      "Epoch 129/2500\n",
      "11/11 - 0s - loss: 0.8039 - val_loss: 0.5489 - 31ms/epoch - 3ms/step\n",
      "Epoch 130/2500\n",
      "11/11 - 0s - loss: 0.8249 - val_loss: 0.5508 - 30ms/epoch - 3ms/step\n",
      "Epoch 131/2500\n",
      "11/11 - 0s - loss: 0.8153 - val_loss: 0.5632 - 29ms/epoch - 3ms/step\n",
      "Epoch 132/2500\n",
      "11/11 - 0s - loss: 0.8033 - val_loss: 0.5618 - 30ms/epoch - 3ms/step\n",
      "Epoch 133/2500\n",
      "11/11 - 0s - loss: 0.8513 - val_loss: 0.5451 - 30ms/epoch - 3ms/step\n",
      "Epoch 134/2500\n",
      "11/11 - 0s - loss: 0.8086 - val_loss: 0.5375 - 30ms/epoch - 3ms/step\n",
      "Epoch 135/2500\n",
      "11/11 - 0s - loss: 0.8204 - val_loss: 0.5379 - 30ms/epoch - 3ms/step\n",
      "Epoch 136/2500\n",
      "11/11 - 0s - loss: 0.8482 - val_loss: 0.5526 - 38ms/epoch - 3ms/step\n",
      "Epoch 137/2500\n",
      "11/11 - 0s - loss: 0.7651 - val_loss: 0.5449 - 40ms/epoch - 4ms/step\n",
      "Epoch 138/2500\n",
      "11/11 - 0s - loss: 0.7328 - val_loss: 0.5374 - 32ms/epoch - 3ms/step\n",
      "Epoch 139/2500\n",
      "11/11 - 0s - loss: 0.8155 - val_loss: 0.5391 - 30ms/epoch - 3ms/step\n",
      "Epoch 140/2500\n",
      "11/11 - 0s - loss: 0.7720 - val_loss: 0.5546 - 30ms/epoch - 3ms/step\n",
      "Epoch 141/2500\n",
      "11/11 - 0s - loss: 0.8461 - val_loss: 0.5460 - 29ms/epoch - 3ms/step\n",
      "Epoch 142/2500\n",
      "11/11 - 0s - loss: 0.7887 - val_loss: 0.5245 - 30ms/epoch - 3ms/step\n",
      "Epoch 143/2500\n",
      "11/11 - 0s - loss: 0.8290 - val_loss: 0.5132 - 29ms/epoch - 3ms/step\n",
      "Epoch 144/2500\n",
      "11/11 - 0s - loss: 0.7445 - val_loss: 0.5372 - 30ms/epoch - 3ms/step\n",
      "Epoch 145/2500\n",
      "11/11 - 0s - loss: 0.8300 - val_loss: 0.5557 - 31ms/epoch - 3ms/step\n",
      "Epoch 146/2500\n",
      "11/11 - 0s - loss: 0.7767 - val_loss: 0.5499 - 29ms/epoch - 3ms/step\n",
      "Epoch 147/2500\n",
      "11/11 - 0s - loss: 0.8309 - val_loss: 0.5508 - 30ms/epoch - 3ms/step\n",
      "Epoch 148/2500\n",
      "11/11 - 0s - loss: 0.7547 - val_loss: 0.5521 - 29ms/epoch - 3ms/step\n",
      "Epoch 149/2500\n",
      "11/11 - 0s - loss: 0.7553 - val_loss: 0.5554 - 30ms/epoch - 3ms/step\n",
      "Epoch 150/2500\n",
      "11/11 - 0s - loss: 0.7850 - val_loss: 0.5506 - 33ms/epoch - 3ms/step\n",
      "Epoch 151/2500\n",
      "11/11 - 0s - loss: 0.7165 - val_loss: 0.5283 - 35ms/epoch - 3ms/step\n",
      "Epoch 152/2500\n",
      "11/11 - 0s - loss: 0.8125 - val_loss: 0.5383 - 32ms/epoch - 3ms/step\n",
      "Epoch 153/2500\n",
      "11/11 - 0s - loss: 0.7121 - val_loss: 0.5161 - 30ms/epoch - 3ms/step\n",
      "Epoch 154/2500\n",
      "11/11 - 0s - loss: 0.7470 - val_loss: 0.5207 - 29ms/epoch - 3ms/step\n",
      "Epoch 155/2500\n",
      "11/11 - 0s - loss: 0.7652 - val_loss: 0.5073 - 30ms/epoch - 3ms/step\n",
      "Epoch 156/2500\n",
      "11/11 - 0s - loss: 0.7444 - val_loss: 0.4897 - 30ms/epoch - 3ms/step\n",
      "Epoch 157/2500\n",
      "11/11 - 0s - loss: 0.6821 - val_loss: 0.5140 - 31ms/epoch - 3ms/step\n",
      "Epoch 158/2500\n",
      "11/11 - 0s - loss: 0.7470 - val_loss: 0.5255 - 30ms/epoch - 3ms/step\n",
      "Epoch 159/2500\n",
      "11/11 - 0s - loss: 0.7205 - val_loss: 0.5142 - 30ms/epoch - 3ms/step\n",
      "Epoch 160/2500\n",
      "11/11 - 0s - loss: 0.7222 - val_loss: 0.5010 - 29ms/epoch - 3ms/step\n",
      "Epoch 161/2500\n",
      "11/11 - 0s - loss: 0.7436 - val_loss: 0.5215 - 30ms/epoch - 3ms/step\n",
      "Epoch 162/2500\n",
      "11/11 - 0s - loss: 0.7411 - val_loss: 0.5349 - 30ms/epoch - 3ms/step\n",
      "Epoch 163/2500\n",
      "11/11 - 0s - loss: 0.8319 - val_loss: 0.5118 - 32ms/epoch - 3ms/step\n",
      "Epoch 164/2500\n",
      "11/11 - 0s - loss: 0.7618 - val_loss: 0.5147 - 30ms/epoch - 3ms/step\n",
      "Epoch 165/2500\n",
      "11/11 - 0s - loss: 0.7111 - val_loss: 0.5158 - 30ms/epoch - 3ms/step\n",
      "Epoch 166/2500\n",
      "11/11 - 0s - loss: 0.7548 - val_loss: 0.5048 - 29ms/epoch - 3ms/step\n",
      "Epoch 167/2500\n",
      "11/11 - 0s - loss: 0.7352 - val_loss: 0.5372 - 29ms/epoch - 3ms/step\n",
      "Epoch 168/2500\n",
      "11/11 - 0s - loss: 0.7212 - val_loss: 0.5050 - 41ms/epoch - 4ms/step\n",
      "Epoch 169/2500\n",
      "11/11 - 0s - loss: 0.7308 - val_loss: 0.5037 - 30ms/epoch - 3ms/step\n",
      "Epoch 170/2500\n",
      "11/11 - 0s - loss: 0.7397 - val_loss: 0.4990 - 29ms/epoch - 3ms/step\n",
      "Epoch 171/2500\n",
      "11/11 - 0s - loss: 0.6696 - val_loss: 0.4922 - 29ms/epoch - 3ms/step\n",
      "Epoch 172/2500\n",
      "11/11 - 0s - loss: 0.7216 - val_loss: 0.5014 - 30ms/epoch - 3ms/step\n",
      "Epoch 173/2500\n",
      "11/11 - 0s - loss: 0.7213 - val_loss: 0.5052 - 30ms/epoch - 3ms/step\n",
      "Epoch 174/2500\n",
      "11/11 - 0s - loss: 0.7484 - val_loss: 0.5051 - 31ms/epoch - 3ms/step\n",
      "Epoch 175/2500\n",
      "11/11 - 0s - loss: 0.6981 - val_loss: 0.5260 - 31ms/epoch - 3ms/step\n",
      "Epoch 176/2500\n",
      "11/11 - 0s - loss: 0.7478 - val_loss: 0.5149 - 31ms/epoch - 3ms/step\n",
      "Epoch 177/2500\n",
      "11/11 - 0s - loss: 0.7848 - val_loss: 0.5194 - 29ms/epoch - 3ms/step\n",
      "Epoch 178/2500\n",
      "11/11 - 0s - loss: 0.7851 - val_loss: 0.5044 - 30ms/epoch - 3ms/step\n",
      "Epoch 179/2500\n",
      "11/11 - 0s - loss: 0.6888 - val_loss: 0.5030 - 30ms/epoch - 3ms/step\n",
      "Epoch 180/2500\n",
      "11/11 - 0s - loss: 0.6810 - val_loss: 0.5092 - 31ms/epoch - 3ms/step\n",
      "Epoch 181/2500\n",
      "11/11 - 0s - loss: 0.7105 - val_loss: 0.5061 - 29ms/epoch - 3ms/step\n",
      "Epoch 182/2500\n",
      "11/11 - 0s - loss: 0.7247 - val_loss: 0.5115 - 29ms/epoch - 3ms/step\n",
      "Epoch 183/2500\n",
      "11/11 - 0s - loss: 0.6952 - val_loss: 0.4937 - 30ms/epoch - 3ms/step\n",
      "Epoch 184/2500\n",
      "11/11 - 0s - loss: 0.7079 - val_loss: 0.4966 - 30ms/epoch - 3ms/step\n",
      "Epoch 185/2500\n",
      "11/11 - 0s - loss: 0.7297 - val_loss: 0.4953 - 29ms/epoch - 3ms/step\n",
      "Epoch 186/2500\n",
      "11/11 - 0s - loss: 0.7175 - val_loss: 0.5045 - 30ms/epoch - 3ms/step\n",
      "Epoch 187/2500\n",
      "11/11 - 0s - loss: 0.7137 - val_loss: 0.4997 - 29ms/epoch - 3ms/step\n",
      "Epoch 188/2500\n",
      "11/11 - 0s - loss: 0.7177 - val_loss: 0.5065 - 31ms/epoch - 3ms/step\n",
      "Epoch 189/2500\n",
      "11/11 - 0s - loss: 0.6532 - val_loss: 0.5190 - 32ms/epoch - 3ms/step\n",
      "Epoch 190/2500\n",
      "11/11 - 0s - loss: 0.6832 - val_loss: 0.5183 - 31ms/epoch - 3ms/step\n",
      "Epoch 191/2500\n",
      "11/11 - 0s - loss: 0.7454 - val_loss: 0.5053 - 29ms/epoch - 3ms/step\n",
      "Epoch 192/2500\n",
      "11/11 - 0s - loss: 0.7057 - val_loss: 0.5021 - 30ms/epoch - 3ms/step\n",
      "Epoch 193/2500\n",
      "11/11 - 0s - loss: 0.6636 - val_loss: 0.4874 - 30ms/epoch - 3ms/step\n",
      "Epoch 194/2500\n",
      "11/11 - 0s - loss: 0.6638 - val_loss: 0.4841 - 30ms/epoch - 3ms/step\n",
      "Epoch 195/2500\n",
      "11/11 - 0s - loss: 0.6863 - val_loss: 0.5056 - 30ms/epoch - 3ms/step\n",
      "Epoch 196/2500\n",
      "11/11 - 0s - loss: 0.6954 - val_loss: 0.5205 - 30ms/epoch - 3ms/step\n",
      "Epoch 197/2500\n",
      "11/11 - 0s - loss: 0.7116 - val_loss: 0.5031 - 29ms/epoch - 3ms/step\n",
      "Epoch 198/2500\n",
      "11/11 - 0s - loss: 0.6602 - val_loss: 0.5033 - 31ms/epoch - 3ms/step\n",
      "Epoch 199/2500\n",
      "11/11 - 0s - loss: 0.6999 - val_loss: 0.4927 - 30ms/epoch - 3ms/step\n",
      "Epoch 200/2500\n",
      "11/11 - 0s - loss: 0.6717 - val_loss: 0.4865 - 30ms/epoch - 3ms/step\n",
      "Epoch 201/2500\n",
      "11/11 - 0s - loss: 0.6788 - val_loss: 0.4969 - 30ms/epoch - 3ms/step\n",
      "Epoch 202/2500\n",
      "11/11 - 0s - loss: 0.6963 - val_loss: 0.5069 - 30ms/epoch - 3ms/step\n",
      "Epoch 203/2500\n",
      "11/11 - 0s - loss: 0.6398 - val_loss: 0.4951 - 29ms/epoch - 3ms/step\n",
      "Epoch 204/2500\n",
      "11/11 - 0s - loss: 0.7160 - val_loss: 0.4932 - 30ms/epoch - 3ms/step\n",
      "Epoch 205/2500\n",
      "11/11 - 0s - loss: 0.7111 - val_loss: 0.4996 - 30ms/epoch - 3ms/step\n",
      "Epoch 206/2500\n",
      "11/11 - 0s - loss: 0.6478 - val_loss: 0.4807 - 34ms/epoch - 3ms/step\n",
      "Epoch 207/2500\n",
      "11/11 - 0s - loss: 0.6473 - val_loss: 0.4826 - 36ms/epoch - 3ms/step\n",
      "Epoch 208/2500\n",
      "11/11 - 0s - loss: 0.7153 - val_loss: 0.5101 - 30ms/epoch - 3ms/step\n",
      "Epoch 209/2500\n",
      "11/11 - 0s - loss: 0.7047 - val_loss: 0.4971 - 30ms/epoch - 3ms/step\n",
      "Epoch 210/2500\n",
      "11/11 - 0s - loss: 0.6587 - val_loss: 0.4835 - 29ms/epoch - 3ms/step\n",
      "Epoch 211/2500\n",
      "11/11 - 0s - loss: 0.7050 - val_loss: 0.4929 - 30ms/epoch - 3ms/step\n",
      "Epoch 212/2500\n",
      "11/11 - 0s - loss: 0.6903 - val_loss: 0.4765 - 30ms/epoch - 3ms/step\n",
      "Epoch 213/2500\n",
      "11/11 - 0s - loss: 0.7239 - val_loss: 0.4925 - 29ms/epoch - 3ms/step\n",
      "Epoch 214/2500\n",
      "11/11 - 0s - loss: 0.6790 - val_loss: 0.4874 - 30ms/epoch - 3ms/step\n",
      "Epoch 215/2500\n",
      "11/11 - 0s - loss: 0.6921 - val_loss: 0.4920 - 29ms/epoch - 3ms/step\n",
      "Epoch 216/2500\n",
      "11/11 - 0s - loss: 0.7297 - val_loss: 0.4741 - 30ms/epoch - 3ms/step\n",
      "Epoch 217/2500\n",
      "11/11 - 0s - loss: 0.6374 - val_loss: 0.4827 - 30ms/epoch - 3ms/step\n",
      "Epoch 218/2500\n",
      "11/11 - 0s - loss: 0.6581 - val_loss: 0.4906 - 29ms/epoch - 3ms/step\n",
      "Epoch 219/2500\n",
      "11/11 - 0s - loss: 0.6830 - val_loss: 0.4752 - 30ms/epoch - 3ms/step\n",
      "Epoch 220/2500\n",
      "11/11 - 0s - loss: 0.6534 - val_loss: 0.4807 - 30ms/epoch - 3ms/step\n",
      "Epoch 221/2500\n",
      "11/11 - 0s - loss: 0.6261 - val_loss: 0.4834 - 30ms/epoch - 3ms/step\n",
      "Epoch 222/2500\n",
      "11/11 - 0s - loss: 0.6949 - val_loss: 0.4812 - 30ms/epoch - 3ms/step\n",
      "Epoch 223/2500\n",
      "11/11 - 0s - loss: 0.7239 - val_loss: 0.5051 - 30ms/epoch - 3ms/step\n",
      "Epoch 224/2500\n",
      "11/11 - 0s - loss: 0.6830 - val_loss: 0.4923 - 30ms/epoch - 3ms/step\n",
      "Epoch 225/2500\n",
      "11/11 - 0s - loss: 0.6495 - val_loss: 0.4740 - 29ms/epoch - 3ms/step\n",
      "Epoch 226/2500\n",
      "11/11 - 0s - loss: 0.6438 - val_loss: 0.4771 - 30ms/epoch - 3ms/step\n",
      "Epoch 227/2500\n",
      "11/11 - 0s - loss: 0.6008 - val_loss: 0.4868 - 30ms/epoch - 3ms/step\n",
      "Epoch 228/2500\n",
      "11/11 - 0s - loss: 0.6965 - val_loss: 0.4936 - 30ms/epoch - 3ms/step\n",
      "Epoch 229/2500\n",
      "11/11 - 0s - loss: 0.6363 - val_loss: 0.4717 - 29ms/epoch - 3ms/step\n",
      "Epoch 230/2500\n",
      "11/11 - 0s - loss: 0.7206 - val_loss: 0.4774 - 29ms/epoch - 3ms/step\n",
      "Epoch 231/2500\n",
      "11/11 - 0s - loss: 0.6519 - val_loss: 0.5051 - 31ms/epoch - 3ms/step\n",
      "Epoch 232/2500\n",
      "11/11 - 0s - loss: 0.6540 - val_loss: 0.4913 - 32ms/epoch - 3ms/step\n",
      "Epoch 233/2500\n",
      "11/11 - 0s - loss: 0.6818 - val_loss: 0.4715 - 32ms/epoch - 3ms/step\n",
      "Epoch 234/2500\n",
      "11/11 - 0s - loss: 0.6441 - val_loss: 0.4869 - 29ms/epoch - 3ms/step\n",
      "Epoch 235/2500\n",
      "11/11 - 0s - loss: 0.6229 - val_loss: 0.4872 - 30ms/epoch - 3ms/step\n",
      "Epoch 236/2500\n",
      "11/11 - 0s - loss: 0.6368 - val_loss: 0.4600 - 30ms/epoch - 3ms/step\n",
      "Epoch 237/2500\n",
      "11/11 - 0s - loss: 0.6596 - val_loss: 0.4663 - 31ms/epoch - 3ms/step\n",
      "Epoch 238/2500\n",
      "11/11 - 0s - loss: 0.6322 - val_loss: 0.4752 - 30ms/epoch - 3ms/step\n",
      "Epoch 239/2500\n",
      "11/11 - 0s - loss: 0.6509 - val_loss: 0.4962 - 29ms/epoch - 3ms/step\n",
      "Epoch 240/2500\n",
      "11/11 - 0s - loss: 0.6713 - val_loss: 0.4932 - 31ms/epoch - 3ms/step\n",
      "Epoch 241/2500\n",
      "11/11 - 0s - loss: 0.6330 - val_loss: 0.4802 - 33ms/epoch - 3ms/step\n",
      "Epoch 242/2500\n",
      "11/11 - 0s - loss: 0.6150 - val_loss: 0.4845 - 31ms/epoch - 3ms/step\n",
      "Epoch 243/2500\n",
      "11/11 - 0s - loss: 0.6342 - val_loss: 0.4890 - 31ms/epoch - 3ms/step\n",
      "Epoch 244/2500\n",
      "11/11 - 0s - loss: 0.5991 - val_loss: 0.4897 - 35ms/epoch - 3ms/step\n",
      "Epoch 245/2500\n",
      "11/11 - 0s - loss: 0.5766 - val_loss: 0.4976 - 36ms/epoch - 3ms/step\n",
      "Epoch 246/2500\n",
      "11/11 - 0s - loss: 0.6408 - val_loss: 0.5048 - 29ms/epoch - 3ms/step\n",
      "Epoch 247/2500\n",
      "11/11 - 0s - loss: 0.6616 - val_loss: 0.4917 - 30ms/epoch - 3ms/step\n",
      "Epoch 248/2500\n",
      "11/11 - 0s - loss: 0.6592 - val_loss: 0.4881 - 31ms/epoch - 3ms/step\n",
      "Epoch 249/2500\n",
      "11/11 - 0s - loss: 0.6011 - val_loss: 0.4873 - 31ms/epoch - 3ms/step\n",
      "Epoch 250/2500\n",
      "11/11 - 0s - loss: 0.6282 - val_loss: 0.4872 - 29ms/epoch - 3ms/step\n",
      "Epoch 251/2500\n",
      "11/11 - 0s - loss: 0.6215 - val_loss: 0.4987 - 30ms/epoch - 3ms/step\n",
      "Epoch 252/2500\n",
      "11/11 - 0s - loss: 0.6349 - val_loss: 0.4971 - 30ms/epoch - 3ms/step\n",
      "Epoch 253/2500\n",
      "11/11 - 0s - loss: 0.5956 - val_loss: 0.4979 - 29ms/epoch - 3ms/step\n",
      "Epoch 254/2500\n",
      "11/11 - 0s - loss: 0.5896 - val_loss: 0.4962 - 30ms/epoch - 3ms/step\n",
      "Epoch 255/2500\n",
      "11/11 - 0s - loss: 0.6177 - val_loss: 0.4900 - 30ms/epoch - 3ms/step\n",
      "Epoch 256/2500\n",
      "11/11 - 0s - loss: 0.6427 - val_loss: 0.4866 - 30ms/epoch - 3ms/step\n",
      "Epoch 257/2500\n",
      "11/11 - 0s - loss: 0.6448 - val_loss: 0.4806 - 31ms/epoch - 3ms/step\n",
      "Epoch 258/2500\n",
      "11/11 - 0s - loss: 0.6451 - val_loss: 0.4912 - 30ms/epoch - 3ms/step\n",
      "Epoch 259/2500\n",
      "11/11 - 0s - loss: 0.6450 - val_loss: 0.5119 - 30ms/epoch - 3ms/step\n",
      "Epoch 260/2500\n",
      "11/11 - 0s - loss: 0.5876 - val_loss: 0.4891 - 29ms/epoch - 3ms/step\n",
      "Epoch 261/2500\n",
      "11/11 - 0s - loss: 0.6299 - val_loss: 0.4795 - 30ms/epoch - 3ms/step\n",
      "Epoch 262/2500\n",
      "11/11 - 0s - loss: 0.6278 - val_loss: 0.4809 - 29ms/epoch - 3ms/step\n",
      "Epoch 263/2500\n",
      "11/11 - 0s - loss: 0.5552 - val_loss: 0.4857 - 30ms/epoch - 3ms/step\n",
      "Epoch 264/2500\n",
      "11/11 - 0s - loss: 0.6570 - val_loss: 0.4826 - 29ms/epoch - 3ms/step\n",
      "Epoch 265/2500\n",
      "11/11 - 0s - loss: 0.6091 - val_loss: 0.4773 - 30ms/epoch - 3ms/step\n",
      "Epoch 266/2500\n",
      "11/11 - 0s - loss: 0.5874 - val_loss: 0.4778 - 30ms/epoch - 3ms/step\n",
      "Epoch 267/2500\n",
      "11/11 - 0s - loss: 0.6132 - val_loss: 0.4817 - 30ms/epoch - 3ms/step\n",
      "Epoch 268/2500\n",
      "11/11 - 0s - loss: 0.6206 - val_loss: 0.4887 - 30ms/epoch - 3ms/step\n",
      "Epoch 269/2500\n",
      "11/11 - 0s - loss: 0.6122 - val_loss: 0.4881 - 30ms/epoch - 3ms/step\n",
      "Epoch 270/2500\n",
      "11/11 - 0s - loss: 0.6002 - val_loss: 0.4956 - 31ms/epoch - 3ms/step\n",
      "Epoch 271/2500\n",
      "11/11 - 0s - loss: 0.6492 - val_loss: 0.4971 - 30ms/epoch - 3ms/step\n",
      "Epoch 272/2500\n",
      "11/11 - 0s - loss: 0.5747 - val_loss: 0.5015 - 30ms/epoch - 3ms/step\n",
      "Epoch 273/2500\n",
      "11/11 - 0s - loss: 0.5909 - val_loss: 0.4848 - 30ms/epoch - 3ms/step\n",
      "Epoch 274/2500\n",
      "11/11 - 0s - loss: 0.6159 - val_loss: 0.4837 - 29ms/epoch - 3ms/step\n",
      "Epoch 275/2500\n",
      "11/11 - 0s - loss: 0.6316 - val_loss: 0.4898 - 30ms/epoch - 3ms/step\n",
      "Epoch 276/2500\n",
      "11/11 - 0s - loss: 0.5854 - val_loss: 0.4796 - 29ms/epoch - 3ms/step\n",
      "Epoch 277/2500\n",
      "11/11 - 0s - loss: 0.6142 - val_loss: 0.4725 - 29ms/epoch - 3ms/step\n",
      "Epoch 278/2500\n",
      "11/11 - 0s - loss: 0.5932 - val_loss: 0.4873 - 43ms/epoch - 4ms/step\n",
      "Epoch 279/2500\n",
      "11/11 - 0s - loss: 0.6488 - val_loss: 0.4928 - 30ms/epoch - 3ms/step\n",
      "Epoch 280/2500\n",
      "11/11 - 0s - loss: 0.6099 - val_loss: 0.4870 - 31ms/epoch - 3ms/step\n",
      "Epoch 281/2500\n",
      "11/11 - 0s - loss: 0.6179 - val_loss: 0.5053 - 29ms/epoch - 3ms/step\n",
      "Epoch 282/2500\n",
      "11/11 - 0s - loss: 0.5700 - val_loss: 0.4881 - 30ms/epoch - 3ms/step\n",
      "Epoch 283/2500\n",
      "11/11 - 0s - loss: 0.6198 - val_loss: 0.4801 - 29ms/epoch - 3ms/step\n",
      "Epoch 284/2500\n",
      "11/11 - 0s - loss: 0.5958 - val_loss: 0.4820 - 30ms/epoch - 3ms/step\n",
      "Epoch 285/2500\n",
      "11/11 - 0s - loss: 0.5958 - val_loss: 0.4751 - 29ms/epoch - 3ms/step\n",
      "Epoch 286/2500\n",
      "11/11 - 0s - loss: 0.5991 - val_loss: 0.4785 - 29ms/epoch - 3ms/step\n",
      "Epoch 287/2500\n",
      "11/11 - 0s - loss: 0.6333 - val_loss: 0.4838 - 29ms/epoch - 3ms/step\n",
      "Epoch 288/2500\n",
      "11/11 - 0s - loss: 0.6240 - val_loss: 0.4837 - 30ms/epoch - 3ms/step\n",
      "Epoch 289/2500\n",
      "11/11 - 0s - loss: 0.6039 - val_loss: 0.4787 - 29ms/epoch - 3ms/step\n",
      "Epoch 290/2500\n",
      "11/11 - 0s - loss: 0.5953 - val_loss: 0.4836 - 29ms/epoch - 3ms/step\n",
      "Epoch 291/2500\n",
      "11/11 - 0s - loss: 0.5849 - val_loss: 0.4839 - 30ms/epoch - 3ms/step\n",
      "Epoch 292/2500\n",
      "11/11 - 0s - loss: 0.5952 - val_loss: 0.4940 - 30ms/epoch - 3ms/step\n",
      "Epoch 293/2500\n",
      "11/11 - 0s - loss: 0.5854 - val_loss: 0.4923 - 29ms/epoch - 3ms/step\n",
      "Epoch 294/2500\n",
      "11/11 - 0s - loss: 0.5900 - val_loss: 0.4925 - 29ms/epoch - 3ms/step\n",
      "Epoch 295/2500\n",
      "11/11 - 0s - loss: 0.5897 - val_loss: 0.4806 - 29ms/epoch - 3ms/step\n",
      "Epoch 296/2500\n",
      "11/11 - 0s - loss: 0.5914 - val_loss: 0.4997 - 29ms/epoch - 3ms/step\n",
      "Epoch 297/2500\n",
      "11/11 - 0s - loss: 0.6340 - val_loss: 0.4886 - 30ms/epoch - 3ms/step\n",
      "Epoch 298/2500\n",
      "11/11 - 0s - loss: 0.5600 - val_loss: 0.4858 - 30ms/epoch - 3ms/step\n",
      "Epoch 299/2500\n",
      "11/11 - 0s - loss: 0.5846 - val_loss: 0.4893 - 30ms/epoch - 3ms/step\n",
      "Epoch 300/2500\n",
      "11/11 - 0s - loss: 0.5911 - val_loss: 0.4883 - 31ms/epoch - 3ms/step\n",
      "Epoch 301/2500\n",
      "11/11 - 0s - loss: 0.6159 - val_loss: 0.4941 - 29ms/epoch - 3ms/step\n",
      "Epoch 302/2500\n",
      "11/11 - 0s - loss: 0.5907 - val_loss: 0.4983 - 29ms/epoch - 3ms/step\n",
      "Epoch 303/2500\n",
      "11/11 - 0s - loss: 0.6042 - val_loss: 0.4937 - 30ms/epoch - 3ms/step\n",
      "Epoch 304/2500\n",
      "11/11 - 0s - loss: 0.5774 - val_loss: 0.4798 - 30ms/epoch - 3ms/step\n",
      "Epoch 305/2500\n",
      "11/11 - 0s - loss: 0.5834 - val_loss: 0.4784 - 30ms/epoch - 3ms/step\n",
      "Epoch 306/2500\n",
      "11/11 - 0s - loss: 0.5838 - val_loss: 0.4898 - 30ms/epoch - 3ms/step\n",
      "Epoch 307/2500\n",
      "11/11 - 0s - loss: 0.6104 - val_loss: 0.4906 - 29ms/epoch - 3ms/step\n",
      "Epoch 308/2500\n",
      "11/11 - 0s - loss: 0.5546 - val_loss: 0.4824 - 29ms/epoch - 3ms/step\n",
      "Epoch 309/2500\n",
      "11/11 - 0s - loss: 0.6204 - val_loss: 0.4785 - 29ms/epoch - 3ms/step\n",
      "Epoch 310/2500\n",
      "11/11 - 0s - loss: 0.5876 - val_loss: 0.4824 - 30ms/epoch - 3ms/step\n",
      "Epoch 311/2500\n",
      "11/11 - 0s - loss: 0.5881 - val_loss: 0.4859 - 29ms/epoch - 3ms/step\n",
      "Epoch 312/2500\n",
      "11/11 - 0s - loss: 0.5892 - val_loss: 0.4955 - 34ms/epoch - 3ms/step\n",
      "Epoch 313/2500\n",
      "11/11 - 0s - loss: 0.5681 - val_loss: 0.4977 - 30ms/epoch - 3ms/step\n",
      "Epoch 314/2500\n",
      "11/11 - 0s - loss: 0.6005 - val_loss: 0.4909 - 41ms/epoch - 4ms/step\n",
      "Epoch 315/2500\n",
      "11/11 - 0s - loss: 0.5781 - val_loss: 0.4796 - 30ms/epoch - 3ms/step\n",
      "Epoch 316/2500\n",
      "11/11 - 0s - loss: 0.5984 - val_loss: 0.4764 - 32ms/epoch - 3ms/step\n",
      "Epoch 317/2500\n",
      "11/11 - 0s - loss: 0.6075 - val_loss: 0.4811 - 36ms/epoch - 3ms/step\n",
      "Epoch 318/2500\n",
      "11/11 - 0s - loss: 0.5575 - val_loss: 0.4793 - 38ms/epoch - 3ms/step\n",
      "Epoch 319/2500\n",
      "11/11 - 0s - loss: 0.5774 - val_loss: 0.4780 - 32ms/epoch - 3ms/step\n",
      "Epoch 320/2500\n",
      "11/11 - 0s - loss: 0.5862 - val_loss: 0.4969 - 33ms/epoch - 3ms/step\n",
      "Epoch 321/2500\n",
      "11/11 - 0s - loss: 0.5772 - val_loss: 0.4968 - 33ms/epoch - 3ms/step\n",
      "Epoch 322/2500\n",
      "11/11 - 0s - loss: 0.6365 - val_loss: 0.4847 - 33ms/epoch - 3ms/step\n",
      "Epoch 323/2500\n",
      "11/11 - 0s - loss: 0.6306 - val_loss: 0.4871 - 34ms/epoch - 3ms/step\n",
      "Epoch 324/2500\n",
      "11/11 - 0s - loss: 0.5733 - val_loss: 0.4902 - 33ms/epoch - 3ms/step\n",
      "Epoch 325/2500\n",
      "11/11 - 0s - loss: 0.5818 - val_loss: 0.4859 - 33ms/epoch - 3ms/step\n",
      "Epoch 326/2500\n",
      "11/11 - 0s - loss: 0.5785 - val_loss: 0.4949 - 32ms/epoch - 3ms/step\n",
      "Epoch 327/2500\n",
      "11/11 - 0s - loss: 0.5702 - val_loss: 0.4901 - 33ms/epoch - 3ms/step\n",
      "Epoch 328/2500\n",
      "11/11 - 0s - loss: 0.5667 - val_loss: 0.4772 - 34ms/epoch - 3ms/step\n",
      "Epoch 329/2500\n",
      "11/11 - 0s - loss: 0.5567 - val_loss: 0.4783 - 33ms/epoch - 3ms/step\n",
      "Epoch 330/2500\n",
      "11/11 - 0s - loss: 0.6138 - val_loss: 0.4728 - 34ms/epoch - 3ms/step\n",
      "Epoch 331/2500\n",
      "11/11 - 0s - loss: 0.5770 - val_loss: 0.4755 - 31ms/epoch - 3ms/step\n",
      "Epoch 332/2500\n",
      "11/11 - 0s - loss: 0.5551 - val_loss: 0.4862 - 34ms/epoch - 3ms/step\n",
      "Epoch 333/2500\n",
      "11/11 - 0s - loss: 0.6162 - val_loss: 0.4970 - 47ms/epoch - 4ms/step\n",
      "Epoch 334/2500\n",
      "11/11 - 0s - loss: 0.5503 - val_loss: 0.4802 - 38ms/epoch - 3ms/step\n",
      "Epoch 335/2500\n",
      "11/11 - 0s - loss: 0.5972 - val_loss: 0.4768 - 36ms/epoch - 3ms/step\n",
      "Epoch 336/2500\n",
      "11/11 - 0s - loss: 0.5690 - val_loss: 0.4827 - 32ms/epoch - 3ms/step\n",
      "Epoch 337/2500\n",
      "11/11 - 0s - loss: 0.5741 - val_loss: 0.4982 - 32ms/epoch - 3ms/step\n",
      "Epoch 338/2500\n",
      "11/11 - 0s - loss: 0.5583 - val_loss: 0.5130 - 32ms/epoch - 3ms/step\n",
      "Epoch 339/2500\n",
      "11/11 - 0s - loss: 0.5679 - val_loss: 0.4836 - 32ms/epoch - 3ms/step\n",
      "Epoch 340/2500\n",
      "11/11 - 0s - loss: 0.5681 - val_loss: 0.4757 - 31ms/epoch - 3ms/step\n",
      "Epoch 341/2500\n",
      "11/11 - 0s - loss: 0.5647 - val_loss: 0.4833 - 29ms/epoch - 3ms/step\n",
      "Epoch 342/2500\n",
      "11/11 - 0s - loss: 0.5570 - val_loss: 0.4869 - 32ms/epoch - 3ms/step\n",
      "Epoch 343/2500\n",
      "11/11 - 0s - loss: 0.5905 - val_loss: 0.4753 - 30ms/epoch - 3ms/step\n",
      "Epoch 344/2500\n",
      "11/11 - 0s - loss: 0.5288 - val_loss: 0.4804 - 30ms/epoch - 3ms/step\n",
      "Epoch 345/2500\n",
      "11/11 - 0s - loss: 0.5389 - val_loss: 0.4868 - 29ms/epoch - 3ms/step\n",
      "Epoch 346/2500\n",
      "11/11 - 0s - loss: 0.5894 - val_loss: 0.4789 - 29ms/epoch - 3ms/step\n",
      "Epoch 347/2500\n",
      "11/11 - 0s - loss: 0.5763 - val_loss: 0.4801 - 31ms/epoch - 3ms/step\n",
      "Epoch 348/2500\n",
      "11/11 - 0s - loss: 0.6118 - val_loss: 0.4671 - 36ms/epoch - 3ms/step\n",
      "Epoch 349/2500\n",
      "11/11 - 0s - loss: 0.5588 - val_loss: 0.4749 - 33ms/epoch - 3ms/step\n",
      "Epoch 350/2500\n",
      "11/11 - 0s - loss: 0.5649 - val_loss: 0.4857 - 32ms/epoch - 3ms/step\n",
      "Epoch 351/2500\n",
      "11/11 - 0s - loss: 0.5769 - val_loss: 0.4750 - 31ms/epoch - 3ms/step\n",
      "Epoch 352/2500\n",
      "11/11 - 0s - loss: 0.5613 - val_loss: 0.4671 - 31ms/epoch - 3ms/step\n",
      "Epoch 353/2500\n",
      "11/11 - 0s - loss: 0.5585 - val_loss: 0.4635 - 31ms/epoch - 3ms/step\n",
      "Epoch 354/2500\n",
      "11/11 - 0s - loss: 0.5493 - val_loss: 0.4659 - 29ms/epoch - 3ms/step\n",
      "Epoch 355/2500\n",
      "11/11 - 0s - loss: 0.5828 - val_loss: 0.4746 - 30ms/epoch - 3ms/step\n",
      "Epoch 356/2500\n",
      "11/11 - 0s - loss: 0.5694 - val_loss: 0.4784 - 30ms/epoch - 3ms/step\n",
      "Epoch 357/2500\n",
      "11/11 - 0s - loss: 0.5614 - val_loss: 0.4772 - 31ms/epoch - 3ms/step\n",
      "Epoch 358/2500\n",
      "11/11 - 0s - loss: 0.5562 - val_loss: 0.4779 - 29ms/epoch - 3ms/step\n",
      "Epoch 359/2500\n",
      "11/11 - 0s - loss: 0.5534 - val_loss: 0.4826 - 31ms/epoch - 3ms/step\n",
      "Epoch 360/2500\n",
      "11/11 - 0s - loss: 0.5905 - val_loss: 0.4797 - 29ms/epoch - 3ms/step\n",
      "Epoch 361/2500\n",
      "11/11 - 0s - loss: 0.5346 - val_loss: 0.4673 - 31ms/epoch - 3ms/step\n",
      "Epoch 362/2500\n",
      "11/11 - 0s - loss: 0.5864 - val_loss: 0.4742 - 43ms/epoch - 4ms/step\n",
      "Epoch 363/2500\n",
      "11/11 - 0s - loss: 0.5668 - val_loss: 0.4649 - 34ms/epoch - 3ms/step\n",
      "Epoch 364/2500\n",
      "11/11 - 0s - loss: 0.5617 - val_loss: 0.4697 - 31ms/epoch - 3ms/step\n",
      "Epoch 365/2500\n",
      "11/11 - 0s - loss: 0.5645 - val_loss: 0.4732 - 31ms/epoch - 3ms/step\n",
      "Epoch 366/2500\n",
      "11/11 - 0s - loss: 0.5654 - val_loss: 0.4759 - 31ms/epoch - 3ms/step\n",
      "Epoch 367/2500\n",
      "11/11 - 0s - loss: 0.5286 - val_loss: 0.4837 - 30ms/epoch - 3ms/step\n",
      "Epoch 368/2500\n",
      "11/11 - 0s - loss: 0.5644 - val_loss: 0.4920 - 31ms/epoch - 3ms/step\n",
      "Epoch 369/2500\n",
      "11/11 - 0s - loss: 0.5203 - val_loss: 0.4762 - 30ms/epoch - 3ms/step\n",
      "Epoch 370/2500\n",
      "11/11 - 0s - loss: 0.5460 - val_loss: 0.4806 - 31ms/epoch - 3ms/step\n",
      "Epoch 371/2500\n",
      "11/11 - 0s - loss: 0.5578 - val_loss: 0.4899 - 30ms/epoch - 3ms/step\n",
      "Epoch 372/2500\n",
      "11/11 - 0s - loss: 0.5541 - val_loss: 0.4878 - 30ms/epoch - 3ms/step\n",
      "Epoch 373/2500\n",
      "11/11 - 0s - loss: 0.5696 - val_loss: 0.4762 - 31ms/epoch - 3ms/step\n",
      "Epoch 374/2500\n",
      "11/11 - 0s - loss: 0.5565 - val_loss: 0.4749 - 33ms/epoch - 3ms/step\n",
      "Epoch 375/2500\n",
      "11/11 - 0s - loss: 0.5678 - val_loss: 0.4752 - 34ms/epoch - 3ms/step\n",
      "Epoch 376/2500\n",
      "11/11 - 0s - loss: 0.5428 - val_loss: 0.4833 - 36ms/epoch - 3ms/step\n",
      "Epoch 377/2500\n",
      "11/11 - 0s - loss: 0.5560 - val_loss: 0.4828 - 36ms/epoch - 3ms/step\n",
      "Epoch 378/2500\n",
      "11/11 - 0s - loss: 0.5661 - val_loss: 0.4932 - 35ms/epoch - 3ms/step\n",
      "Epoch 379/2500\n",
      "11/11 - 0s - loss: 0.5510 - val_loss: 0.4947 - 38ms/epoch - 3ms/step\n",
      "Epoch 380/2500\n",
      "11/11 - 0s - loss: 0.5756 - val_loss: 0.4929 - 33ms/epoch - 3ms/step\n",
      "Epoch 381/2500\n",
      "11/11 - 0s - loss: 0.5338 - val_loss: 0.4818 - 30ms/epoch - 3ms/step\n",
      "Epoch 382/2500\n",
      "11/11 - 0s - loss: 0.5543 - val_loss: 0.4889 - 30ms/epoch - 3ms/step\n",
      "Epoch 383/2500\n",
      "11/11 - 0s - loss: 0.5668 - val_loss: 0.4825 - 31ms/epoch - 3ms/step\n",
      "Epoch 384/2500\n",
      "11/11 - 0s - loss: 0.5721 - val_loss: 0.4821 - 30ms/epoch - 3ms/step\n",
      "Epoch 385/2500\n",
      "11/11 - 0s - loss: 0.5550 - val_loss: 0.4788 - 31ms/epoch - 3ms/step\n",
      "Epoch 386/2500\n",
      "11/11 - 0s - loss: 0.5116 - val_loss: 0.4738 - 31ms/epoch - 3ms/step\n",
      "Epoch 387/2500\n",
      "11/11 - 0s - loss: 0.5360 - val_loss: 0.4853 - 34ms/epoch - 3ms/step\n",
      "Epoch 388/2500\n",
      "11/11 - 0s - loss: 0.5350 - val_loss: 0.4826 - 33ms/epoch - 3ms/step\n",
      "Epoch 389/2500\n",
      "11/11 - 0s - loss: 0.5531 - val_loss: 0.4816 - 33ms/epoch - 3ms/step\n",
      "Epoch 390/2500\n",
      "11/11 - 0s - loss: 0.5535 - val_loss: 0.4820 - 32ms/epoch - 3ms/step\n",
      "Epoch 391/2500\n",
      "11/11 - 0s - loss: 0.5394 - val_loss: 0.4855 - 32ms/epoch - 3ms/step\n",
      "Epoch 392/2500\n",
      "11/11 - 0s - loss: 0.5528 - val_loss: 0.4934 - 32ms/epoch - 3ms/step\n",
      "Epoch 393/2500\n",
      "11/11 - 0s - loss: 0.5669 - val_loss: 0.4834 - 31ms/epoch - 3ms/step\n",
      "Epoch 394/2500\n",
      "11/11 - 0s - loss: 0.5380 - val_loss: 0.4766 - 31ms/epoch - 3ms/step\n",
      "Epoch 395/2500\n",
      "11/11 - 0s - loss: 0.5347 - val_loss: 0.4810 - 43ms/epoch - 4ms/step\n",
      "Epoch 396/2500\n",
      "11/11 - 0s - loss: 0.5451 - val_loss: 0.4835 - 31ms/epoch - 3ms/step\n",
      "Epoch 397/2500\n",
      "11/11 - 0s - loss: 0.5508 - val_loss: 0.4908 - 33ms/epoch - 3ms/step\n",
      "Epoch 398/2500\n",
      "11/11 - 0s - loss: 0.5571 - val_loss: 0.4846 - 32ms/epoch - 3ms/step\n",
      "Epoch 399/2500\n",
      "11/11 - 0s - loss: 0.5531 - val_loss: 0.4882 - 34ms/epoch - 3ms/step\n",
      "Epoch 400/2500\n",
      "11/11 - 0s - loss: 0.5496 - val_loss: 0.4895 - 32ms/epoch - 3ms/step\n",
      "Epoch 401/2500\n",
      "11/11 - 0s - loss: 0.5573 - val_loss: 0.4728 - 31ms/epoch - 3ms/step\n",
      "Epoch 402/2500\n",
      "11/11 - 0s - loss: 0.5200 - val_loss: 0.4790 - 31ms/epoch - 3ms/step\n",
      "Epoch 403/2500\n",
      "11/11 - 0s - loss: 0.5413 - val_loss: 0.4820 - 31ms/epoch - 3ms/step\n",
      "Epoch 404/2500\n",
      "11/11 - 0s - loss: 0.5471 - val_loss: 0.4752 - 31ms/epoch - 3ms/step\n",
      "Epoch 405/2500\n",
      "11/11 - 0s - loss: 0.5380 - val_loss: 0.4750 - 30ms/epoch - 3ms/step\n",
      "Epoch 406/2500\n",
      "11/11 - 0s - loss: 0.5639 - val_loss: 0.4702 - 29ms/epoch - 3ms/step\n",
      "Epoch 407/2500\n",
      "11/11 - 0s - loss: 0.5662 - val_loss: 0.4791 - 31ms/epoch - 3ms/step\n",
      "Epoch 408/2500\n",
      "11/11 - 0s - loss: 0.5652 - val_loss: 0.4723 - 31ms/epoch - 3ms/step\n",
      "Epoch 409/2500\n",
      "11/11 - 0s - loss: 0.5490 - val_loss: 0.4700 - 30ms/epoch - 3ms/step\n",
      "Epoch 410/2500\n",
      "11/11 - 0s - loss: 0.5343 - val_loss: 0.4869 - 32ms/epoch - 3ms/step\n",
      "Epoch 411/2500\n",
      "11/11 - 0s - loss: 0.5407 - val_loss: 0.4808 - 29ms/epoch - 3ms/step\n",
      "Epoch 412/2500\n",
      "11/11 - 0s - loss: 0.5608 - val_loss: 0.4832 - 30ms/epoch - 3ms/step\n",
      "Epoch 413/2500\n",
      "11/11 - 0s - loss: 0.5128 - val_loss: 0.4805 - 30ms/epoch - 3ms/step\n",
      "Epoch 414/2500\n",
      "11/11 - 0s - loss: 0.5636 - val_loss: 0.4854 - 30ms/epoch - 3ms/step\n",
      "Epoch 415/2500\n",
      "11/11 - 0s - loss: 0.5224 - val_loss: 0.4786 - 30ms/epoch - 3ms/step\n",
      "Epoch 416/2500\n",
      "11/11 - 0s - loss: 0.5217 - val_loss: 0.4732 - 29ms/epoch - 3ms/step\n",
      "Epoch 417/2500\n",
      "11/11 - 0s - loss: 0.5399 - val_loss: 0.4739 - 31ms/epoch - 3ms/step\n",
      "Epoch 418/2500\n",
      "11/11 - 0s - loss: 0.5133 - val_loss: 0.4730 - 31ms/epoch - 3ms/step\n",
      "Epoch 419/2500\n",
      "11/11 - 0s - loss: 0.5620 - val_loss: 0.4790 - 30ms/epoch - 3ms/step\n",
      "Epoch 420/2500\n",
      "11/11 - 0s - loss: 0.5167 - val_loss: 0.4848 - 29ms/epoch - 3ms/step\n",
      "Epoch 421/2500\n",
      "11/11 - 0s - loss: 0.5460 - val_loss: 0.4744 - 29ms/epoch - 3ms/step\n",
      "Epoch 422/2500\n",
      "11/11 - 0s - loss: 0.5437 - val_loss: 0.4731 - 29ms/epoch - 3ms/step\n",
      "Epoch 423/2500\n",
      "11/11 - 0s - loss: 0.5547 - val_loss: 0.4754 - 29ms/epoch - 3ms/step\n",
      "Epoch 424/2500\n",
      "11/11 - 0s - loss: 0.5171 - val_loss: 0.4646 - 30ms/epoch - 3ms/step\n",
      "Epoch 425/2500\n",
      "11/11 - 0s - loss: 0.5433 - val_loss: 0.4625 - 30ms/epoch - 3ms/step\n",
      "Epoch 426/2500\n",
      "11/11 - 0s - loss: 0.5550 - val_loss: 0.4643 - 30ms/epoch - 3ms/step\n",
      "Epoch 427/2500\n",
      "11/11 - 0s - loss: 0.5321 - val_loss: 0.4717 - 29ms/epoch - 3ms/step\n",
      "Epoch 428/2500\n",
      "11/11 - 0s - loss: 0.5478 - val_loss: 0.4772 - 43ms/epoch - 4ms/step\n",
      "Epoch 429/2500\n",
      "11/11 - 0s - loss: 0.5480 - val_loss: 0.4750 - 29ms/epoch - 3ms/step\n",
      "Epoch 430/2500\n",
      "11/11 - 0s - loss: 0.5261 - val_loss: 0.4753 - 32ms/epoch - 3ms/step\n",
      "Epoch 431/2500\n",
      "11/11 - 0s - loss: 0.5269 - val_loss: 0.4746 - 35ms/epoch - 3ms/step\n",
      "Epoch 432/2500\n",
      "11/11 - 0s - loss: 0.5644 - val_loss: 0.4739 - 30ms/epoch - 3ms/step\n",
      "Epoch 433/2500\n",
      "11/11 - 0s - loss: 0.5416 - val_loss: 0.4712 - 30ms/epoch - 3ms/step\n",
      "Epoch 434/2500\n",
      "11/11 - 0s - loss: 0.5355 - val_loss: 0.4728 - 29ms/epoch - 3ms/step\n",
      "Epoch 435/2500\n",
      "11/11 - 0s - loss: 0.5622 - val_loss: 0.4896 - 29ms/epoch - 3ms/step\n",
      "Epoch 436/2500\n",
      "11/11 - 0s - loss: 0.5568 - val_loss: 0.4753 - 30ms/epoch - 3ms/step\n",
      "Epoch 437/2500\n",
      "11/11 - 0s - loss: 0.5406 - val_loss: 0.4627 - 30ms/epoch - 3ms/step\n",
      "Epoch 438/2500\n",
      "11/11 - 0s - loss: 0.5220 - val_loss: 0.4780 - 31ms/epoch - 3ms/step\n",
      "Epoch 439/2500\n",
      "11/11 - 0s - loss: 0.5290 - val_loss: 0.4783 - 32ms/epoch - 3ms/step\n",
      "Epoch 440/2500\n",
      "11/11 - 0s - loss: 0.5593 - val_loss: 0.4736 - 32ms/epoch - 3ms/step\n",
      "Epoch 441/2500\n",
      "11/11 - 0s - loss: 0.5261 - val_loss: 0.4745 - 35ms/epoch - 3ms/step\n",
      "Epoch 442/2500\n",
      "11/11 - 0s - loss: 0.5250 - val_loss: 0.4794 - 35ms/epoch - 3ms/step\n",
      "Epoch 443/2500\n",
      "11/11 - 0s - loss: 0.5274 - val_loss: 0.4891 - 44ms/epoch - 4ms/step\n",
      "Epoch 444/2500\n",
      "11/11 - 0s - loss: 0.5433 - val_loss: 0.4752 - 34ms/epoch - 3ms/step\n",
      "Epoch 445/2500\n",
      "11/11 - 0s - loss: 0.5351 - val_loss: 0.4743 - 35ms/epoch - 3ms/step\n",
      "Epoch 446/2500\n",
      "11/11 - 0s - loss: 0.5055 - val_loss: 0.4805 - 34ms/epoch - 3ms/step\n",
      "Epoch 447/2500\n",
      "11/11 - 0s - loss: 0.5334 - val_loss: 0.4731 - 33ms/epoch - 3ms/step\n",
      "Epoch 448/2500\n",
      "11/11 - 0s - loss: 0.5385 - val_loss: 0.4647 - 35ms/epoch - 3ms/step\n",
      "Epoch 449/2500\n",
      "11/11 - 0s - loss: 0.4978 - val_loss: 0.4721 - 34ms/epoch - 3ms/step\n",
      "Epoch 450/2500\n",
      "11/11 - 0s - loss: 0.5429 - val_loss: 0.4679 - 32ms/epoch - 3ms/step\n",
      "Epoch 451/2500\n",
      "11/11 - 0s - loss: 0.5562 - val_loss: 0.4636 - 34ms/epoch - 3ms/step\n",
      "Epoch 452/2500\n",
      "11/11 - 0s - loss: 0.5266 - val_loss: 0.4869 - 32ms/epoch - 3ms/step\n",
      "Epoch 453/2500\n",
      "11/11 - 0s - loss: 0.5321 - val_loss: 0.4704 - 34ms/epoch - 3ms/step\n",
      "Epoch 454/2500\n",
      "11/11 - 0s - loss: 0.5346 - val_loss: 0.4626 - 36ms/epoch - 3ms/step\n",
      "Epoch 455/2500\n",
      "11/11 - 0s - loss: 0.5464 - val_loss: 0.4817 - 32ms/epoch - 3ms/step\n",
      "Epoch 456/2500\n",
      "11/11 - 0s - loss: 0.5232 - val_loss: 0.4805 - 33ms/epoch - 3ms/step\n",
      "Epoch 457/2500\n",
      "11/11 - 0s - loss: 0.5006 - val_loss: 0.4774 - 33ms/epoch - 3ms/step\n",
      "Epoch 458/2500\n",
      "11/11 - 0s - loss: 0.5118 - val_loss: 0.4749 - 32ms/epoch - 3ms/step\n",
      "Epoch 459/2500\n",
      "11/11 - 0s - loss: 0.5070 - val_loss: 0.4737 - 32ms/epoch - 3ms/step\n",
      "Epoch 460/2500\n",
      "11/11 - 0s - loss: 0.5310 - val_loss: 0.4760 - 35ms/epoch - 3ms/step\n",
      "Epoch 461/2500\n",
      "11/11 - 0s - loss: 0.5589 - val_loss: 0.4825 - 31ms/epoch - 3ms/step\n",
      "Epoch 462/2500\n",
      "11/11 - 0s - loss: 0.5109 - val_loss: 0.4883 - 32ms/epoch - 3ms/step\n",
      "Epoch 463/2500\n",
      "11/11 - 0s - loss: 0.5313 - val_loss: 0.4803 - 33ms/epoch - 3ms/step\n",
      "Epoch 464/2500\n",
      "11/11 - 0s - loss: 0.5281 - val_loss: 0.4753 - 33ms/epoch - 3ms/step\n",
      "Epoch 465/2500\n",
      "11/11 - 0s - loss: 0.5127 - val_loss: 0.4809 - 33ms/epoch - 3ms/step\n",
      "Epoch 466/2500\n",
      "11/11 - 0s - loss: 0.5467 - val_loss: 0.4841 - 31ms/epoch - 3ms/step\n",
      "Epoch 467/2500\n",
      "11/11 - 0s - loss: 0.5102 - val_loss: 0.5102 - 31ms/epoch - 3ms/step\n",
      "Epoch 468/2500\n",
      "11/11 - 0s - loss: 0.5129 - val_loss: 0.4942 - 32ms/epoch - 3ms/step\n",
      "Epoch 469/2500\n",
      "11/11 - 0s - loss: 0.5276 - val_loss: 0.4830 - 34ms/epoch - 3ms/step\n",
      "Epoch 470/2500\n",
      "11/11 - 0s - loss: 0.5265 - val_loss: 0.4865 - 31ms/epoch - 3ms/step\n",
      "Epoch 471/2500\n",
      "11/11 - 0s - loss: 0.5296 - val_loss: 0.5029 - 32ms/epoch - 3ms/step\n",
      "Epoch 472/2500\n",
      "11/11 - 0s - loss: 0.5188 - val_loss: 0.4899 - 31ms/epoch - 3ms/step\n",
      "Epoch 473/2500\n",
      "11/11 - 0s - loss: 0.5036 - val_loss: 0.4717 - 32ms/epoch - 3ms/step\n",
      "Epoch 474/2500\n",
      "11/11 - 0s - loss: 0.5085 - val_loss: 0.4693 - 33ms/epoch - 3ms/step\n",
      "Epoch 475/2500\n",
      "11/11 - 0s - loss: 0.5113 - val_loss: 0.4788 - 45ms/epoch - 4ms/step\n",
      "Epoch 476/2500\n",
      "11/11 - 0s - loss: 0.5023 - val_loss: 0.4678 - 31ms/epoch - 3ms/step\n",
      "Epoch 477/2500\n",
      "11/11 - 0s - loss: 0.5225 - val_loss: 0.4700 - 34ms/epoch - 3ms/step\n",
      "Epoch 478/2500\n",
      "11/11 - 0s - loss: 0.5404 - val_loss: 0.4611 - 34ms/epoch - 3ms/step\n",
      "Epoch 479/2500\n",
      "11/11 - 0s - loss: 0.5083 - val_loss: 0.4706 - 32ms/epoch - 3ms/step\n",
      "Epoch 480/2500\n",
      "11/11 - 0s - loss: 0.5377 - val_loss: 0.4827 - 35ms/epoch - 3ms/step\n",
      "Epoch 481/2500\n",
      "11/11 - 0s - loss: 0.5395 - val_loss: 0.4733 - 32ms/epoch - 3ms/step\n",
      "Epoch 482/2500\n",
      "11/11 - 0s - loss: 0.5210 - val_loss: 0.4828 - 33ms/epoch - 3ms/step\n",
      "Epoch 483/2500\n",
      "11/11 - 0s - loss: 0.5254 - val_loss: 0.4703 - 35ms/epoch - 3ms/step\n",
      "Epoch 484/2500\n",
      "11/11 - 0s - loss: 0.5249 - val_loss: 0.4635 - 32ms/epoch - 3ms/step\n",
      "Epoch 485/2500\n",
      "11/11 - 0s - loss: 0.5187 - val_loss: 0.4703 - 32ms/epoch - 3ms/step\n",
      "Epoch 486/2500\n",
      "11/11 - 0s - loss: 0.5322 - val_loss: 0.4611 - 33ms/epoch - 3ms/step\n",
      "Epoch 487/2500\n",
      "11/11 - 0s - loss: 0.5430 - val_loss: 0.4688 - 33ms/epoch - 3ms/step\n",
      "Epoch 488/2500\n",
      "11/11 - 0s - loss: 0.5038 - val_loss: 0.4775 - 32ms/epoch - 3ms/step\n",
      "Epoch 489/2500\n",
      "11/11 - 0s - loss: 0.5369 - val_loss: 0.4682 - 32ms/epoch - 3ms/step\n",
      "Epoch 490/2500\n",
      "11/11 - 0s - loss: 0.5157 - val_loss: 0.4700 - 31ms/epoch - 3ms/step\n",
      "Epoch 491/2500\n",
      "11/11 - 0s - loss: 0.5131 - val_loss: 0.4686 - 33ms/epoch - 3ms/step\n",
      "Epoch 492/2500\n",
      "11/11 - 0s - loss: 0.5342 - val_loss: 0.4684 - 32ms/epoch - 3ms/step\n",
      "Epoch 493/2500\n",
      "11/11 - 0s - loss: 0.5039 - val_loss: 0.4753 - 31ms/epoch - 3ms/step\n",
      "Epoch 494/2500\n",
      "11/11 - 0s - loss: 0.5391 - val_loss: 0.4674 - 33ms/epoch - 3ms/step\n",
      "Epoch 495/2500\n",
      "11/11 - 0s - loss: 0.4903 - val_loss: 0.4604 - 32ms/epoch - 3ms/step\n",
      "Epoch 496/2500\n",
      "11/11 - 0s - loss: 0.5174 - val_loss: 0.4649 - 33ms/epoch - 3ms/step\n",
      "Epoch 497/2500\n",
      "11/11 - 0s - loss: 0.5185 - val_loss: 0.4761 - 32ms/epoch - 3ms/step\n",
      "Epoch 498/2500\n",
      "11/11 - 0s - loss: 0.5123 - val_loss: 0.4703 - 31ms/epoch - 3ms/step\n",
      "Epoch 499/2500\n",
      "11/11 - 0s - loss: 0.5067 - val_loss: 0.4645 - 32ms/epoch - 3ms/step\n",
      "Epoch 500/2500\n",
      "11/11 - 0s - loss: 0.5253 - val_loss: 0.4735 - 32ms/epoch - 3ms/step\n",
      "Epoch 501/2500\n",
      "11/11 - 0s - loss: 0.4912 - val_loss: 0.4704 - 33ms/epoch - 3ms/step\n",
      "Epoch 502/2500\n",
      "11/11 - 0s - loss: 0.5099 - val_loss: 0.4696 - 32ms/epoch - 3ms/step\n",
      "Epoch 503/2500\n",
      "11/11 - 0s - loss: 0.5346 - val_loss: 0.4815 - 32ms/epoch - 3ms/step\n",
      "Epoch 504/2500\n",
      "11/11 - 0s - loss: 0.5122 - val_loss: 0.4674 - 32ms/epoch - 3ms/step\n",
      "Epoch 505/2500\n",
      "11/11 - 0s - loss: 0.5018 - val_loss: 0.4666 - 38ms/epoch - 3ms/step\n",
      "Epoch 506/2500\n",
      "11/11 - 0s - loss: 0.5214 - val_loss: 0.4635 - 34ms/epoch - 3ms/step\n",
      "Epoch 507/2500\n",
      "11/11 - 0s - loss: 0.4906 - val_loss: 0.4732 - 33ms/epoch - 3ms/step\n",
      "Epoch 508/2500\n",
      "11/11 - 0s - loss: 0.5204 - val_loss: 0.4661 - 32ms/epoch - 3ms/step\n",
      "Epoch 509/2500\n",
      "11/11 - 0s - loss: 0.5072 - val_loss: 0.4636 - 32ms/epoch - 3ms/step\n",
      "Epoch 510/2500\n",
      "11/11 - 0s - loss: 0.4847 - val_loss: 0.4606 - 32ms/epoch - 3ms/step\n",
      "Epoch 511/2500\n",
      "11/11 - 0s - loss: 0.5119 - val_loss: 0.4605 - 32ms/epoch - 3ms/step\n",
      "Epoch 512/2500\n",
      "11/11 - 0s - loss: 0.5194 - val_loss: 0.4670 - 32ms/epoch - 3ms/step\n",
      "Epoch 513/2500\n",
      "11/11 - 0s - loss: 0.5268 - val_loss: 0.4705 - 31ms/epoch - 3ms/step\n",
      "Epoch 514/2500\n",
      "11/11 - 0s - loss: 0.4733 - val_loss: 0.4702 - 34ms/epoch - 3ms/step\n",
      "Epoch 515/2500\n",
      "11/11 - 0s - loss: 0.4847 - val_loss: 0.4769 - 33ms/epoch - 3ms/step\n",
      "Epoch 516/2500\n",
      "11/11 - 0s - loss: 0.4940 - val_loss: 0.4627 - 33ms/epoch - 3ms/step\n",
      "Epoch 517/2500\n",
      "11/11 - 0s - loss: 0.5104 - val_loss: 0.4642 - 48ms/epoch - 4ms/step\n",
      "Epoch 518/2500\n",
      "11/11 - 0s - loss: 0.5183 - val_loss: 0.4689 - 31ms/epoch - 3ms/step\n",
      "Epoch 519/2500\n",
      "11/11 - 0s - loss: 0.5106 - val_loss: 0.4618 - 32ms/epoch - 3ms/step\n",
      "Epoch 520/2500\n",
      "11/11 - 0s - loss: 0.4932 - val_loss: 0.4728 - 32ms/epoch - 3ms/step\n",
      "Epoch 521/2500\n",
      "11/11 - 0s - loss: 0.5129 - val_loss: 0.4737 - 32ms/epoch - 3ms/step\n",
      "Epoch 522/2500\n",
      "11/11 - 0s - loss: 0.5239 - val_loss: 0.4743 - 34ms/epoch - 3ms/step\n",
      "Epoch 523/2500\n",
      "11/11 - 0s - loss: 0.5018 - val_loss: 0.4603 - 31ms/epoch - 3ms/step\n",
      "Epoch 524/2500\n",
      "11/11 - 0s - loss: 0.5069 - val_loss: 0.4591 - 33ms/epoch - 3ms/step\n",
      "Epoch 525/2500\n",
      "11/11 - 0s - loss: 0.4782 - val_loss: 0.4688 - 33ms/epoch - 3ms/step\n",
      "Epoch 526/2500\n",
      "11/11 - 0s - loss: 0.5159 - val_loss: 0.4693 - 37ms/epoch - 3ms/step\n",
      "Epoch 527/2500\n",
      "11/11 - 0s - loss: 0.5230 - val_loss: 0.4657 - 32ms/epoch - 3ms/step\n",
      "Epoch 528/2500\n",
      "11/11 - 0s - loss: 0.5297 - val_loss: 0.4776 - 32ms/epoch - 3ms/step\n",
      "Epoch 529/2500\n",
      "11/11 - 0s - loss: 0.5102 - val_loss: 0.4685 - 34ms/epoch - 3ms/step\n",
      "Epoch 530/2500\n",
      "11/11 - 0s - loss: 0.5159 - val_loss: 0.4540 - 32ms/epoch - 3ms/step\n",
      "Epoch 531/2500\n",
      "11/11 - 0s - loss: 0.5091 - val_loss: 0.4507 - 33ms/epoch - 3ms/step\n",
      "Epoch 532/2500\n",
      "11/11 - 0s - loss: 0.5389 - val_loss: 0.4575 - 32ms/epoch - 3ms/step\n",
      "Epoch 533/2500\n",
      "11/11 - 0s - loss: 0.5128 - val_loss: 0.4618 - 35ms/epoch - 3ms/step\n",
      "Epoch 534/2500\n",
      "11/11 - 0s - loss: 0.5247 - val_loss: 0.4542 - 32ms/epoch - 3ms/step\n",
      "Epoch 535/2500\n",
      "11/11 - 0s - loss: 0.5004 - val_loss: 0.4595 - 33ms/epoch - 3ms/step\n",
      "Epoch 536/2500\n",
      "11/11 - 0s - loss: 0.4916 - val_loss: 0.4708 - 31ms/epoch - 3ms/step\n",
      "Epoch 537/2500\n",
      "11/11 - 0s - loss: 0.5204 - val_loss: 0.4712 - 32ms/epoch - 3ms/step\n",
      "Epoch 538/2500\n",
      "11/11 - 0s - loss: 0.5068 - val_loss: 0.4582 - 37ms/epoch - 3ms/step\n",
      "Epoch 539/2500\n",
      "11/11 - 0s - loss: 0.4913 - val_loss: 0.4649 - 35ms/epoch - 3ms/step\n",
      "Epoch 540/2500\n",
      "11/11 - 0s - loss: 0.4955 - val_loss: 0.4683 - 32ms/epoch - 3ms/step\n",
      "Epoch 541/2500\n",
      "11/11 - 0s - loss: 0.5055 - val_loss: 0.4613 - 32ms/epoch - 3ms/step\n",
      "Epoch 542/2500\n",
      "11/11 - 0s - loss: 0.4940 - val_loss: 0.4667 - 32ms/epoch - 3ms/step\n",
      "Epoch 543/2500\n",
      "11/11 - 0s - loss: 0.5019 - val_loss: 0.4756 - 35ms/epoch - 3ms/step\n",
      "Epoch 544/2500\n",
      "11/11 - 0s - loss: 0.4986 - val_loss: 0.4606 - 33ms/epoch - 3ms/step\n",
      "Epoch 545/2500\n",
      "11/11 - 0s - loss: 0.5153 - val_loss: 0.4601 - 33ms/epoch - 3ms/step\n",
      "Epoch 546/2500\n",
      "11/11 - 0s - loss: 0.4891 - val_loss: 0.4630 - 30ms/epoch - 3ms/step\n",
      "Epoch 547/2500\n",
      "11/11 - 0s - loss: 0.4896 - val_loss: 0.4767 - 31ms/epoch - 3ms/step\n",
      "Epoch 548/2500\n",
      "11/11 - 0s - loss: 0.5035 - val_loss: 0.4623 - 30ms/epoch - 3ms/step\n",
      "Epoch 549/2500\n",
      "11/11 - 0s - loss: 0.5051 - val_loss: 0.4747 - 29ms/epoch - 3ms/step\n",
      "Epoch 550/2500\n",
      "11/11 - 0s - loss: 0.5066 - val_loss: 0.4697 - 30ms/epoch - 3ms/step\n",
      "Epoch 551/2500\n",
      "11/11 - 0s - loss: 0.5009 - val_loss: 0.4733 - 31ms/epoch - 3ms/step\n",
      "Epoch 552/2500\n",
      "11/11 - 0s - loss: 0.4878 - val_loss: 0.4663 - 31ms/epoch - 3ms/step\n",
      "Epoch 553/2500\n",
      "11/11 - 0s - loss: 0.4908 - val_loss: 0.4723 - 29ms/epoch - 3ms/step\n",
      "Epoch 554/2500\n",
      "11/11 - 0s - loss: 0.4998 - val_loss: 0.4643 - 30ms/epoch - 3ms/step\n",
      "Epoch 555/2500\n",
      "11/11 - 0s - loss: 0.4662 - val_loss: 0.4658 - 30ms/epoch - 3ms/step\n",
      "Epoch 556/2500\n",
      "11/11 - 0s - loss: 0.5108 - val_loss: 0.4815 - 43ms/epoch - 4ms/step\n",
      "Epoch 557/2500\n",
      "11/11 - 0s - loss: 0.5068 - val_loss: 0.4710 - 29ms/epoch - 3ms/step\n",
      "Epoch 558/2500\n",
      "11/11 - 0s - loss: 0.5030 - val_loss: 0.4682 - 31ms/epoch - 3ms/step\n",
      "Epoch 559/2500\n",
      "11/11 - 0s - loss: 0.4635 - val_loss: 0.4713 - 30ms/epoch - 3ms/step\n",
      "Epoch 560/2500\n",
      "11/11 - 0s - loss: 0.5035 - val_loss: 0.4699 - 30ms/epoch - 3ms/step\n",
      "Epoch 561/2500\n",
      "11/11 - 0s - loss: 0.4508 - val_loss: 0.4625 - 29ms/epoch - 3ms/step\n",
      "Epoch 562/2500\n",
      "11/11 - 0s - loss: 0.4997 - val_loss: 0.4600 - 30ms/epoch - 3ms/step\n",
      "Epoch 563/2500\n",
      "11/11 - 0s - loss: 0.5016 - val_loss: 0.4718 - 30ms/epoch - 3ms/step\n",
      "Epoch 564/2500\n",
      "11/11 - 0s - loss: 0.4963 - val_loss: 0.4593 - 30ms/epoch - 3ms/step\n",
      "Epoch 565/2500\n",
      "11/11 - 0s - loss: 0.4864 - val_loss: 0.4631 - 30ms/epoch - 3ms/step\n",
      "Epoch 566/2500\n",
      "11/11 - 0s - loss: 0.4823 - val_loss: 0.4660 - 30ms/epoch - 3ms/step\n",
      "Epoch 567/2500\n",
      "11/11 - 0s - loss: 0.4914 - val_loss: 0.4666 - 32ms/epoch - 3ms/step\n",
      "Epoch 568/2500\n",
      "11/11 - 0s - loss: 0.5058 - val_loss: 0.4621 - 30ms/epoch - 3ms/step\n",
      "Epoch 569/2500\n",
      "11/11 - 0s - loss: 0.4812 - val_loss: 0.4618 - 31ms/epoch - 3ms/step\n",
      "Epoch 570/2500\n",
      "11/11 - 0s - loss: 0.5056 - val_loss: 0.4614 - 29ms/epoch - 3ms/step\n",
      "Epoch 571/2500\n",
      "11/11 - 0s - loss: 0.4960 - val_loss: 0.4579 - 30ms/epoch - 3ms/step\n",
      "Epoch 572/2500\n",
      "11/11 - 0s - loss: 0.4937 - val_loss: 0.4625 - 30ms/epoch - 3ms/step\n",
      "Epoch 573/2500\n",
      "11/11 - 0s - loss: 0.4832 - val_loss: 0.4615 - 29ms/epoch - 3ms/step\n",
      "Epoch 574/2500\n",
      "11/11 - 0s - loss: 0.4852 - val_loss: 0.4525 - 29ms/epoch - 3ms/step\n",
      "Epoch 575/2500\n",
      "11/11 - 0s - loss: 0.5082 - val_loss: 0.4586 - 30ms/epoch - 3ms/step\n",
      "Epoch 576/2500\n",
      "11/11 - 0s - loss: 0.4764 - val_loss: 0.4572 - 29ms/epoch - 3ms/step\n",
      "Epoch 577/2500\n",
      "11/11 - 0s - loss: 0.4759 - val_loss: 0.4594 - 30ms/epoch - 3ms/step\n",
      "Epoch 578/2500\n",
      "11/11 - 0s - loss: 0.4987 - val_loss: 0.4728 - 30ms/epoch - 3ms/step\n",
      "Epoch 579/2500\n",
      "11/11 - 0s - loss: 0.5125 - val_loss: 0.4690 - 30ms/epoch - 3ms/step\n",
      "Epoch 580/2500\n",
      "11/11 - 0s - loss: 0.4814 - val_loss: 0.4647 - 31ms/epoch - 3ms/step\n",
      "Epoch 581/2500\n",
      "11/11 - 0s - loss: 0.4953 - val_loss: 0.4592 - 30ms/epoch - 3ms/step\n",
      "Epoch 582/2500\n",
      "11/11 - 0s - loss: 0.4877 - val_loss: 0.4587 - 29ms/epoch - 3ms/step\n",
      "Epoch 583/2500\n",
      "11/11 - 0s - loss: 0.4778 - val_loss: 0.4605 - 29ms/epoch - 3ms/step\n",
      "Epoch 584/2500\n",
      "11/11 - 0s - loss: 0.4870 - val_loss: 0.4629 - 29ms/epoch - 3ms/step\n",
      "Epoch 585/2500\n",
      "11/11 - 0s - loss: 0.4884 - val_loss: 0.4685 - 29ms/epoch - 3ms/step\n",
      "Epoch 586/2500\n",
      "11/11 - 0s - loss: 0.4719 - val_loss: 0.4705 - 29ms/epoch - 3ms/step\n",
      "Epoch 587/2500\n",
      "11/11 - 0s - loss: 0.4765 - val_loss: 0.4683 - 29ms/epoch - 3ms/step\n",
      "Epoch 588/2500\n",
      "11/11 - 0s - loss: 0.4968 - val_loss: 0.4648 - 29ms/epoch - 3ms/step\n",
      "Epoch 589/2500\n",
      "11/11 - 0s - loss: 0.5074 - val_loss: 0.4732 - 29ms/epoch - 3ms/step\n",
      "Epoch 590/2500\n",
      "11/11 - 0s - loss: 0.4746 - val_loss: 0.4792 - 29ms/epoch - 3ms/step\n",
      "Epoch 591/2500\n",
      "11/11 - 0s - loss: 0.4967 - val_loss: 0.4791 - 30ms/epoch - 3ms/step\n",
      "Epoch 592/2500\n",
      "11/11 - 0s - loss: 0.4826 - val_loss: 0.4860 - 29ms/epoch - 3ms/step\n",
      "Epoch 593/2500\n",
      "11/11 - 0s - loss: 0.4634 - val_loss: 0.4638 - 29ms/epoch - 3ms/step\n",
      "Epoch 594/2500\n",
      "11/11 - 0s - loss: 0.4772 - val_loss: 0.4639 - 29ms/epoch - 3ms/step\n",
      "Epoch 595/2500\n",
      "11/11 - 0s - loss: 0.5153 - val_loss: 0.4622 - 35ms/epoch - 3ms/step\n",
      "Epoch 596/2500\n",
      "11/11 - 0s - loss: 0.4997 - val_loss: 0.4736 - 30ms/epoch - 3ms/step\n",
      "Epoch 597/2500\n",
      "11/11 - 0s - loss: 0.4811 - val_loss: 0.4734 - 29ms/epoch - 3ms/step\n",
      "Epoch 598/2500\n",
      "11/11 - 0s - loss: 0.5046 - val_loss: 0.4677 - 30ms/epoch - 3ms/step\n",
      "Epoch 599/2500\n",
      "11/11 - 0s - loss: 0.4937 - val_loss: 0.4721 - 29ms/epoch - 3ms/step\n",
      "Epoch 600/2500\n",
      "11/11 - 0s - loss: 0.5110 - val_loss: 0.4742 - 30ms/epoch - 3ms/step\n",
      "Epoch 601/2500\n",
      "11/11 - 0s - loss: 0.4705 - val_loss: 0.4756 - 29ms/epoch - 3ms/step\n",
      "Epoch 602/2500\n",
      "11/11 - 0s - loss: 0.5117 - val_loss: 0.4714 - 30ms/epoch - 3ms/step\n",
      "Epoch 603/2500\n",
      "11/11 - 0s - loss: 0.4639 - val_loss: 0.4799 - 29ms/epoch - 3ms/step\n",
      "Epoch 604/2500\n",
      "11/11 - 0s - loss: 0.4531 - val_loss: 0.4907 - 29ms/epoch - 3ms/step\n",
      "Epoch 605/2500\n",
      "11/11 - 0s - loss: 0.4975 - val_loss: 0.4761 - 29ms/epoch - 3ms/step\n",
      "Epoch 606/2500\n",
      "11/11 - 0s - loss: 0.4721 - val_loss: 0.4786 - 30ms/epoch - 3ms/step\n",
      "Epoch 607/2500\n",
      "11/11 - 0s - loss: 0.4887 - val_loss: 0.4744 - 29ms/epoch - 3ms/step\n",
      "Epoch 608/2500\n",
      "11/11 - 0s - loss: 0.5254 - val_loss: 0.4720 - 30ms/epoch - 3ms/step\n",
      "Epoch 609/2500\n",
      "11/11 - 0s - loss: 0.5057 - val_loss: 0.4689 - 30ms/epoch - 3ms/step\n",
      "Epoch 610/2500\n",
      "11/11 - 0s - loss: 0.4966 - val_loss: 0.4623 - 29ms/epoch - 3ms/step\n",
      "Epoch 611/2500\n",
      "11/11 - 0s - loss: 0.4893 - val_loss: 0.4767 - 29ms/epoch - 3ms/step\n",
      "Epoch 612/2500\n",
      "11/11 - 0s - loss: 0.4829 - val_loss: 0.4861 - 29ms/epoch - 3ms/step\n",
      "Epoch 613/2500\n",
      "11/11 - 0s - loss: 0.4466 - val_loss: 0.4683 - 30ms/epoch - 3ms/step\n",
      "Epoch 614/2500\n",
      "11/11 - 0s - loss: 0.5138 - val_loss: 0.4709 - 30ms/epoch - 3ms/step\n",
      "Epoch 615/2500\n",
      "11/11 - 0s - loss: 0.4769 - val_loss: 0.4758 - 30ms/epoch - 3ms/step\n",
      "Epoch 616/2500\n",
      "11/11 - 0s - loss: 0.4972 - val_loss: 0.4718 - 29ms/epoch - 3ms/step\n",
      "Epoch 617/2500\n",
      "11/11 - 0s - loss: 0.4739 - val_loss: 0.4660 - 29ms/epoch - 3ms/step\n",
      "Epoch 618/2500\n",
      "11/11 - 0s - loss: 0.4707 - val_loss: 0.4732 - 29ms/epoch - 3ms/step\n",
      "Epoch 619/2500\n",
      "11/11 - 0s - loss: 0.4597 - val_loss: 0.4678 - 30ms/epoch - 3ms/step\n",
      "Epoch 620/2500\n",
      "11/11 - 0s - loss: 0.4888 - val_loss: 0.4626 - 28ms/epoch - 3ms/step\n",
      "Epoch 621/2500\n",
      "11/11 - 0s - loss: 0.5012 - val_loss: 0.4700 - 30ms/epoch - 3ms/step\n",
      "Epoch 622/2500\n",
      "11/11 - 0s - loss: 0.4957 - val_loss: 0.4646 - 30ms/epoch - 3ms/step\n",
      "Epoch 623/2500\n",
      "11/11 - 0s - loss: 0.5135 - val_loss: 0.4603 - 28ms/epoch - 3ms/step\n",
      "Epoch 624/2500\n",
      "11/11 - 0s - loss: 0.5093 - val_loss: 0.4587 - 29ms/epoch - 3ms/step\n",
      "Epoch 625/2500\n",
      "11/11 - 0s - loss: 0.4925 - val_loss: 0.4725 - 30ms/epoch - 3ms/step\n",
      "Epoch 626/2500\n",
      "11/11 - 0s - loss: 0.4842 - val_loss: 0.4589 - 30ms/epoch - 3ms/step\n",
      "Epoch 627/2500\n",
      "11/11 - 0s - loss: 0.4746 - val_loss: 0.4562 - 34ms/epoch - 3ms/step\n",
      "Epoch 628/2500\n",
      "11/11 - 0s - loss: 0.4698 - val_loss: 0.4576 - 36ms/epoch - 3ms/step\n",
      "Epoch 629/2500\n",
      "11/11 - 0s - loss: 0.4729 - val_loss: 0.4640 - 31ms/epoch - 3ms/step\n",
      "Epoch 630/2500\n",
      "11/11 - 0s - loss: 0.5016 - val_loss: 0.4652 - 30ms/epoch - 3ms/step\n",
      "Epoch 631/2500\n",
      "11/11 - 0s - loss: 0.4900 - val_loss: 0.4674 - 30ms/epoch - 3ms/step\n",
      "Epoch 632/2500\n",
      "11/11 - 0s - loss: 0.4812 - val_loss: 0.4762 - 29ms/epoch - 3ms/step\n",
      "Epoch 633/2500\n",
      "11/11 - 0s - loss: 0.4889 - val_loss: 0.4776 - 30ms/epoch - 3ms/step\n",
      "Epoch 634/2500\n",
      "11/11 - 0s - loss: 0.4645 - val_loss: 0.4746 - 32ms/epoch - 3ms/step\n",
      "Epoch 635/2500\n",
      "11/11 - 0s - loss: 0.4875 - val_loss: 0.4723 - 29ms/epoch - 3ms/step\n",
      "Epoch 636/2500\n",
      "11/11 - 0s - loss: 0.4902 - val_loss: 0.4690 - 29ms/epoch - 3ms/step\n",
      "Epoch 637/2500\n",
      "11/11 - 0s - loss: 0.4661 - val_loss: 0.4703 - 29ms/epoch - 3ms/step\n",
      "Epoch 638/2500\n",
      "11/11 - 0s - loss: 0.4712 - val_loss: 0.4636 - 30ms/epoch - 3ms/step\n",
      "Epoch 639/2500\n",
      "11/11 - 0s - loss: 0.4884 - val_loss: 0.4682 - 29ms/epoch - 3ms/step\n",
      "Epoch 640/2500\n",
      "11/11 - 0s - loss: 0.4839 - val_loss: 0.4557 - 29ms/epoch - 3ms/step\n",
      "Epoch 641/2500\n",
      "11/11 - 0s - loss: 0.5121 - val_loss: 0.4616 - 29ms/epoch - 3ms/step\n",
      "Epoch 642/2500\n",
      "11/11 - 0s - loss: 0.4904 - val_loss: 0.4699 - 30ms/epoch - 3ms/step\n",
      "Epoch 643/2500\n",
      "11/11 - 0s - loss: 0.4677 - val_loss: 0.4588 - 29ms/epoch - 3ms/step\n",
      "Epoch 644/2500\n",
      "11/11 - 0s - loss: 0.4912 - val_loss: 0.4494 - 29ms/epoch - 3ms/step\n",
      "Epoch 645/2500\n",
      "11/11 - 0s - loss: 0.4801 - val_loss: 0.4523 - 30ms/epoch - 3ms/step\n",
      "Epoch 646/2500\n",
      "11/11 - 0s - loss: 0.4980 - val_loss: 0.4610 - 30ms/epoch - 3ms/step\n",
      "Epoch 647/2500\n",
      "11/11 - 0s - loss: 0.4711 - val_loss: 0.4497 - 30ms/epoch - 3ms/step\n",
      "Epoch 648/2500\n",
      "11/11 - 0s - loss: 0.4504 - val_loss: 0.4616 - 29ms/epoch - 3ms/step\n",
      "Epoch 649/2500\n",
      "11/11 - 0s - loss: 0.4744 - val_loss: 0.4672 - 29ms/epoch - 3ms/step\n",
      "Epoch 650/2500\n",
      "11/11 - 0s - loss: 0.4730 - val_loss: 0.4713 - 29ms/epoch - 3ms/step\n",
      "Epoch 651/2500\n",
      "11/11 - 0s - loss: 0.4882 - val_loss: 0.4690 - 30ms/epoch - 3ms/step\n",
      "Epoch 652/2500\n",
      "11/11 - 0s - loss: 0.4693 - val_loss: 0.4728 - 30ms/epoch - 3ms/step\n",
      "Epoch 653/2500\n",
      "11/11 - 0s - loss: 0.4640 - val_loss: 0.4700 - 29ms/epoch - 3ms/step\n",
      "Epoch 654/2500\n",
      "11/11 - 0s - loss: 0.4740 - val_loss: 0.4612 - 29ms/epoch - 3ms/step\n",
      "Epoch 655/2500\n",
      "11/11 - 0s - loss: 0.4457 - val_loss: 0.4663 - 29ms/epoch - 3ms/step\n",
      "Epoch 656/2500\n",
      "11/11 - 0s - loss: 0.4872 - val_loss: 0.4670 - 29ms/epoch - 3ms/step\n",
      "Epoch 657/2500\n",
      "11/11 - 0s - loss: 0.4801 - val_loss: 0.4623 - 29ms/epoch - 3ms/step\n",
      "Epoch 658/2500\n",
      "11/11 - 0s - loss: 0.4561 - val_loss: 0.4647 - 29ms/epoch - 3ms/step\n",
      "Epoch 659/2500\n",
      "11/11 - 0s - loss: 0.4728 - val_loss: 0.4613 - 30ms/epoch - 3ms/step\n",
      "Epoch 660/2500\n",
      "11/11 - 0s - loss: 0.4703 - val_loss: 0.4640 - 29ms/epoch - 3ms/step\n",
      "Epoch 661/2500\n",
      "11/11 - 0s - loss: 0.4777 - val_loss: 0.4607 - 29ms/epoch - 3ms/step\n",
      "Epoch 662/2500\n",
      "11/11 - 0s - loss: 0.4651 - val_loss: 0.4684 - 30ms/epoch - 3ms/step\n",
      "Epoch 663/2500\n",
      "11/11 - 0s - loss: 0.4689 - val_loss: 0.4597 - 30ms/epoch - 3ms/step\n",
      "Epoch 664/2500\n",
      "11/11 - 0s - loss: 0.4700 - val_loss: 0.4657 - 30ms/epoch - 3ms/step\n",
      "Epoch 665/2500\n",
      "11/11 - 0s - loss: 0.4642 - val_loss: 0.4721 - 29ms/epoch - 3ms/step\n",
      "Epoch 666/2500\n",
      "11/11 - 0s - loss: 0.4742 - val_loss: 0.4650 - 42ms/epoch - 4ms/step\n",
      "Epoch 667/2500\n",
      "11/11 - 0s - loss: 0.4879 - val_loss: 0.4738 - 29ms/epoch - 3ms/step\n",
      "Epoch 668/2500\n",
      "11/11 - 0s - loss: 0.4744 - val_loss: 0.4640 - 29ms/epoch - 3ms/step\n",
      "Epoch 669/2500\n",
      "11/11 - 0s - loss: 0.4739 - val_loss: 0.4561 - 29ms/epoch - 3ms/step\n",
      "Epoch 670/2500\n",
      "11/11 - 0s - loss: 0.4777 - val_loss: 0.4567 - 30ms/epoch - 3ms/step\n",
      "Epoch 671/2500\n",
      "11/11 - 0s - loss: 0.4731 - val_loss: 0.4615 - 29ms/epoch - 3ms/step\n",
      "Epoch 672/2500\n",
      "11/11 - 0s - loss: 0.4530 - val_loss: 0.4517 - 29ms/epoch - 3ms/step\n",
      "Epoch 673/2500\n",
      "11/11 - 0s - loss: 0.4697 - val_loss: 0.4600 - 30ms/epoch - 3ms/step\n",
      "Epoch 674/2500\n",
      "11/11 - 0s - loss: 0.4851 - val_loss: 0.4776 - 30ms/epoch - 3ms/step\n",
      "Epoch 675/2500\n",
      "11/11 - 0s - loss: 0.4837 - val_loss: 0.4600 - 30ms/epoch - 3ms/step\n",
      "Epoch 676/2500\n",
      "11/11 - 0s - loss: 0.4549 - val_loss: 0.4680 - 29ms/epoch - 3ms/step\n",
      "Epoch 677/2500\n",
      "11/11 - 0s - loss: 0.4853 - val_loss: 0.4631 - 31ms/epoch - 3ms/step\n",
      "Epoch 678/2500\n",
      "11/11 - 0s - loss: 0.4644 - val_loss: 0.4470 - 28ms/epoch - 3ms/step\n",
      "Epoch 679/2500\n",
      "11/11 - 0s - loss: 0.4823 - val_loss: 0.4395 - 28ms/epoch - 3ms/step\n",
      "Epoch 680/2500\n",
      "11/11 - 0s - loss: 0.4780 - val_loss: 0.4551 - 29ms/epoch - 3ms/step\n",
      "Epoch 681/2500\n",
      "11/11 - 0s - loss: 0.4883 - val_loss: 0.4541 - 29ms/epoch - 3ms/step\n",
      "Epoch 682/2500\n",
      "11/11 - 0s - loss: 0.4521 - val_loss: 0.4470 - 29ms/epoch - 3ms/step\n",
      "Epoch 683/2500\n",
      "11/11 - 0s - loss: 0.4849 - val_loss: 0.4552 - 29ms/epoch - 3ms/step\n",
      "Epoch 684/2500\n",
      "11/11 - 0s - loss: 0.4565 - val_loss: 0.4433 - 28ms/epoch - 3ms/step\n",
      "Epoch 685/2500\n",
      "11/11 - 0s - loss: 0.4770 - val_loss: 0.4449 - 28ms/epoch - 3ms/step\n",
      "Epoch 686/2500\n",
      "11/11 - 0s - loss: 0.4564 - val_loss: 0.4517 - 29ms/epoch - 3ms/step\n",
      "Epoch 687/2500\n",
      "11/11 - 0s - loss: 0.4606 - val_loss: 0.4565 - 29ms/epoch - 3ms/step\n",
      "Epoch 688/2500\n",
      "11/11 - 0s - loss: 0.4964 - val_loss: 0.4398 - 28ms/epoch - 3ms/step\n",
      "Epoch 689/2500\n",
      "11/11 - 0s - loss: 0.4826 - val_loss: 0.4383 - 29ms/epoch - 3ms/step\n",
      "Epoch 690/2500\n",
      "11/11 - 0s - loss: 0.4752 - val_loss: 0.4330 - 29ms/epoch - 3ms/step\n",
      "Epoch 691/2500\n",
      "11/11 - 0s - loss: 0.4904 - val_loss: 0.4436 - 29ms/epoch - 3ms/step\n",
      "Epoch 692/2500\n",
      "11/11 - 0s - loss: 0.4748 - val_loss: 0.4339 - 29ms/epoch - 3ms/step\n",
      "Epoch 693/2500\n",
      "11/11 - 0s - loss: 0.4596 - val_loss: 0.4418 - 29ms/epoch - 3ms/step\n",
      "Epoch 694/2500\n",
      "11/11 - 0s - loss: 0.4676 - val_loss: 0.4448 - 29ms/epoch - 3ms/step\n",
      "Epoch 695/2500\n",
      "11/11 - 0s - loss: 0.4793 - val_loss: 0.4423 - 28ms/epoch - 3ms/step\n",
      "Epoch 696/2500\n",
      "11/11 - 0s - loss: 0.4782 - val_loss: 0.4510 - 28ms/epoch - 3ms/step\n",
      "Epoch 697/2500\n",
      "11/11 - 0s - loss: 0.4564 - val_loss: 0.4441 - 29ms/epoch - 3ms/step\n",
      "Epoch 698/2500\n",
      "11/11 - 0s - loss: 0.4657 - val_loss: 0.4539 - 29ms/epoch - 3ms/step\n",
      "Epoch 699/2500\n",
      "11/11 - 0s - loss: 0.4866 - val_loss: 0.4476 - 29ms/epoch - 3ms/step\n",
      "Epoch 700/2500\n",
      "11/11 - 0s - loss: 0.4711 - val_loss: 0.4407 - 29ms/epoch - 3ms/step\n",
      "Epoch 701/2500\n",
      "11/11 - 0s - loss: 0.4547 - val_loss: 0.4510 - 28ms/epoch - 3ms/step\n",
      "Epoch 702/2500\n",
      "11/11 - 0s - loss: 0.4546 - val_loss: 0.4462 - 29ms/epoch - 3ms/step\n",
      "Epoch 703/2500\n",
      "11/11 - 0s - loss: 0.4664 - val_loss: 0.4526 - 39ms/epoch - 4ms/step\n",
      "Epoch 704/2500\n",
      "11/11 - 0s - loss: 0.4641 - val_loss: 0.4489 - 29ms/epoch - 3ms/step\n",
      "Epoch 705/2500\n",
      "11/11 - 0s - loss: 0.4759 - val_loss: 0.4452 - 28ms/epoch - 3ms/step\n",
      "Epoch 706/2500\n",
      "11/11 - 0s - loss: 0.4835 - val_loss: 0.4572 - 29ms/epoch - 3ms/step\n",
      "Epoch 707/2500\n",
      "11/11 - 0s - loss: 0.4798 - val_loss: 0.4395 - 29ms/epoch - 3ms/step\n",
      "Epoch 708/2500\n",
      "11/11 - 0s - loss: 0.4531 - val_loss: 0.4480 - 29ms/epoch - 3ms/step\n",
      "Epoch 709/2500\n",
      "11/11 - 0s - loss: 0.4660 - val_loss: 0.4609 - 29ms/epoch - 3ms/step\n",
      "Epoch 710/2500\n",
      "11/11 - 0s - loss: 0.4714 - val_loss: 0.4472 - 29ms/epoch - 3ms/step\n",
      "Epoch 711/2500\n",
      "11/11 - 0s - loss: 0.4628 - val_loss: 0.4435 - 29ms/epoch - 3ms/step\n",
      "Epoch 712/2500\n",
      "11/11 - 0s - loss: 0.4699 - val_loss: 0.4411 - 28ms/epoch - 3ms/step\n",
      "Epoch 713/2500\n",
      "11/11 - 0s - loss: 0.4572 - val_loss: 0.4396 - 29ms/epoch - 3ms/step\n",
      "Epoch 714/2500\n",
      "11/11 - 0s - loss: 0.4647 - val_loss: 0.4452 - 29ms/epoch - 3ms/step\n",
      "Epoch 715/2500\n",
      "11/11 - 0s - loss: 0.4444 - val_loss: 0.4418 - 28ms/epoch - 3ms/step\n",
      "Epoch 716/2500\n",
      "11/11 - 0s - loss: 0.4487 - val_loss: 0.4621 - 29ms/epoch - 3ms/step\n",
      "Epoch 717/2500\n",
      "11/11 - 0s - loss: 0.4605 - val_loss: 0.4496 - 28ms/epoch - 3ms/step\n",
      "Epoch 718/2500\n",
      "11/11 - 0s - loss: 0.4602 - val_loss: 0.4403 - 29ms/epoch - 3ms/step\n",
      "Epoch 719/2500\n",
      "11/11 - 0s - loss: 0.4832 - val_loss: 0.4360 - 29ms/epoch - 3ms/step\n",
      "Epoch 720/2500\n",
      "11/11 - 0s - loss: 0.4763 - val_loss: 0.4412 - 28ms/epoch - 3ms/step\n",
      "Epoch 721/2500\n",
      "11/11 - 0s - loss: 0.4806 - val_loss: 0.4355 - 29ms/epoch - 3ms/step\n",
      "Epoch 722/2500\n",
      "11/11 - 0s - loss: 0.4768 - val_loss: 0.4355 - 28ms/epoch - 3ms/step\n",
      "Epoch 723/2500\n",
      "11/11 - 0s - loss: 0.4629 - val_loss: 0.4363 - 29ms/epoch - 3ms/step\n",
      "Epoch 724/2500\n",
      "11/11 - 0s - loss: 0.4703 - val_loss: 0.4316 - 28ms/epoch - 3ms/step\n",
      "Epoch 725/2500\n",
      "11/11 - 0s - loss: 0.4559 - val_loss: 0.4408 - 29ms/epoch - 3ms/step\n",
      "Epoch 726/2500\n",
      "11/11 - 0s - loss: 0.4784 - val_loss: 0.4705 - 29ms/epoch - 3ms/step\n",
      "Epoch 727/2500\n",
      "11/11 - 0s - loss: 0.4610 - val_loss: 0.4514 - 29ms/epoch - 3ms/step\n",
      "Epoch 728/2500\n",
      "11/11 - 0s - loss: 0.4734 - val_loss: 0.4394 - 29ms/epoch - 3ms/step\n",
      "Epoch 729/2500\n",
      "11/11 - 0s - loss: 0.4792 - val_loss: 0.4384 - 39ms/epoch - 4ms/step\n",
      "Epoch 730/2500\n",
      "11/11 - 0s - loss: 0.4742 - val_loss: 0.4339 - 30ms/epoch - 3ms/step\n",
      "Epoch 731/2500\n",
      "11/11 - 0s - loss: 0.4945 - val_loss: 0.4393 - 30ms/epoch - 3ms/step\n",
      "Epoch 732/2500\n",
      "11/11 - 0s - loss: 0.4648 - val_loss: 0.4404 - 29ms/epoch - 3ms/step\n",
      "Epoch 733/2500\n",
      "11/11 - 0s - loss: 0.4862 - val_loss: 0.4375 - 29ms/epoch - 3ms/step\n",
      "Epoch 734/2500\n",
      "11/11 - 0s - loss: 0.4798 - val_loss: 0.4488 - 29ms/epoch - 3ms/step\n",
      "Epoch 735/2500\n",
      "11/11 - 0s - loss: 0.4618 - val_loss: 0.4417 - 28ms/epoch - 3ms/step\n",
      "Epoch 736/2500\n",
      "11/11 - 0s - loss: 0.4702 - val_loss: 0.4331 - 29ms/epoch - 3ms/step\n",
      "Epoch 737/2500\n",
      "11/11 - 0s - loss: 0.4646 - val_loss: 0.4298 - 28ms/epoch - 3ms/step\n",
      "Epoch 738/2500\n",
      "11/11 - 0s - loss: 0.4788 - val_loss: 0.4478 - 29ms/epoch - 3ms/step\n",
      "Epoch 739/2500\n",
      "11/11 - 0s - loss: 0.4661 - val_loss: 0.4500 - 28ms/epoch - 3ms/step\n",
      "Epoch 740/2500\n",
      "11/11 - 0s - loss: 0.4714 - val_loss: 0.4368 - 29ms/epoch - 3ms/step\n",
      "Epoch 741/2500\n",
      "11/11 - 0s - loss: 0.4621 - val_loss: 0.4324 - 29ms/epoch - 3ms/step\n",
      "Epoch 742/2500\n",
      "11/11 - 0s - loss: 0.4606 - val_loss: 0.4454 - 30ms/epoch - 3ms/step\n",
      "Epoch 743/2500\n",
      "11/11 - 0s - loss: 0.4714 - val_loss: 0.4392 - 29ms/epoch - 3ms/step\n",
      "Epoch 744/2500\n",
      "11/11 - 0s - loss: 0.4654 - val_loss: 0.4420 - 29ms/epoch - 3ms/step\n",
      "Epoch 745/2500\n",
      "11/11 - 0s - loss: 0.4716 - val_loss: 0.4545 - 29ms/epoch - 3ms/step\n",
      "Epoch 746/2500\n",
      "11/11 - 0s - loss: 0.4601 - val_loss: 0.4430 - 29ms/epoch - 3ms/step\n",
      "Epoch 747/2500\n",
      "11/11 - 0s - loss: 0.4500 - val_loss: 0.4474 - 28ms/epoch - 3ms/step\n",
      "Epoch 748/2500\n",
      "11/11 - 0s - loss: 0.4635 - val_loss: 0.4359 - 28ms/epoch - 3ms/step\n",
      "Epoch 749/2500\n",
      "11/11 - 0s - loss: 0.4621 - val_loss: 0.4443 - 29ms/epoch - 3ms/step\n",
      "Epoch 750/2500\n",
      "11/11 - 0s - loss: 0.4541 - val_loss: 0.4465 - 28ms/epoch - 3ms/step\n",
      "Epoch 751/2500\n",
      "11/11 - 0s - loss: 0.4807 - val_loss: 0.4396 - 30ms/epoch - 3ms/step\n",
      "Epoch 752/2500\n",
      "11/11 - 0s - loss: 0.4538 - val_loss: 0.4541 - 29ms/epoch - 3ms/step\n",
      "Epoch 753/2500\n",
      "11/11 - 0s - loss: 0.4832 - val_loss: 0.4544 - 29ms/epoch - 3ms/step\n",
      "Epoch 754/2500\n",
      "11/11 - 0s - loss: 0.4468 - val_loss: 0.4418 - 29ms/epoch - 3ms/step\n",
      "Epoch 755/2500\n",
      "11/11 - 0s - loss: 0.4703 - val_loss: 0.4526 - 28ms/epoch - 3ms/step\n",
      "Epoch 756/2500\n",
      "11/11 - 0s - loss: 0.4727 - val_loss: 0.4618 - 37ms/epoch - 3ms/step\n",
      "Epoch 757/2500\n",
      "11/11 - 0s - loss: 0.4739 - val_loss: 0.4485 - 31ms/epoch - 3ms/step\n",
      "Epoch 758/2500\n",
      "11/11 - 0s - loss: 0.4551 - val_loss: 0.4456 - 29ms/epoch - 3ms/step\n",
      "Epoch 759/2500\n",
      "11/11 - 0s - loss: 0.4633 - val_loss: 0.4443 - 29ms/epoch - 3ms/step\n",
      "Epoch 760/2500\n",
      "11/11 - 0s - loss: 0.4856 - val_loss: 0.4502 - 29ms/epoch - 3ms/step\n",
      "Epoch 761/2500\n",
      "11/11 - 0s - loss: 0.4749 - val_loss: 0.4407 - 29ms/epoch - 3ms/step\n",
      "Epoch 762/2500\n",
      "11/11 - 0s - loss: 0.4740 - val_loss: 0.4427 - 29ms/epoch - 3ms/step\n",
      "Epoch 763/2500\n",
      "11/11 - 0s - loss: 0.4574 - val_loss: 0.4477 - 29ms/epoch - 3ms/step\n",
      "Epoch 764/2500\n",
      "11/11 - 0s - loss: 0.4602 - val_loss: 0.4584 - 29ms/epoch - 3ms/step\n",
      "Epoch 765/2500\n",
      "11/11 - 0s - loss: 0.4752 - val_loss: 0.4345 - 29ms/epoch - 3ms/step\n",
      "Epoch 766/2500\n",
      "11/11 - 0s - loss: 0.4640 - val_loss: 0.4517 - 28ms/epoch - 3ms/step\n",
      "Epoch 767/2500\n",
      "11/11 - 0s - loss: 0.4536 - val_loss: 0.4481 - 29ms/epoch - 3ms/step\n",
      "Epoch 768/2500\n",
      "11/11 - 0s - loss: 0.5041 - val_loss: 0.4447 - 29ms/epoch - 3ms/step\n",
      "Epoch 769/2500\n",
      "11/11 - 0s - loss: 0.4455 - val_loss: 0.4489 - 29ms/epoch - 3ms/step\n",
      "Epoch 770/2500\n",
      "11/11 - 0s - loss: 0.4502 - val_loss: 0.4521 - 29ms/epoch - 3ms/step\n",
      "Epoch 771/2500\n",
      "11/11 - 0s - loss: 0.4694 - val_loss: 0.4442 - 29ms/epoch - 3ms/step\n",
      "Epoch 772/2500\n",
      "11/11 - 0s - loss: 0.4633 - val_loss: 0.4445 - 29ms/epoch - 3ms/step\n",
      "Epoch 773/2500\n",
      "11/11 - 0s - loss: 0.4392 - val_loss: 0.4472 - 31ms/epoch - 3ms/step\n",
      "Epoch 774/2500\n",
      "11/11 - 0s - loss: 0.4430 - val_loss: 0.4427 - 28ms/epoch - 3ms/step\n",
      "Epoch 775/2500\n",
      "11/11 - 0s - loss: 0.4623 - val_loss: 0.4415 - 30ms/epoch - 3ms/step\n",
      "Epoch 776/2500\n",
      "11/11 - 0s - loss: 0.4699 - val_loss: 0.4409 - 29ms/epoch - 3ms/step\n",
      "Epoch 777/2500\n",
      "11/11 - 0s - loss: 0.4552 - val_loss: 0.4401 - 29ms/epoch - 3ms/step\n",
      "Epoch 778/2500\n",
      "11/11 - 0s - loss: 0.4671 - val_loss: 0.4538 - 29ms/epoch - 3ms/step\n",
      "Epoch 779/2500\n",
      "11/11 - 0s - loss: 0.4421 - val_loss: 0.4625 - 29ms/epoch - 3ms/step\n",
      "Epoch 780/2500\n",
      "11/11 - 0s - loss: 0.4671 - val_loss: 0.4564 - 29ms/epoch - 3ms/step\n",
      "Epoch 781/2500\n",
      "11/11 - 0s - loss: 0.4620 - val_loss: 0.4521 - 36ms/epoch - 3ms/step\n",
      "Epoch 782/2500\n",
      "11/11 - 0s - loss: 0.4430 - val_loss: 0.4555 - 29ms/epoch - 3ms/step\n",
      "Epoch 783/2500\n",
      "11/11 - 0s - loss: 0.4682 - val_loss: 0.4544 - 29ms/epoch - 3ms/step\n",
      "Epoch 784/2500\n",
      "11/11 - 0s - loss: 0.4329 - val_loss: 0.4509 - 28ms/epoch - 3ms/step\n",
      "Epoch 785/2500\n",
      "11/11 - 0s - loss: 0.4483 - val_loss: 0.4600 - 40ms/epoch - 4ms/step\n",
      "Epoch 786/2500\n",
      "11/11 - 0s - loss: 0.4647 - val_loss: 0.4489 - 29ms/epoch - 3ms/step\n",
      "Epoch 787/2500\n",
      "11/11 - 0s - loss: 0.4509 - val_loss: 0.4651 - 29ms/epoch - 3ms/step\n",
      "Epoch 788/2500\n",
      "11/11 - 0s - loss: 0.4741 - val_loss: 0.4524 - 29ms/epoch - 3ms/step\n",
      "Epoch 789/2500\n",
      "11/11 - 0s - loss: 0.4643 - val_loss: 0.4484 - 28ms/epoch - 3ms/step\n",
      "Epoch 790/2500\n",
      "11/11 - 0s - loss: 0.4484 - val_loss: 0.4576 - 29ms/epoch - 3ms/step\n",
      "Epoch 791/2500\n",
      "11/11 - 0s - loss: 0.4809 - val_loss: 0.4791 - 29ms/epoch - 3ms/step\n",
      "Epoch 792/2500\n",
      "11/11 - 0s - loss: 0.4602 - val_loss: 0.4531 - 29ms/epoch - 3ms/step\n",
      "Epoch 793/2500\n",
      "11/11 - 0s - loss: 0.4554 - val_loss: 0.4493 - 29ms/epoch - 3ms/step\n",
      "Epoch 794/2500\n",
      "11/11 - 0s - loss: 0.4604 - val_loss: 0.4641 - 29ms/epoch - 3ms/step\n",
      "Epoch 795/2500\n",
      "11/11 - 0s - loss: 0.4727 - val_loss: 0.4519 - 29ms/epoch - 3ms/step\n",
      "Epoch 796/2500\n",
      "11/11 - 0s - loss: 0.4584 - val_loss: 0.4495 - 29ms/epoch - 3ms/step\n",
      "Epoch 797/2500\n",
      "11/11 - 0s - loss: 0.4579 - val_loss: 0.4564 - 29ms/epoch - 3ms/step\n",
      "Epoch 798/2500\n",
      "11/11 - 0s - loss: 0.4623 - val_loss: 0.4549 - 29ms/epoch - 3ms/step\n",
      "Epoch 799/2500\n",
      "11/11 - 0s - loss: 0.4562 - val_loss: 0.4477 - 29ms/epoch - 3ms/step\n",
      "Epoch 800/2500\n",
      "11/11 - 0s - loss: 0.4447 - val_loss: 0.4569 - 29ms/epoch - 3ms/step\n",
      "Epoch 801/2500\n",
      "11/11 - 0s - loss: 0.4675 - val_loss: 0.4589 - 28ms/epoch - 3ms/step\n",
      "Epoch 802/2500\n",
      "11/11 - 0s - loss: 0.4748 - val_loss: 0.4476 - 28ms/epoch - 3ms/step\n",
      "Epoch 803/2500\n",
      "11/11 - 0s - loss: 0.4599 - val_loss: 0.4525 - 29ms/epoch - 3ms/step\n",
      "Epoch 804/2500\n",
      "11/11 - 0s - loss: 0.4869 - val_loss: 0.4600 - 29ms/epoch - 3ms/step\n",
      "Epoch 805/2500\n",
      "11/11 - 0s - loss: 0.4547 - val_loss: 0.4514 - 29ms/epoch - 3ms/step\n",
      "Epoch 806/2500\n",
      "11/11 - 0s - loss: 0.4475 - val_loss: 0.4497 - 29ms/epoch - 3ms/step\n",
      "Epoch 807/2500\n",
      "11/11 - 0s - loss: 0.4487 - val_loss: 0.4465 - 32ms/epoch - 3ms/step\n",
      "Epoch 808/2500\n",
      "11/11 - 0s - loss: 0.4675 - val_loss: 0.4590 - 30ms/epoch - 3ms/step\n",
      "Epoch 809/2500\n",
      "11/11 - 0s - loss: 0.4504 - val_loss: 0.4494 - 29ms/epoch - 3ms/step\n",
      "Epoch 810/2500\n",
      "11/11 - 0s - loss: 0.4495 - val_loss: 0.4508 - 31ms/epoch - 3ms/step\n",
      "Epoch 811/2500\n",
      "11/11 - 0s - loss: 0.4322 - val_loss: 0.4547 - 31ms/epoch - 3ms/step\n",
      "Epoch 812/2500\n",
      "11/11 - 0s - loss: 0.4621 - val_loss: 0.4578 - 31ms/epoch - 3ms/step\n",
      "Epoch 813/2500\n",
      "11/11 - 0s - loss: 0.4424 - val_loss: 0.4435 - 29ms/epoch - 3ms/step\n",
      "Epoch 814/2500\n",
      "11/11 - 0s - loss: 0.4531 - val_loss: 0.4495 - 30ms/epoch - 3ms/step\n",
      "Epoch 815/2500\n",
      "11/11 - 0s - loss: 0.4736 - val_loss: 0.4432 - 40ms/epoch - 4ms/step\n",
      "Epoch 816/2500\n",
      "11/11 - 0s - loss: 0.4549 - val_loss: 0.4626 - 29ms/epoch - 3ms/step\n",
      "Epoch 817/2500\n",
      "11/11 - 0s - loss: 0.4369 - val_loss: 0.4479 - 29ms/epoch - 3ms/step\n",
      "Epoch 818/2500\n",
      "11/11 - 0s - loss: 0.4770 - val_loss: 0.4484 - 30ms/epoch - 3ms/step\n",
      "Epoch 819/2500\n",
      "11/11 - 0s - loss: 0.4503 - val_loss: 0.4556 - 29ms/epoch - 3ms/step\n",
      "Epoch 820/2500\n",
      "11/11 - 0s - loss: 0.4606 - val_loss: 0.4559 - 31ms/epoch - 3ms/step\n",
      "Epoch 821/2500\n",
      "11/11 - 0s - loss: 0.4687 - val_loss: 0.4497 - 28ms/epoch - 3ms/step\n",
      "Epoch 822/2500\n",
      "11/11 - 0s - loss: 0.4588 - val_loss: 0.4665 - 29ms/epoch - 3ms/step\n",
      "Epoch 823/2500\n",
      "11/11 - 0s - loss: 0.4593 - val_loss: 0.4602 - 29ms/epoch - 3ms/step\n",
      "Epoch 824/2500\n",
      "11/11 - 0s - loss: 0.4647 - val_loss: 0.4558 - 30ms/epoch - 3ms/step\n",
      "Epoch 825/2500\n",
      "11/11 - 0s - loss: 0.4579 - val_loss: 0.4656 - 29ms/epoch - 3ms/step\n",
      "Epoch 826/2500\n",
      "11/11 - 0s - loss: 0.4724 - val_loss: 0.4523 - 29ms/epoch - 3ms/step\n",
      "Epoch 827/2500\n",
      "11/11 - 0s - loss: 0.4619 - val_loss: 0.4517 - 29ms/epoch - 3ms/step\n",
      "Epoch 828/2500\n",
      "11/11 - 0s - loss: 0.4702 - val_loss: 0.4639 - 29ms/epoch - 3ms/step\n",
      "Epoch 829/2500\n",
      "11/11 - 0s - loss: 0.4393 - val_loss: 0.4474 - 29ms/epoch - 3ms/step\n",
      "Epoch 830/2500\n",
      "11/11 - 0s - loss: 0.4638 - val_loss: 0.4505 - 30ms/epoch - 3ms/step\n",
      "Epoch 831/2500\n",
      "11/11 - 0s - loss: 0.4497 - val_loss: 0.4545 - 29ms/epoch - 3ms/step\n",
      "Epoch 832/2500\n",
      "11/11 - 0s - loss: 0.4621 - val_loss: 0.4503 - 30ms/epoch - 3ms/step\n",
      "Epoch 833/2500\n",
      "11/11 - 0s - loss: 0.4581 - val_loss: 0.4396 - 28ms/epoch - 3ms/step\n",
      "Epoch 834/2500\n",
      "11/11 - 0s - loss: 0.4610 - val_loss: 0.4426 - 29ms/epoch - 3ms/step\n",
      "Epoch 835/2500\n",
      "11/11 - 0s - loss: 0.4600 - val_loss: 0.4542 - 29ms/epoch - 3ms/step\n",
      "Epoch 836/2500\n",
      "11/11 - 0s - loss: 0.4482 - val_loss: 0.4485 - 29ms/epoch - 3ms/step\n",
      "Epoch 837/2500\n",
      "11/11 - 0s - loss: 0.4563 - val_loss: 0.4536 - 28ms/epoch - 3ms/step\n",
      "Epoch 838/2500\n",
      "11/11 - 0s - loss: 0.4332 - val_loss: 0.4561 - 29ms/epoch - 3ms/step\n",
      "Epoch 839/2500\n",
      "11/11 - 0s - loss: 0.4594 - val_loss: 0.4506 - 39ms/epoch - 4ms/step\n",
      "Epoch 840/2500\n",
      "11/11 - 0s - loss: 0.4614 - val_loss: 0.4481 - 28ms/epoch - 3ms/step\n",
      "Epoch 841/2500\n",
      "11/11 - 0s - loss: 0.4452 - val_loss: 0.4469 - 29ms/epoch - 3ms/step\n",
      "Epoch 842/2500\n",
      "11/11 - 0s - loss: 0.4368 - val_loss: 0.4599 - 29ms/epoch - 3ms/step\n",
      "Epoch 843/2500\n",
      "11/11 - 0s - loss: 0.4595 - val_loss: 0.4499 - 29ms/epoch - 3ms/step\n",
      "Epoch 844/2500\n",
      "11/11 - 0s - loss: 0.4660 - val_loss: 0.4500 - 30ms/epoch - 3ms/step\n",
      "Epoch 845/2500\n",
      "11/11 - 0s - loss: 0.4422 - val_loss: 0.4541 - 29ms/epoch - 3ms/step\n",
      "Epoch 846/2500\n",
      "11/11 - 0s - loss: 0.4390 - val_loss: 0.4395 - 29ms/epoch - 3ms/step\n",
      "Epoch 847/2500\n",
      "11/11 - 0s - loss: 0.4433 - val_loss: 0.4417 - 29ms/epoch - 3ms/step\n",
      "Epoch 848/2500\n",
      "11/11 - 0s - loss: 0.4710 - val_loss: 0.4495 - 29ms/epoch - 3ms/step\n",
      "Epoch 849/2500\n",
      "11/11 - 0s - loss: 0.4559 - val_loss: 0.4512 - 29ms/epoch - 3ms/step\n",
      "Epoch 850/2500\n",
      "11/11 - 0s - loss: 0.4493 - val_loss: 0.4422 - 29ms/epoch - 3ms/step\n",
      "Epoch 851/2500\n",
      "11/11 - 0s - loss: 0.4730 - val_loss: 0.4386 - 29ms/epoch - 3ms/step\n",
      "Epoch 852/2500\n",
      "11/11 - 0s - loss: 0.4377 - val_loss: 0.4535 - 29ms/epoch - 3ms/step\n",
      "Epoch 853/2500\n",
      "11/11 - 0s - loss: 0.4410 - val_loss: 0.4527 - 30ms/epoch - 3ms/step\n",
      "Epoch 854/2500\n",
      "11/11 - 0s - loss: 0.4536 - val_loss: 0.4605 - 29ms/epoch - 3ms/step\n",
      "Epoch 855/2500\n",
      "11/11 - 0s - loss: 0.4338 - val_loss: 0.4500 - 29ms/epoch - 3ms/step\n",
      "Epoch 856/2500\n",
      "11/11 - 0s - loss: 0.4369 - val_loss: 0.4511 - 29ms/epoch - 3ms/step\n",
      "Epoch 857/2500\n",
      "11/11 - 0s - loss: 0.4297 - val_loss: 0.4535 - 29ms/epoch - 3ms/step\n",
      "Epoch 858/2500\n",
      "11/11 - 0s - loss: 0.4448 - val_loss: 0.4554 - 29ms/epoch - 3ms/step\n",
      "Epoch 859/2500\n",
      "11/11 - 0s - loss: 0.4422 - val_loss: 0.4653 - 29ms/epoch - 3ms/step\n",
      "Epoch 860/2500\n",
      "11/11 - 0s - loss: 0.4467 - val_loss: 0.4536 - 29ms/epoch - 3ms/step\n",
      "Epoch 861/2500\n",
      "11/11 - 0s - loss: 0.4493 - val_loss: 0.4550 - 30ms/epoch - 3ms/step\n",
      "Epoch 862/2500\n",
      "11/11 - 0s - loss: 0.4359 - val_loss: 0.4653 - 31ms/epoch - 3ms/step\n",
      "Epoch 863/2500\n",
      "11/11 - 0s - loss: 0.4411 - val_loss: 0.4566 - 30ms/epoch - 3ms/step\n",
      "Epoch 864/2500\n",
      "11/11 - 0s - loss: 0.4499 - val_loss: 0.4560 - 30ms/epoch - 3ms/step\n",
      "Epoch 865/2500\n",
      "11/11 - 0s - loss: 0.4349 - val_loss: 0.4511 - 29ms/epoch - 3ms/step\n",
      "Epoch 866/2500\n",
      "11/11 - 0s - loss: 0.4422 - val_loss: 0.4555 - 30ms/epoch - 3ms/step\n",
      "Epoch 867/2500\n",
      "11/11 - 0s - loss: 0.4419 - val_loss: 0.4438 - 33ms/epoch - 3ms/step\n",
      "Epoch 868/2500\n",
      "11/11 - 0s - loss: 0.4468 - val_loss: 0.4538 - 30ms/epoch - 3ms/step\n",
      "Epoch 869/2500\n",
      "11/11 - 0s - loss: 0.4501 - val_loss: 0.4508 - 33ms/epoch - 3ms/step\n",
      "Epoch 870/2500\n",
      "11/11 - 0s - loss: 0.4521 - val_loss: 0.4452 - 34ms/epoch - 3ms/step\n",
      "Epoch 871/2500\n",
      "11/11 - 0s - loss: 0.4513 - val_loss: 0.4467 - 29ms/epoch - 3ms/step\n",
      "Epoch 872/2500\n",
      "11/11 - 0s - loss: 0.4396 - val_loss: 0.4531 - 30ms/epoch - 3ms/step\n",
      "Epoch 873/2500\n",
      "11/11 - 0s - loss: 0.4601 - val_loss: 0.4438 - 31ms/epoch - 3ms/step\n",
      "Epoch 874/2500\n",
      "11/11 - 0s - loss: 0.4255 - val_loss: 0.4442 - 30ms/epoch - 3ms/step\n",
      "Epoch 875/2500\n",
      "11/11 - 0s - loss: 0.4384 - val_loss: 0.4462 - 29ms/epoch - 3ms/step\n",
      "Epoch 876/2500\n",
      "11/11 - 0s - loss: 0.4564 - val_loss: 0.4792 - 29ms/epoch - 3ms/step\n",
      "Epoch 877/2500\n",
      "11/11 - 0s - loss: 0.4384 - val_loss: 0.4484 - 29ms/epoch - 3ms/step\n",
      "Epoch 878/2500\n",
      "11/11 - 0s - loss: 0.4642 - val_loss: 0.4375 - 29ms/epoch - 3ms/step\n",
      "Epoch 879/2500\n",
      "11/11 - 0s - loss: 0.4564 - val_loss: 0.4424 - 29ms/epoch - 3ms/step\n",
      "Epoch 880/2500\n",
      "11/11 - 0s - loss: 0.4342 - val_loss: 0.4389 - 28ms/epoch - 3ms/step\n",
      "Epoch 881/2500\n",
      "11/11 - 0s - loss: 0.4431 - val_loss: 0.4430 - 30ms/epoch - 3ms/step\n",
      "Epoch 882/2500\n",
      "11/11 - 0s - loss: 0.4366 - val_loss: 0.4477 - 29ms/epoch - 3ms/step\n",
      "Epoch 883/2500\n",
      "11/11 - 0s - loss: 0.4409 - val_loss: 0.4395 - 28ms/epoch - 3ms/step\n",
      "Epoch 884/2500\n",
      "11/11 - 0s - loss: 0.4665 - val_loss: 0.4522 - 29ms/epoch - 3ms/step\n",
      "Epoch 885/2500\n",
      "11/11 - 0s - loss: 0.4502 - val_loss: 0.4506 - 29ms/epoch - 3ms/step\n",
      "Epoch 886/2500\n",
      "11/11 - 0s - loss: 0.4407 - val_loss: 0.4491 - 28ms/epoch - 3ms/step\n",
      "Epoch 887/2500\n",
      "11/11 - 0s - loss: 0.4334 - val_loss: 0.4548 - 29ms/epoch - 3ms/step\n",
      "Epoch 888/2500\n",
      "11/11 - 0s - loss: 0.4360 - val_loss: 0.4428 - 28ms/epoch - 3ms/step\n",
      "Epoch 889/2500\n",
      "11/11 - 0s - loss: 0.4518 - val_loss: 0.4484 - 28ms/epoch - 3ms/step\n",
      "Epoch 890/2500\n",
      "11/11 - 0s - loss: 0.4532 - val_loss: 0.4422 - 30ms/epoch - 3ms/step\n",
      "Epoch 891/2500\n",
      "11/11 - 0s - loss: 0.4367 - val_loss: 0.4402 - 30ms/epoch - 3ms/step\n",
      "Epoch 892/2500\n",
      "11/11 - 0s - loss: 0.4405 - val_loss: 0.4486 - 29ms/epoch - 3ms/step\n",
      "Epoch 893/2500\n",
      "11/11 - 0s - loss: 0.4517 - val_loss: 0.4400 - 29ms/epoch - 3ms/step\n",
      "Epoch 894/2500\n",
      "11/11 - 0s - loss: 0.4409 - val_loss: 0.4426 - 29ms/epoch - 3ms/step\n",
      "Epoch 895/2500\n",
      "11/11 - 0s - loss: 0.4620 - val_loss: 0.4481 - 28ms/epoch - 3ms/step\n",
      "Epoch 896/2500\n",
      "11/11 - 0s - loss: 0.4290 - val_loss: 0.4370 - 29ms/epoch - 3ms/step\n",
      "Epoch 897/2500\n",
      "11/11 - 0s - loss: 0.4383 - val_loss: 0.4480 - 29ms/epoch - 3ms/step\n",
      "Epoch 898/2500\n",
      "11/11 - 0s - loss: 0.4491 - val_loss: 0.4425 - 29ms/epoch - 3ms/step\n",
      "Epoch 899/2500\n",
      "11/11 - 0s - loss: 0.4349 - val_loss: 0.4428 - 29ms/epoch - 3ms/step\n",
      "Epoch 900/2500\n",
      "11/11 - 0s - loss: 0.4258 - val_loss: 0.4425 - 30ms/epoch - 3ms/step\n",
      "Epoch 901/2500\n",
      "11/11 - 0s - loss: 0.4395 - val_loss: 0.4395 - 29ms/epoch - 3ms/step\n",
      "Epoch 902/2500\n",
      "11/11 - 0s - loss: 0.4431 - val_loss: 0.4371 - 29ms/epoch - 3ms/step\n",
      "Epoch 903/2500\n",
      "11/11 - 0s - loss: 0.4394 - val_loss: 0.4477 - 29ms/epoch - 3ms/step\n",
      "Epoch 904/2500\n",
      "11/11 - 0s - loss: 0.4421 - val_loss: 0.4436 - 41ms/epoch - 4ms/step\n",
      "Epoch 905/2500\n",
      "11/11 - 0s - loss: 0.4489 - val_loss: 0.4555 - 29ms/epoch - 3ms/step\n",
      "Epoch 906/2500\n",
      "11/11 - 0s - loss: 0.4335 - val_loss: 0.4495 - 29ms/epoch - 3ms/step\n",
      "Epoch 907/2500\n",
      "11/11 - 0s - loss: 0.4354 - val_loss: 0.4515 - 29ms/epoch - 3ms/step\n",
      "Epoch 908/2500\n",
      "11/11 - 0s - loss: 0.4664 - val_loss: 0.4534 - 29ms/epoch - 3ms/step\n",
      "Epoch 909/2500\n",
      "11/11 - 0s - loss: 0.4571 - val_loss: 0.4478 - 28ms/epoch - 3ms/step\n",
      "Epoch 910/2500\n",
      "11/11 - 0s - loss: 0.4525 - val_loss: 0.4485 - 29ms/epoch - 3ms/step\n",
      "Epoch 911/2500\n",
      "11/11 - 0s - loss: 0.4448 - val_loss: 0.4441 - 29ms/epoch - 3ms/step\n",
      "Epoch 912/2500\n",
      "11/11 - 0s - loss: 0.4445 - val_loss: 0.4414 - 29ms/epoch - 3ms/step\n",
      "Epoch 913/2500\n",
      "11/11 - 0s - loss: 0.4336 - val_loss: 0.4455 - 29ms/epoch - 3ms/step\n",
      "Epoch 914/2500\n",
      "11/11 - 0s - loss: 0.4465 - val_loss: 0.4433 - 28ms/epoch - 3ms/step\n",
      "Epoch 915/2500\n",
      "11/11 - 0s - loss: 0.4488 - val_loss: 0.4407 - 30ms/epoch - 3ms/step\n",
      "Epoch 916/2500\n",
      "11/11 - 0s - loss: 0.4496 - val_loss: 0.4419 - 29ms/epoch - 3ms/step\n",
      "Epoch 917/2500\n",
      "11/11 - 0s - loss: 0.4571 - val_loss: 0.4636 - 29ms/epoch - 3ms/step\n",
      "Epoch 918/2500\n",
      "11/11 - 0s - loss: 0.4695 - val_loss: 0.4417 - 28ms/epoch - 3ms/step\n",
      "Epoch 919/2500\n",
      "11/11 - 0s - loss: 0.4464 - val_loss: 0.4483 - 29ms/epoch - 3ms/step\n",
      "Epoch 920/2500\n",
      "11/11 - 0s - loss: 0.4391 - val_loss: 0.4509 - 29ms/epoch - 3ms/step\n",
      "Epoch 921/2500\n",
      "11/11 - 0s - loss: 0.4414 - val_loss: 0.4388 - 30ms/epoch - 3ms/step\n",
      "Epoch 922/2500\n",
      "11/11 - 0s - loss: 0.4324 - val_loss: 0.4379 - 29ms/epoch - 3ms/step\n",
      "Epoch 923/2500\n",
      "11/11 - 0s - loss: 0.4536 - val_loss: 0.4489 - 29ms/epoch - 3ms/step\n",
      "Epoch 924/2500\n",
      "11/11 - 0s - loss: 0.4435 - val_loss: 0.4478 - 29ms/epoch - 3ms/step\n",
      "Epoch 925/2500\n",
      "11/11 - 0s - loss: 0.4321 - val_loss: 0.4475 - 28ms/epoch - 3ms/step\n",
      "Epoch 926/2500\n",
      "11/11 - 0s - loss: 0.4518 - val_loss: 0.4545 - 29ms/epoch - 3ms/step\n",
      "Epoch 927/2500\n",
      "11/11 - 0s - loss: 0.4526 - val_loss: 0.4353 - 28ms/epoch - 3ms/step\n",
      "Epoch 928/2500\n",
      "11/11 - 0s - loss: 0.4538 - val_loss: 0.4500 - 29ms/epoch - 3ms/step\n",
      "Epoch 929/2500\n",
      "11/11 - 0s - loss: 0.4383 - val_loss: 0.4495 - 29ms/epoch - 3ms/step\n",
      "Epoch 930/2500\n",
      "11/11 - 0s - loss: 0.4591 - val_loss: 0.4403 - 28ms/epoch - 3ms/step\n",
      "Epoch 931/2500\n",
      "11/11 - 0s - loss: 0.4420 - val_loss: 0.4470 - 40ms/epoch - 4ms/step\n",
      "Epoch 932/2500\n",
      "11/11 - 0s - loss: 0.4174 - val_loss: 0.4448 - 29ms/epoch - 3ms/step\n",
      "Epoch 933/2500\n",
      "11/11 - 0s - loss: 0.4480 - val_loss: 0.4589 - 28ms/epoch - 3ms/step\n",
      "Epoch 934/2500\n",
      "11/11 - 0s - loss: 0.4491 - val_loss: 0.4505 - 29ms/epoch - 3ms/step\n",
      "Epoch 935/2500\n",
      "11/11 - 0s - loss: 0.4480 - val_loss: 0.4430 - 29ms/epoch - 3ms/step\n",
      "Epoch 936/2500\n",
      "11/11 - 0s - loss: 0.4368 - val_loss: 0.4383 - 29ms/epoch - 3ms/step\n",
      "Epoch 937/2500\n",
      "11/11 - 0s - loss: 0.4488 - val_loss: 0.4514 - 29ms/epoch - 3ms/step\n",
      "Epoch 938/2500\n",
      "11/11 - 0s - loss: 0.4412 - val_loss: 0.4406 - 28ms/epoch - 3ms/step\n",
      "Epoch 939/2500\n",
      "11/11 - 0s - loss: 0.4616 - val_loss: 0.4432 - 29ms/epoch - 3ms/step\n",
      "Epoch 940/2500\n",
      "11/11 - 0s - loss: 0.4511 - val_loss: 0.4337 - 29ms/epoch - 3ms/step\n",
      "Epoch 941/2500\n",
      "11/11 - 0s - loss: 0.4370 - val_loss: 0.4415 - 29ms/epoch - 3ms/step\n",
      "Epoch 942/2500\n",
      "11/11 - 0s - loss: 0.4435 - val_loss: 0.4351 - 28ms/epoch - 3ms/step\n",
      "Epoch 943/2500\n",
      "11/11 - 0s - loss: 0.4450 - val_loss: 0.4399 - 29ms/epoch - 3ms/step\n",
      "Epoch 944/2500\n",
      "11/11 - 0s - loss: 0.4400 - val_loss: 0.4437 - 29ms/epoch - 3ms/step\n",
      "Epoch 945/2500\n",
      "11/11 - 0s - loss: 0.4359 - val_loss: 0.4413 - 30ms/epoch - 3ms/step\n",
      "Epoch 946/2500\n",
      "11/11 - 0s - loss: 0.4314 - val_loss: 0.4478 - 28ms/epoch - 3ms/step\n",
      "Epoch 947/2500\n",
      "11/11 - 0s - loss: 0.4324 - val_loss: 0.4456 - 29ms/epoch - 3ms/step\n",
      "Epoch 948/2500\n",
      "11/11 - 0s - loss: 0.4594 - val_loss: 0.4469 - 28ms/epoch - 3ms/step\n",
      "Epoch 949/2500\n",
      "11/11 - 0s - loss: 0.4432 - val_loss: 0.4379 - 28ms/epoch - 3ms/step\n",
      "Epoch 950/2500\n",
      "11/11 - 0s - loss: 0.4387 - val_loss: 0.4360 - 29ms/epoch - 3ms/step\n",
      "Epoch 951/2500\n",
      "11/11 - 0s - loss: 0.4414 - val_loss: 0.4421 - 28ms/epoch - 3ms/step\n",
      "Epoch 952/2500\n",
      "11/11 - 0s - loss: 0.4215 - val_loss: 0.4489 - 29ms/epoch - 3ms/step\n",
      "Epoch 953/2500\n",
      "11/11 - 0s - loss: 0.4543 - val_loss: 0.4395 - 29ms/epoch - 3ms/step\n",
      "Epoch 954/2500\n",
      "11/11 - 0s - loss: 0.4427 - val_loss: 0.4409 - 28ms/epoch - 3ms/step\n",
      "Epoch 955/2500\n",
      "11/11 - 0s - loss: 0.4488 - val_loss: 0.4481 - 29ms/epoch - 3ms/step\n",
      "Epoch 956/2500\n",
      "11/11 - 0s - loss: 0.4382 - val_loss: 0.4411 - 28ms/epoch - 3ms/step\n",
      "Epoch 957/2500\n",
      "11/11 - 0s - loss: 0.4256 - val_loss: 0.4459 - 35ms/epoch - 3ms/step\n",
      "Epoch 958/2500\n",
      "11/11 - 0s - loss: 0.4310 - val_loss: 0.4412 - 31ms/epoch - 3ms/step\n",
      "Epoch 959/2500\n",
      "11/11 - 0s - loss: 0.4462 - val_loss: 0.4336 - 29ms/epoch - 3ms/step\n",
      "Epoch 960/2500\n",
      "11/11 - 0s - loss: 0.4314 - val_loss: 0.4492 - 29ms/epoch - 3ms/step\n",
      "Epoch 961/2500\n",
      "11/11 - 0s - loss: 0.4319 - val_loss: 0.4353 - 28ms/epoch - 3ms/step\n",
      "Epoch 962/2500\n",
      "11/11 - 0s - loss: 0.4362 - val_loss: 0.4454 - 29ms/epoch - 3ms/step\n",
      "Epoch 963/2500\n",
      "11/11 - 0s - loss: 0.4337 - val_loss: 0.4392 - 29ms/epoch - 3ms/step\n",
      "Epoch 964/2500\n",
      "11/11 - 0s - loss: 0.4345 - val_loss: 0.4288 - 29ms/epoch - 3ms/step\n",
      "Epoch 965/2500\n",
      "11/11 - 0s - loss: 0.4569 - val_loss: 0.4355 - 29ms/epoch - 3ms/step\n",
      "Epoch 966/2500\n",
      "11/11 - 0s - loss: 0.4487 - val_loss: 0.4365 - 29ms/epoch - 3ms/step\n",
      "Epoch 967/2500\n",
      "11/11 - 0s - loss: 0.4237 - val_loss: 0.4281 - 28ms/epoch - 3ms/step\n",
      "Epoch 968/2500\n",
      "11/11 - 0s - loss: 0.4364 - val_loss: 0.4332 - 29ms/epoch - 3ms/step\n",
      "Epoch 969/2500\n",
      "11/11 - 0s - loss: 0.4459 - val_loss: 0.4372 - 29ms/epoch - 3ms/step\n",
      "Epoch 970/2500\n",
      "11/11 - 0s - loss: 0.4329 - val_loss: 0.4459 - 28ms/epoch - 3ms/step\n",
      "Epoch 971/2500\n",
      "11/11 - 0s - loss: 0.4375 - val_loss: 0.4320 - 29ms/epoch - 3ms/step\n",
      "Epoch 972/2500\n",
      "11/11 - 0s - loss: 0.4575 - val_loss: 0.4370 - 29ms/epoch - 3ms/step\n",
      "Epoch 973/2500\n",
      "11/11 - 0s - loss: 0.4329 - val_loss: 0.4461 - 29ms/epoch - 3ms/step\n",
      "Epoch 974/2500\n",
      "11/11 - 0s - loss: 0.4335 - val_loss: 0.4404 - 29ms/epoch - 3ms/step\n",
      "Epoch 975/2500\n",
      "11/11 - 0s - loss: 0.4498 - val_loss: 0.4453 - 29ms/epoch - 3ms/step\n",
      "Epoch 976/2500\n",
      "11/11 - 0s - loss: 0.4377 - val_loss: 0.4500 - 29ms/epoch - 3ms/step\n",
      "Epoch 977/2500\n",
      "11/11 - 0s - loss: 0.4409 - val_loss: 0.4425 - 29ms/epoch - 3ms/step\n",
      "Epoch 978/2500\n",
      "11/11 - 0s - loss: 0.4467 - val_loss: 0.4624 - 29ms/epoch - 3ms/step\n",
      "Epoch 979/2500\n",
      "11/11 - 0s - loss: 0.4415 - val_loss: 0.4444 - 29ms/epoch - 3ms/step\n",
      "Epoch 980/2500\n",
      "11/11 - 0s - loss: 0.4329 - val_loss: 0.4423 - 29ms/epoch - 3ms/step\n",
      "Epoch 981/2500\n",
      "11/11 - 0s - loss: 0.4673 - val_loss: 0.4472 - 28ms/epoch - 3ms/step\n",
      "Epoch 982/2500\n",
      "11/11 - 0s - loss: 0.4301 - val_loss: 0.4459 - 28ms/epoch - 3ms/step\n",
      "Epoch 983/2500\n",
      "11/11 - 0s - loss: 0.4484 - val_loss: 0.4487 - 28ms/epoch - 3ms/step\n",
      "Epoch 984/2500\n",
      "11/11 - 0s - loss: 0.4379 - val_loss: 0.4424 - 29ms/epoch - 3ms/step\n",
      "Epoch 985/2500\n",
      "11/11 - 0s - loss: 0.4327 - val_loss: 0.4438 - 28ms/epoch - 3ms/step\n",
      "Epoch 986/2500\n",
      "11/11 - 0s - loss: 0.4433 - val_loss: 0.4421 - 29ms/epoch - 3ms/step\n",
      "Epoch 987/2500\n",
      "11/11 - 0s - loss: 0.4448 - val_loss: 0.4415 - 29ms/epoch - 3ms/step\n",
      "Epoch 988/2500\n",
      "11/11 - 0s - loss: 0.4346 - val_loss: 0.4392 - 29ms/epoch - 3ms/step\n",
      "Epoch 989/2500\n",
      "11/11 - 0s - loss: 0.4199 - val_loss: 0.4414 - 30ms/epoch - 3ms/step\n",
      "Epoch 990/2500\n",
      "11/11 - 0s - loss: 0.4326 - val_loss: 0.4580 - 29ms/epoch - 3ms/step\n",
      "Epoch 991/2500\n",
      "11/11 - 0s - loss: 0.4483 - val_loss: 0.4496 - 29ms/epoch - 3ms/step\n",
      "Epoch 992/2500\n",
      "11/11 - 0s - loss: 0.4459 - val_loss: 0.4362 - 28ms/epoch - 3ms/step\n",
      "Epoch 993/2500\n",
      "11/11 - 0s - loss: 0.4405 - val_loss: 0.4370 - 29ms/epoch - 3ms/step\n",
      "Epoch 994/2500\n",
      "11/11 - 0s - loss: 0.4494 - val_loss: 0.4430 - 29ms/epoch - 3ms/step\n",
      "Epoch 995/2500\n",
      "11/11 - 0s - loss: 0.4425 - val_loss: 0.4424 - 28ms/epoch - 3ms/step\n",
      "Epoch 996/2500\n",
      "11/11 - 0s - loss: 0.4372 - val_loss: 0.4313 - 40ms/epoch - 4ms/step\n",
      "Epoch 997/2500\n",
      "11/11 - 0s - loss: 0.4484 - val_loss: 0.4469 - 29ms/epoch - 3ms/step\n",
      "Epoch 998/2500\n",
      "11/11 - 0s - loss: 0.4309 - val_loss: 0.4244 - 29ms/epoch - 3ms/step\n",
      "Epoch 999/2500\n",
      "11/11 - 0s - loss: 0.4249 - val_loss: 0.4250 - 28ms/epoch - 3ms/step\n",
      "Epoch 1000/2500\n",
      "11/11 - 0s - loss: 0.4426 - val_loss: 0.4518 - 29ms/epoch - 3ms/step\n",
      "Epoch 1001/2500\n",
      "11/11 - 0s - loss: 0.4430 - val_loss: 0.4276 - 29ms/epoch - 3ms/step\n",
      "Epoch 1002/2500\n",
      "11/11 - 0s - loss: 0.4431 - val_loss: 0.4298 - 28ms/epoch - 3ms/step\n",
      "Epoch 1003/2500\n",
      "11/11 - 0s - loss: 0.4381 - val_loss: 0.4600 - 29ms/epoch - 3ms/step\n",
      "Epoch 1004/2500\n",
      "11/11 - 0s - loss: 0.4290 - val_loss: 0.4377 - 29ms/epoch - 3ms/step\n",
      "Epoch 1005/2500\n",
      "11/11 - 0s - loss: 0.4572 - val_loss: 0.4375 - 29ms/epoch - 3ms/step\n",
      "Epoch 1006/2500\n",
      "11/11 - 0s - loss: 0.4189 - val_loss: 0.4472 - 29ms/epoch - 3ms/step\n",
      "Epoch 1007/2500\n",
      "11/11 - 0s - loss: 0.4406 - val_loss: 0.4383 - 29ms/epoch - 3ms/step\n",
      "Epoch 1008/2500\n",
      "11/11 - 0s - loss: 0.4411 - val_loss: 0.4387 - 29ms/epoch - 3ms/step\n",
      "Epoch 1009/2500\n",
      "11/11 - 0s - loss: 0.4473 - val_loss: 0.4556 - 28ms/epoch - 3ms/step\n",
      "Epoch 1010/2500\n",
      "11/11 - 0s - loss: 0.4400 - val_loss: 0.4366 - 29ms/epoch - 3ms/step\n",
      "Epoch 1011/2500\n",
      "11/11 - 0s - loss: 0.4341 - val_loss: 0.4367 - 29ms/epoch - 3ms/step\n",
      "Epoch 1012/2500\n",
      "11/11 - 0s - loss: 0.4417 - val_loss: 0.4485 - 31ms/epoch - 3ms/step\n",
      "Epoch 1013/2500\n",
      "11/11 - 0s - loss: 0.4257 - val_loss: 0.4522 - 29ms/epoch - 3ms/step\n",
      "Epoch 1014/2500\n",
      "11/11 - 0s - loss: 0.4094 - val_loss: 0.4425 - 29ms/epoch - 3ms/step\n",
      "Epoch 1015/2500\n",
      "11/11 - 0s - loss: 0.4329 - val_loss: 0.4393 - 29ms/epoch - 3ms/step\n",
      "Epoch 1016/2500\n",
      "11/11 - 0s - loss: 0.4339 - val_loss: 0.4367 - 29ms/epoch - 3ms/step\n",
      "Epoch 1017/2500\n",
      "11/11 - 0s - loss: 0.4507 - val_loss: 0.4402 - 29ms/epoch - 3ms/step\n",
      "Epoch 1018/2500\n",
      "11/11 - 0s - loss: 0.4256 - val_loss: 0.4465 - 31ms/epoch - 3ms/step\n",
      "Epoch 1019/2500\n",
      "11/11 - 0s - loss: 0.4345 - val_loss: 0.4464 - 29ms/epoch - 3ms/step\n",
      "Epoch 1020/2500\n",
      "11/11 - 0s - loss: 0.4178 - val_loss: 0.4421 - 29ms/epoch - 3ms/step\n",
      "Epoch 1021/2500\n",
      "11/11 - 0s - loss: 0.4243 - val_loss: 0.4355 - 29ms/epoch - 3ms/step\n",
      "Epoch 1022/2500\n",
      "11/11 - 0s - loss: 0.4405 - val_loss: 0.4361 - 29ms/epoch - 3ms/step\n",
      "Epoch 1023/2500\n",
      "11/11 - 0s - loss: 0.4368 - val_loss: 0.4547 - 28ms/epoch - 3ms/step\n",
      "Epoch 1024/2500\n",
      "11/11 - 0s - loss: 0.4539 - val_loss: 0.4438 - 29ms/epoch - 3ms/step\n",
      "Epoch 1025/2500\n",
      "11/11 - 0s - loss: 0.4310 - val_loss: 0.4413 - 29ms/epoch - 3ms/step\n",
      "Epoch 1026/2500\n",
      "11/11 - 0s - loss: 0.4486 - val_loss: 0.4563 - 29ms/epoch - 3ms/step\n",
      "Epoch 1027/2500\n",
      "11/11 - 0s - loss: 0.4280 - val_loss: 0.4449 - 29ms/epoch - 3ms/step\n",
      "Epoch 1028/2500\n",
      "11/11 - 0s - loss: 0.4288 - val_loss: 0.4366 - 28ms/epoch - 3ms/step\n",
      "Epoch 1029/2500\n",
      "11/11 - 0s - loss: 0.4228 - val_loss: 0.4364 - 29ms/epoch - 3ms/step\n",
      "Epoch 1030/2500\n",
      "11/11 - 0s - loss: 0.4446 - val_loss: 0.4406 - 40ms/epoch - 4ms/step\n",
      "Epoch 1031/2500\n",
      "11/11 - 0s - loss: 0.4462 - val_loss: 0.4494 - 30ms/epoch - 3ms/step\n",
      "Epoch 1032/2500\n",
      "11/11 - 0s - loss: 0.4422 - val_loss: 0.4412 - 29ms/epoch - 3ms/step\n",
      "Epoch 1033/2500\n",
      "11/11 - 0s - loss: 0.4270 - val_loss: 0.4459 - 28ms/epoch - 3ms/step\n",
      "Epoch 1034/2500\n",
      "11/11 - 0s - loss: 0.4220 - val_loss: 0.4471 - 29ms/epoch - 3ms/step\n",
      "Epoch 1035/2500\n",
      "11/11 - 0s - loss: 0.4212 - val_loss: 0.4415 - 28ms/epoch - 3ms/step\n",
      "Epoch 1036/2500\n",
      "11/11 - 0s - loss: 0.4352 - val_loss: 0.4485 - 28ms/epoch - 3ms/step\n",
      "Epoch 1037/2500\n",
      "11/11 - 0s - loss: 0.4210 - val_loss: 0.4354 - 29ms/epoch - 3ms/step\n",
      "Epoch 1038/2500\n",
      "11/11 - 0s - loss: 0.4264 - val_loss: 0.4464 - 29ms/epoch - 3ms/step\n",
      "Epoch 1039/2500\n",
      "11/11 - 0s - loss: 0.4134 - val_loss: 0.4445 - 29ms/epoch - 3ms/step\n",
      "Epoch 1040/2500\n",
      "11/11 - 0s - loss: 0.4140 - val_loss: 0.4525 - 29ms/epoch - 3ms/step\n",
      "Epoch 1041/2500\n",
      "11/11 - 0s - loss: 0.4232 - val_loss: 0.4425 - 28ms/epoch - 3ms/step\n",
      "Epoch 1042/2500\n",
      "11/11 - 0s - loss: 0.4374 - val_loss: 0.4350 - 30ms/epoch - 3ms/step\n",
      "Epoch 1043/2500\n",
      "11/11 - 0s - loss: 0.4308 - val_loss: 0.4392 - 28ms/epoch - 3ms/step\n",
      "Epoch 1044/2500\n",
      "11/11 - 0s - loss: 0.4338 - val_loss: 0.4386 - 32ms/epoch - 3ms/step\n",
      "Epoch 1045/2500\n",
      "11/11 - 0s - loss: 0.4271 - val_loss: 0.4442 - 28ms/epoch - 3ms/step\n",
      "Epoch 1046/2500\n",
      "11/11 - 0s - loss: 0.4138 - val_loss: 0.4360 - 29ms/epoch - 3ms/step\n",
      "Epoch 1047/2500\n",
      "11/11 - 0s - loss: 0.4315 - val_loss: 0.4365 - 29ms/epoch - 3ms/step\n",
      "Epoch 1048/2500\n",
      "11/11 - 0s - loss: 0.4312 - val_loss: 0.4496 - 28ms/epoch - 3ms/step\n",
      "Epoch 1049/2500\n",
      "11/11 - 0s - loss: 0.4389 - val_loss: 0.4366 - 29ms/epoch - 3ms/step\n",
      "Epoch 1050/2500\n",
      "11/11 - 0s - loss: 0.4194 - val_loss: 0.4430 - 29ms/epoch - 3ms/step\n",
      "Epoch 1051/2500\n",
      "11/11 - 0s - loss: 0.4328 - val_loss: 0.4528 - 28ms/epoch - 3ms/step\n",
      "Epoch 1052/2500\n",
      "11/11 - 0s - loss: 0.4320 - val_loss: 0.4375 - 29ms/epoch - 3ms/step\n",
      "Epoch 1053/2500\n",
      "11/11 - 0s - loss: 0.4288 - val_loss: 0.4301 - 29ms/epoch - 3ms/step\n",
      "Epoch 1054/2500\n",
      "11/11 - 0s - loss: 0.4212 - val_loss: 0.4388 - 29ms/epoch - 3ms/step\n",
      "Epoch 1055/2500\n",
      "11/11 - 0s - loss: 0.4295 - val_loss: 0.4335 - 28ms/epoch - 3ms/step\n",
      "Epoch 1056/2500\n",
      "11/11 - 0s - loss: 0.4200 - val_loss: 0.4384 - 29ms/epoch - 3ms/step\n",
      "Epoch 1057/2500\n",
      "11/11 - 0s - loss: 0.4382 - val_loss: 0.4392 - 29ms/epoch - 3ms/step\n",
      "Epoch 1058/2500\n",
      "11/11 - 0s - loss: 0.4298 - val_loss: 0.4376 - 29ms/epoch - 3ms/step\n",
      "Epoch 1059/2500\n",
      "11/11 - 0s - loss: 0.4340 - val_loss: 0.4457 - 29ms/epoch - 3ms/step\n",
      "Epoch 1060/2500\n",
      "11/11 - 0s - loss: 0.4285 - val_loss: 0.4406 - 29ms/epoch - 3ms/step\n",
      "Epoch 1061/2500\n",
      "11/11 - 0s - loss: 0.4384 - val_loss: 0.4458 - 28ms/epoch - 3ms/step\n",
      "Epoch 1062/2500\n",
      "11/11 - 0s - loss: 0.4296 - val_loss: 0.4420 - 29ms/epoch - 3ms/step\n",
      "Epoch 1063/2500\n",
      "11/11 - 0s - loss: 0.4292 - val_loss: 0.4361 - 32ms/epoch - 3ms/step\n",
      "Epoch 1064/2500\n",
      "11/11 - 0s - loss: 0.4264 - val_loss: 0.4519 - 35ms/epoch - 3ms/step\n",
      "Epoch 1065/2500\n",
      "11/11 - 0s - loss: 0.4375 - val_loss: 0.4470 - 29ms/epoch - 3ms/step\n",
      "Epoch 1066/2500\n",
      "11/11 - 0s - loss: 0.4237 - val_loss: 0.4394 - 29ms/epoch - 3ms/step\n",
      "Epoch 1067/2500\n",
      "11/11 - 0s - loss: 0.4090 - val_loss: 0.4370 - 29ms/epoch - 3ms/step\n",
      "Epoch 1068/2500\n",
      "11/11 - 0s - loss: 0.4164 - val_loss: 0.4319 - 28ms/epoch - 3ms/step\n",
      "Epoch 1069/2500\n",
      "11/11 - 0s - loss: 0.4311 - val_loss: 0.4395 - 29ms/epoch - 3ms/step\n",
      "Epoch 1070/2500\n",
      "11/11 - 0s - loss: 0.4212 - val_loss: 0.4412 - 29ms/epoch - 3ms/step\n",
      "Epoch 1071/2500\n",
      "11/11 - 0s - loss: 0.4352 - val_loss: 0.4420 - 28ms/epoch - 3ms/step\n",
      "Epoch 1072/2500\n",
      "11/11 - 0s - loss: 0.4277 - val_loss: 0.4375 - 29ms/epoch - 3ms/step\n",
      "Epoch 1073/2500\n",
      "11/11 - 0s - loss: 0.4219 - val_loss: 0.4414 - 28ms/epoch - 3ms/step\n",
      "Epoch 1074/2500\n",
      "11/11 - 0s - loss: 0.4356 - val_loss: 0.4375 - 29ms/epoch - 3ms/step\n",
      "Epoch 1075/2500\n",
      "11/11 - 0s - loss: 0.4493 - val_loss: 0.4317 - 30ms/epoch - 3ms/step\n",
      "Epoch 1076/2500\n",
      "11/11 - 0s - loss: 0.4080 - val_loss: 0.4352 - 30ms/epoch - 3ms/step\n",
      "Epoch 1077/2500\n",
      "11/11 - 0s - loss: 0.4256 - val_loss: 0.4364 - 29ms/epoch - 3ms/step\n",
      "Epoch 1078/2500\n",
      "11/11 - 0s - loss: 0.4460 - val_loss: 0.4373 - 29ms/epoch - 3ms/step\n",
      "Epoch 1079/2500\n",
      "11/11 - 0s - loss: 0.4257 - val_loss: 0.4354 - 33ms/epoch - 3ms/step\n",
      "Epoch 1080/2500\n",
      "11/11 - 0s - loss: 0.4390 - val_loss: 0.4394 - 29ms/epoch - 3ms/step\n",
      "Epoch 1081/2500\n",
      "11/11 - 0s - loss: 0.4451 - val_loss: 0.4345 - 28ms/epoch - 3ms/step\n",
      "Epoch 1082/2500\n",
      "11/11 - 0s - loss: 0.4239 - val_loss: 0.4427 - 29ms/epoch - 3ms/step\n",
      "Epoch 1083/2500\n",
      "11/11 - 0s - loss: 0.4307 - val_loss: 0.4384 - 28ms/epoch - 3ms/step\n",
      "Epoch 1084/2500\n",
      "11/11 - 0s - loss: 0.4365 - val_loss: 0.4298 - 29ms/epoch - 3ms/step\n",
      "Epoch 1085/2500\n",
      "11/11 - 0s - loss: 0.4415 - val_loss: 0.4407 - 29ms/epoch - 3ms/step\n",
      "Epoch 1086/2500\n",
      "11/11 - 0s - loss: 0.4180 - val_loss: 0.4403 - 28ms/epoch - 3ms/step\n",
      "Epoch 1087/2500\n",
      "11/11 - 0s - loss: 0.4382 - val_loss: 0.4373 - 29ms/epoch - 3ms/step\n",
      "Epoch 1088/2500\n",
      "11/11 - 0s - loss: 0.4387 - val_loss: 0.4454 - 29ms/epoch - 3ms/step\n",
      "Epoch 1089/2500\n",
      "11/11 - 0s - loss: 0.4205 - val_loss: 0.4502 - 29ms/epoch - 3ms/step\n",
      "Epoch 1090/2500\n",
      "11/11 - 0s - loss: 0.4315 - val_loss: 0.4409 - 29ms/epoch - 3ms/step\n",
      "Epoch 1091/2500\n",
      "11/11 - 0s - loss: 0.4301 - val_loss: 0.4581 - 29ms/epoch - 3ms/step\n",
      "Epoch 1092/2500\n",
      "11/11 - 0s - loss: 0.4344 - val_loss: 0.4401 - 29ms/epoch - 3ms/step\n",
      "Epoch 1093/2500\n",
      "11/11 - 0s - loss: 0.4394 - val_loss: 0.4448 - 29ms/epoch - 3ms/step\n",
      "Epoch 1094/2500\n",
      "11/11 - 0s - loss: 0.4300 - val_loss: 0.4398 - 29ms/epoch - 3ms/step\n",
      "Epoch 1095/2500\n",
      "11/11 - 0s - loss: 0.4332 - val_loss: 0.4469 - 29ms/epoch - 3ms/step\n",
      "Epoch 1096/2500\n",
      "11/11 - 0s - loss: 0.4481 - val_loss: 0.4347 - 29ms/epoch - 3ms/step\n",
      "Epoch 1097/2500\n",
      "11/11 - 0s - loss: 0.4248 - val_loss: 0.4362 - 30ms/epoch - 3ms/step\n",
      "Epoch 1098/2500\n",
      "11/11 - 0s - loss: 0.4301 - val_loss: 0.4436 - 38ms/epoch - 3ms/step\n",
      "Epoch 1099/2500\n",
      "11/11 - 0s - loss: 0.4363 - val_loss: 0.4352 - 29ms/epoch - 3ms/step\n",
      "Epoch 1100/2500\n",
      "11/11 - 0s - loss: 0.4110 - val_loss: 0.4313 - 28ms/epoch - 3ms/step\n",
      "Epoch 1101/2500\n",
      "11/11 - 0s - loss: 0.4252 - val_loss: 0.4347 - 29ms/epoch - 3ms/step\n",
      "Epoch 1102/2500\n",
      "11/11 - 0s - loss: 0.4292 - val_loss: 0.4322 - 29ms/epoch - 3ms/step\n",
      "Epoch 1103/2500\n",
      "11/11 - 0s - loss: 0.4424 - val_loss: 0.4413 - 28ms/epoch - 3ms/step\n",
      "Epoch 1104/2500\n",
      "11/11 - 0s - loss: 0.4499 - val_loss: 0.4350 - 29ms/epoch - 3ms/step\n",
      "Epoch 1105/2500\n",
      "11/11 - 0s - loss: 0.4222 - val_loss: 0.4246 - 30ms/epoch - 3ms/step\n",
      "Epoch 1106/2500\n",
      "11/11 - 0s - loss: 0.4311 - val_loss: 0.4307 - 29ms/epoch - 3ms/step\n",
      "Epoch 1107/2500\n",
      "11/11 - 0s - loss: 0.4329 - val_loss: 0.4257 - 33ms/epoch - 3ms/step\n",
      "Epoch 1108/2500\n",
      "11/11 - 0s - loss: 0.4266 - val_loss: 0.4265 - 30ms/epoch - 3ms/step\n",
      "Epoch 1109/2500\n",
      "11/11 - 0s - loss: 0.4325 - val_loss: 0.4270 - 29ms/epoch - 3ms/step\n",
      "Epoch 1110/2500\n",
      "11/11 - 0s - loss: 0.4310 - val_loss: 0.4366 - 29ms/epoch - 3ms/step\n",
      "Epoch 1111/2500\n",
      "11/11 - 0s - loss: 0.4209 - val_loss: 0.4315 - 29ms/epoch - 3ms/step\n",
      "Epoch 1112/2500\n",
      "11/11 - 0s - loss: 0.4358 - val_loss: 0.4501 - 29ms/epoch - 3ms/step\n",
      "Epoch 1113/2500\n",
      "11/11 - 0s - loss: 0.4244 - val_loss: 0.4272 - 29ms/epoch - 3ms/step\n",
      "Epoch 1114/2500\n",
      "11/11 - 0s - loss: 0.4189 - val_loss: 0.4311 - 29ms/epoch - 3ms/step\n",
      "Epoch 1115/2500\n",
      "11/11 - 0s - loss: 0.4153 - val_loss: 0.4357 - 29ms/epoch - 3ms/step\n",
      "Epoch 1116/2500\n",
      "11/11 - 0s - loss: 0.4133 - val_loss: 0.4281 - 29ms/epoch - 3ms/step\n",
      "Epoch 1117/2500\n",
      "11/11 - 0s - loss: 0.4201 - val_loss: 0.4348 - 29ms/epoch - 3ms/step\n",
      "Epoch 1118/2500\n",
      "11/11 - 0s - loss: 0.4262 - val_loss: 0.4376 - 29ms/epoch - 3ms/step\n",
      "Epoch 1119/2500\n",
      "11/11 - 0s - loss: 0.4189 - val_loss: 0.4384 - 28ms/epoch - 3ms/step\n",
      "Epoch 1120/2500\n",
      "11/11 - 0s - loss: 0.4322 - val_loss: 0.4372 - 29ms/epoch - 3ms/step\n",
      "Epoch 1121/2500\n",
      "11/11 - 0s - loss: 0.4413 - val_loss: 0.4304 - 29ms/epoch - 3ms/step\n",
      "Epoch 1122/2500\n",
      "11/11 - 0s - loss: 0.4426 - val_loss: 0.4294 - 28ms/epoch - 3ms/step\n",
      "Epoch 1123/2500\n",
      "11/11 - 0s - loss: 0.4457 - val_loss: 0.4412 - 29ms/epoch - 3ms/step\n",
      "Epoch 1124/2500\n",
      "11/11 - 0s - loss: 0.4306 - val_loss: 0.4396 - 29ms/epoch - 3ms/step\n",
      "Epoch 1125/2500\n",
      "11/11 - 0s - loss: 0.4189 - val_loss: 0.4381 - 29ms/epoch - 3ms/step\n",
      "Epoch 1126/2500\n",
      "11/11 - 0s - loss: 0.4246 - val_loss: 0.4293 - 29ms/epoch - 3ms/step\n",
      "Epoch 1127/2500\n",
      "11/11 - 0s - loss: 0.4385 - val_loss: 0.4363 - 29ms/epoch - 3ms/step\n",
      "Epoch 1128/2500\n",
      "11/11 - 0s - loss: 0.4384 - val_loss: 0.4469 - 33ms/epoch - 3ms/step\n",
      "Epoch 1129/2500\n",
      "11/11 - 0s - loss: 0.4244 - val_loss: 0.4357 - 29ms/epoch - 3ms/step\n",
      "Epoch 1130/2500\n",
      "11/11 - 0s - loss: 0.4213 - val_loss: 0.4436 - 29ms/epoch - 3ms/step\n",
      "Epoch 1131/2500\n",
      "11/11 - 0s - loss: 0.4331 - val_loss: 0.4396 - 29ms/epoch - 3ms/step\n",
      "Epoch 1132/2500\n",
      "11/11 - 0s - loss: 0.4294 - val_loss: 0.4409 - 42ms/epoch - 4ms/step\n",
      "Epoch 1133/2500\n",
      "11/11 - 0s - loss: 0.4291 - val_loss: 0.4353 - 29ms/epoch - 3ms/step\n",
      "Epoch 1134/2500\n",
      "11/11 - 0s - loss: 0.4355 - val_loss: 0.4368 - 29ms/epoch - 3ms/step\n",
      "Epoch 1135/2500\n",
      "11/11 - 0s - loss: 0.4248 - val_loss: 0.4467 - 29ms/epoch - 3ms/step\n",
      "Epoch 1136/2500\n",
      "11/11 - 0s - loss: 0.4449 - val_loss: 0.4569 - 30ms/epoch - 3ms/step\n",
      "Epoch 1137/2500\n",
      "11/11 - 0s - loss: 0.4301 - val_loss: 0.4419 - 32ms/epoch - 3ms/step\n",
      "Epoch 1138/2500\n",
      "11/11 - 0s - loss: 0.4232 - val_loss: 0.4404 - 31ms/epoch - 3ms/step\n",
      "Epoch 1139/2500\n",
      "11/11 - 0s - loss: 0.4127 - val_loss: 0.4359 - 29ms/epoch - 3ms/step\n",
      "Epoch 1140/2500\n",
      "11/11 - 0s - loss: 0.4312 - val_loss: 0.4457 - 29ms/epoch - 3ms/step\n",
      "Epoch 1141/2500\n",
      "11/11 - 0s - loss: 0.4248 - val_loss: 0.4379 - 30ms/epoch - 3ms/step\n",
      "Epoch 1142/2500\n",
      "11/11 - 0s - loss: 0.4180 - val_loss: 0.4504 - 28ms/epoch - 3ms/step\n",
      "Epoch 1143/2500\n",
      "11/11 - 0s - loss: 0.4304 - val_loss: 0.4525 - 29ms/epoch - 3ms/step\n",
      "Epoch 1144/2500\n",
      "11/11 - 0s - loss: 0.4280 - val_loss: 0.4383 - 29ms/epoch - 3ms/step\n",
      "Epoch 1145/2500\n",
      "11/11 - 0s - loss: 0.4250 - val_loss: 0.4481 - 29ms/epoch - 3ms/step\n",
      "Epoch 1146/2500\n",
      "11/11 - 0s - loss: 0.4250 - val_loss: 0.4423 - 29ms/epoch - 3ms/step\n",
      "Epoch 1147/2500\n",
      "11/11 - 0s - loss: 0.4311 - val_loss: 0.4298 - 30ms/epoch - 3ms/step\n",
      "Epoch 1148/2500\n",
      "11/11 - 0s - loss: 0.4278 - val_loss: 0.4277 - 29ms/epoch - 3ms/step\n",
      "Epoch 1149/2500\n",
      "11/11 - 0s - loss: 0.4146 - val_loss: 0.4360 - 28ms/epoch - 3ms/step\n",
      "Epoch 1150/2500\n",
      "11/11 - 0s - loss: 0.4278 - val_loss: 0.4299 - 29ms/epoch - 3ms/step\n",
      "Epoch 1151/2500\n",
      "11/11 - 0s - loss: 0.4407 - val_loss: 0.4451 - 29ms/epoch - 3ms/step\n",
      "Epoch 1152/2500\n",
      "11/11 - 0s - loss: 0.4254 - val_loss: 0.4497 - 28ms/epoch - 3ms/step\n",
      "Epoch 1153/2500\n",
      "11/11 - 0s - loss: 0.4189 - val_loss: 0.4409 - 29ms/epoch - 3ms/step\n",
      "Epoch 1154/2500\n",
      "11/11 - 0s - loss: 0.4126 - val_loss: 0.4356 - 29ms/epoch - 3ms/step\n",
      "Epoch 1155/2500\n",
      "11/11 - 0s - loss: 0.4391 - val_loss: 0.4315 - 28ms/epoch - 3ms/step\n",
      "Epoch 1156/2500\n",
      "11/11 - 0s - loss: 0.4349 - val_loss: 0.4411 - 29ms/epoch - 3ms/step\n",
      "Epoch 1157/2500\n",
      "11/11 - 0s - loss: 0.4400 - val_loss: 0.4393 - 29ms/epoch - 3ms/step\n",
      "Epoch 1158/2500\n",
      "11/11 - 0s - loss: 0.4189 - val_loss: 0.4339 - 32ms/epoch - 3ms/step\n",
      "Epoch 1159/2500\n",
      "11/11 - 0s - loss: 0.4150 - val_loss: 0.4399 - 35ms/epoch - 3ms/step\n",
      "Epoch 1160/2500\n",
      "11/11 - 0s - loss: 0.4099 - val_loss: 0.4419 - 29ms/epoch - 3ms/step\n",
      "Epoch 1161/2500\n",
      "11/11 - 0s - loss: 0.4203 - val_loss: 0.4480 - 30ms/epoch - 3ms/step\n",
      "Epoch 1162/2500\n",
      "11/11 - 0s - loss: 0.4429 - val_loss: 0.4318 - 31ms/epoch - 3ms/step\n",
      "Epoch 1163/2500\n",
      "11/11 - 0s - loss: 0.4308 - val_loss: 0.4337 - 32ms/epoch - 3ms/step\n",
      "Epoch 1164/2500\n",
      "11/11 - 0s - loss: 0.4254 - val_loss: 0.4300 - 39ms/epoch - 4ms/step\n",
      "Epoch 1165/2500\n",
      "11/11 - 0s - loss: 0.4296 - val_loss: 0.4342 - 29ms/epoch - 3ms/step\n",
      "Epoch 1166/2500\n",
      "11/11 - 0s - loss: 0.4021 - val_loss: 0.4367 - 32ms/epoch - 3ms/step\n",
      "Epoch 1167/2500\n",
      "11/11 - 0s - loss: 0.4216 - val_loss: 0.4270 - 29ms/epoch - 3ms/step\n",
      "Epoch 1168/2500\n",
      "11/11 - 0s - loss: 0.4194 - val_loss: 0.4296 - 29ms/epoch - 3ms/step\n",
      "Epoch 1169/2500\n",
      "11/11 - 0s - loss: 0.4200 - val_loss: 0.4262 - 30ms/epoch - 3ms/step\n",
      "Epoch 1170/2500\n",
      "11/11 - 0s - loss: 0.4252 - val_loss: 0.4289 - 30ms/epoch - 3ms/step\n",
      "Epoch 1171/2500\n",
      "11/11 - 0s - loss: 0.4200 - val_loss: 0.4290 - 28ms/epoch - 3ms/step\n",
      "Epoch 1172/2500\n",
      "11/11 - 0s - loss: 0.4114 - val_loss: 0.4266 - 31ms/epoch - 3ms/step\n",
      "Epoch 1173/2500\n",
      "11/11 - 0s - loss: 0.4412 - val_loss: 0.4363 - 30ms/epoch - 3ms/step\n",
      "Epoch 1174/2500\n",
      "11/11 - 0s - loss: 0.4278 - val_loss: 0.4305 - 29ms/epoch - 3ms/step\n",
      "Epoch 1175/2500\n",
      "11/11 - 0s - loss: 0.4339 - val_loss: 0.4258 - 29ms/epoch - 3ms/step\n",
      "Epoch 1176/2500\n",
      "11/11 - 0s - loss: 0.4251 - val_loss: 0.4342 - 29ms/epoch - 3ms/step\n",
      "Epoch 1177/2500\n",
      "11/11 - 0s - loss: 0.4183 - val_loss: 0.4294 - 29ms/epoch - 3ms/step\n",
      "Epoch 1178/2500\n",
      "11/11 - 0s - loss: 0.4379 - val_loss: 0.4333 - 29ms/epoch - 3ms/step\n",
      "Epoch 1179/2500\n",
      "11/11 - 0s - loss: 0.4386 - val_loss: 0.4318 - 29ms/epoch - 3ms/step\n",
      "Epoch 1180/2500\n",
      "11/11 - 0s - loss: 0.4356 - val_loss: 0.4309 - 29ms/epoch - 3ms/step\n",
      "Epoch 1181/2500\n",
      "11/11 - 0s - loss: 0.4198 - val_loss: 0.4415 - 29ms/epoch - 3ms/step\n",
      "Epoch 1182/2500\n",
      "11/11 - 0s - loss: 0.4165 - val_loss: 0.4315 - 38ms/epoch - 3ms/step\n",
      "Epoch 1183/2500\n",
      "11/11 - 0s - loss: 0.4167 - val_loss: 0.4392 - 31ms/epoch - 3ms/step\n",
      "Epoch 1184/2500\n",
      "11/11 - 0s - loss: 0.4251 - val_loss: 0.4318 - 29ms/epoch - 3ms/step\n",
      "Epoch 1185/2500\n",
      "11/11 - 0s - loss: 0.4334 - val_loss: 0.4293 - 29ms/epoch - 3ms/step\n",
      "Epoch 1186/2500\n",
      "11/11 - 0s - loss: 0.4134 - val_loss: 0.4211 - 29ms/epoch - 3ms/step\n",
      "Epoch 1187/2500\n",
      "11/11 - 0s - loss: 0.4215 - val_loss: 0.4401 - 30ms/epoch - 3ms/step\n",
      "Epoch 1188/2500\n",
      "11/11 - 0s - loss: 0.4199 - val_loss: 0.4326 - 29ms/epoch - 3ms/step\n",
      "Epoch 1189/2500\n",
      "11/11 - 0s - loss: 0.4276 - val_loss: 0.4276 - 28ms/epoch - 3ms/step\n",
      "Epoch 1190/2500\n",
      "11/11 - 0s - loss: 0.4078 - val_loss: 0.4218 - 30ms/epoch - 3ms/step\n",
      "Epoch 1191/2500\n",
      "11/11 - 0s - loss: 0.3999 - val_loss: 0.4307 - 29ms/epoch - 3ms/step\n",
      "Epoch 1192/2500\n",
      "11/11 - 0s - loss: 0.4354 - val_loss: 0.4263 - 28ms/epoch - 3ms/step\n",
      "Epoch 1193/2500\n",
      "11/11 - 0s - loss: 0.4209 - val_loss: 0.4210 - 29ms/epoch - 3ms/step\n",
      "Epoch 1194/2500\n",
      "11/11 - 0s - loss: 0.4286 - val_loss: 0.4228 - 29ms/epoch - 3ms/step\n",
      "Epoch 1195/2500\n",
      "11/11 - 0s - loss: 0.4058 - val_loss: 0.4225 - 31ms/epoch - 3ms/step\n",
      "Epoch 1196/2500\n",
      "11/11 - 0s - loss: 0.4448 - val_loss: 0.4321 - 31ms/epoch - 3ms/step\n",
      "Epoch 1197/2500\n",
      "11/11 - 0s - loss: 0.4210 - val_loss: 0.4207 - 29ms/epoch - 3ms/step\n",
      "Epoch 1198/2500\n",
      "11/11 - 0s - loss: 0.4134 - val_loss: 0.4241 - 32ms/epoch - 3ms/step\n",
      "Epoch 1199/2500\n",
      "11/11 - 0s - loss: 0.4329 - val_loss: 0.4169 - 30ms/epoch - 3ms/step\n",
      "Epoch 1200/2500\n",
      "11/11 - 0s - loss: 0.4410 - val_loss: 0.4133 - 29ms/epoch - 3ms/step\n",
      "Epoch 1201/2500\n",
      "11/11 - 0s - loss: 0.4236 - val_loss: 0.4228 - 29ms/epoch - 3ms/step\n",
      "Epoch 1202/2500\n",
      "11/11 - 0s - loss: 0.4293 - val_loss: 0.4264 - 29ms/epoch - 3ms/step\n",
      "Epoch 1203/2500\n",
      "11/11 - 0s - loss: 0.4320 - val_loss: 0.4180 - 29ms/epoch - 3ms/step\n",
      "Epoch 1204/2500\n",
      "11/11 - 0s - loss: 0.4198 - val_loss: 0.4205 - 28ms/epoch - 3ms/step\n",
      "Epoch 1205/2500\n",
      "11/11 - 0s - loss: 0.4330 - val_loss: 0.4217 - 29ms/epoch - 3ms/step\n",
      "Epoch 1206/2500\n",
      "11/11 - 0s - loss: 0.4120 - val_loss: 0.4268 - 29ms/epoch - 3ms/step\n",
      "Epoch 1207/2500\n",
      "11/11 - 0s - loss: 0.4040 - val_loss: 0.4274 - 29ms/epoch - 3ms/step\n",
      "Epoch 1208/2500\n",
      "11/11 - 0s - loss: 0.4255 - val_loss: 0.4314 - 29ms/epoch - 3ms/step\n",
      "Epoch 1209/2500\n",
      "11/11 - 0s - loss: 0.4099 - val_loss: 0.4276 - 29ms/epoch - 3ms/step\n",
      "Epoch 1210/2500\n",
      "11/11 - 0s - loss: 0.4360 - val_loss: 0.4351 - 30ms/epoch - 3ms/step\n",
      "Epoch 1211/2500\n",
      "11/11 - 0s - loss: 0.4090 - val_loss: 0.4279 - 28ms/epoch - 3ms/step\n",
      "Epoch 1212/2500\n",
      "11/11 - 0s - loss: 0.4079 - val_loss: 0.4282 - 30ms/epoch - 3ms/step\n",
      "Epoch 1213/2500\n",
      "11/11 - 0s - loss: 0.4164 - val_loss: 0.4343 - 29ms/epoch - 3ms/step\n",
      "Epoch 1214/2500\n",
      "11/11 - 0s - loss: 0.4365 - val_loss: 0.4279 - 29ms/epoch - 3ms/step\n",
      "Epoch 1215/2500\n",
      "11/11 - 0s - loss: 0.4301 - val_loss: 0.4276 - 29ms/epoch - 3ms/step\n",
      "Epoch 1216/2500\n",
      "11/11 - 0s - loss: 0.4122 - val_loss: 0.4346 - 30ms/epoch - 3ms/step\n",
      "Epoch 1217/2500\n",
      "11/11 - 0s - loss: 0.4247 - val_loss: 0.4283 - 29ms/epoch - 3ms/step\n",
      "Epoch 1218/2500\n",
      "11/11 - 0s - loss: 0.4198 - val_loss: 0.4250 - 29ms/epoch - 3ms/step\n",
      "Epoch 1219/2500\n",
      "11/11 - 0s - loss: 0.4255 - val_loss: 0.4307 - 29ms/epoch - 3ms/step\n",
      "Epoch 1220/2500\n",
      "11/11 - 0s - loss: 0.4255 - val_loss: 0.4318 - 29ms/epoch - 3ms/step\n",
      "Epoch 1221/2500\n",
      "11/11 - 0s - loss: 0.4221 - val_loss: 0.4209 - 29ms/epoch - 3ms/step\n",
      "Epoch 1222/2500\n",
      "11/11 - 0s - loss: 0.4393 - val_loss: 0.4280 - 41ms/epoch - 4ms/step\n",
      "Epoch 1223/2500\n",
      "11/11 - 0s - loss: 0.4206 - val_loss: 0.4199 - 33ms/epoch - 3ms/step\n",
      "Epoch 1224/2500\n",
      "11/11 - 0s - loss: 0.4544 - val_loss: 0.4266 - 31ms/epoch - 3ms/step\n",
      "Epoch 1225/2500\n",
      "11/11 - 0s - loss: 0.4083 - val_loss: 0.4228 - 30ms/epoch - 3ms/step\n",
      "Epoch 1226/2500\n",
      "11/11 - 0s - loss: 0.4164 - val_loss: 0.4265 - 30ms/epoch - 3ms/step\n",
      "Epoch 1227/2500\n",
      "11/11 - 0s - loss: 0.4205 - val_loss: 0.4210 - 29ms/epoch - 3ms/step\n",
      "Epoch 1228/2500\n",
      "11/11 - 0s - loss: 0.4259 - val_loss: 0.4288 - 30ms/epoch - 3ms/step\n",
      "Epoch 1229/2500\n",
      "11/11 - 0s - loss: 0.4383 - val_loss: 0.4403 - 29ms/epoch - 3ms/step\n",
      "Epoch 1230/2500\n",
      "11/11 - 0s - loss: 0.4329 - val_loss: 0.4315 - 29ms/epoch - 3ms/step\n",
      "Epoch 1231/2500\n",
      "11/11 - 0s - loss: 0.4307 - val_loss: 0.4216 - 29ms/epoch - 3ms/step\n",
      "Epoch 1232/2500\n",
      "11/11 - 0s - loss: 0.4210 - val_loss: 0.4276 - 30ms/epoch - 3ms/step\n",
      "Epoch 1233/2500\n",
      "11/11 - 0s - loss: 0.4302 - val_loss: 0.4268 - 29ms/epoch - 3ms/step\n",
      "Epoch 1234/2500\n",
      "11/11 - 0s - loss: 0.4198 - val_loss: 0.4299 - 29ms/epoch - 3ms/step\n",
      "Epoch 1235/2500\n",
      "11/11 - 0s - loss: 0.4334 - val_loss: 0.4298 - 29ms/epoch - 3ms/step\n",
      "Epoch 1236/2500\n",
      "11/11 - 0s - loss: 0.4342 - val_loss: 0.4225 - 29ms/epoch - 3ms/step\n",
      "Epoch 1237/2500\n",
      "11/11 - 0s - loss: 0.4391 - val_loss: 0.4257 - 29ms/epoch - 3ms/step\n",
      "Epoch 1238/2500\n",
      "11/11 - 0s - loss: 0.4333 - val_loss: 0.4260 - 29ms/epoch - 3ms/step\n",
      "Epoch 1239/2500\n",
      "11/11 - 0s - loss: 0.4183 - val_loss: 0.4254 - 29ms/epoch - 3ms/step\n",
      "Epoch 1240/2500\n",
      "11/11 - 0s - loss: 0.4203 - val_loss: 0.4240 - 28ms/epoch - 3ms/step\n",
      "Epoch 1241/2500\n",
      "11/11 - 0s - loss: 0.4265 - val_loss: 0.4280 - 29ms/epoch - 3ms/step\n",
      "Epoch 1242/2500\n",
      "11/11 - 0s - loss: 0.4036 - val_loss: 0.4339 - 30ms/epoch - 3ms/step\n",
      "Epoch 1243/2500\n",
      "11/11 - 0s - loss: 0.4247 - val_loss: 0.4315 - 30ms/epoch - 3ms/step\n",
      "Epoch 1244/2500\n",
      "11/11 - 0s - loss: 0.4204 - val_loss: 0.4318 - 39ms/epoch - 4ms/step\n",
      "Epoch 1245/2500\n",
      "11/11 - 0s - loss: 0.4356 - val_loss: 0.4266 - 29ms/epoch - 3ms/step\n",
      "Epoch 1246/2500\n",
      "11/11 - 0s - loss: 0.4215 - val_loss: 0.4192 - 29ms/epoch - 3ms/step\n",
      "Epoch 1247/2500\n",
      "11/11 - 0s - loss: 0.4038 - val_loss: 0.4229 - 29ms/epoch - 3ms/step\n",
      "Epoch 1248/2500\n",
      "11/11 - 0s - loss: 0.4189 - val_loss: 0.4278 - 29ms/epoch - 3ms/step\n",
      "Epoch 1249/2500\n",
      "11/11 - 0s - loss: 0.4178 - val_loss: 0.4174 - 28ms/epoch - 3ms/step\n",
      "Epoch 1250/2500\n",
      "11/11 - 0s - loss: 0.4152 - val_loss: 0.4238 - 29ms/epoch - 3ms/step\n",
      "Epoch 1251/2500\n",
      "11/11 - 0s - loss: 0.4266 - val_loss: 0.4209 - 29ms/epoch - 3ms/step\n",
      "Epoch 1252/2500\n",
      "11/11 - 0s - loss: 0.4268 - val_loss: 0.4233 - 31ms/epoch - 3ms/step\n",
      "Epoch 1253/2500\n",
      "11/11 - 0s - loss: 0.4185 - val_loss: 0.4225 - 29ms/epoch - 3ms/step\n",
      "Epoch 1254/2500\n",
      "11/11 - 0s - loss: 0.4168 - val_loss: 0.4172 - 28ms/epoch - 3ms/step\n",
      "Epoch 1255/2500\n",
      "11/11 - 0s - loss: 0.4242 - val_loss: 0.4279 - 29ms/epoch - 3ms/step\n",
      "Epoch 1256/2500\n",
      "11/11 - 0s - loss: 0.4240 - val_loss: 0.4153 - 28ms/epoch - 3ms/step\n",
      "Epoch 1257/2500\n",
      "11/11 - 0s - loss: 0.4151 - val_loss: 0.4177 - 29ms/epoch - 3ms/step\n",
      "Epoch 1258/2500\n",
      "11/11 - 0s - loss: 0.4230 - val_loss: 0.4285 - 28ms/epoch - 3ms/step\n",
      "Epoch 1259/2500\n",
      "11/11 - 0s - loss: 0.4369 - val_loss: 0.4177 - 29ms/epoch - 3ms/step\n",
      "Epoch 1260/2500\n",
      "11/11 - 0s - loss: 0.4305 - val_loss: 0.4173 - 28ms/epoch - 3ms/step\n",
      "Epoch 1261/2500\n",
      "11/11 - 0s - loss: 0.4206 - val_loss: 0.4253 - 29ms/epoch - 3ms/step\n",
      "Epoch 1262/2500\n",
      "11/11 - 0s - loss: 0.4196 - val_loss: 0.4244 - 29ms/epoch - 3ms/step\n",
      "Epoch 1263/2500\n",
      "11/11 - 0s - loss: 0.4132 - val_loss: 0.4265 - 29ms/epoch - 3ms/step\n",
      "Epoch 1264/2500\n",
      "11/11 - 0s - loss: 0.4189 - val_loss: 0.4282 - 29ms/epoch - 3ms/step\n",
      "Epoch 1265/2500\n",
      "11/11 - 0s - loss: 0.4085 - val_loss: 0.4318 - 29ms/epoch - 3ms/step\n",
      "Epoch 1266/2500\n",
      "11/11 - 0s - loss: 0.4236 - val_loss: 0.4229 - 29ms/epoch - 3ms/step\n",
      "Epoch 1267/2500\n",
      "11/11 - 0s - loss: 0.4089 - val_loss: 0.4255 - 29ms/epoch - 3ms/step\n",
      "Epoch 1268/2500\n",
      "11/11 - 0s - loss: 0.4386 - val_loss: 0.4278 - 28ms/epoch - 3ms/step\n",
      "Epoch 1269/2500\n",
      "11/11 - 0s - loss: 0.4210 - val_loss: 0.4283 - 29ms/epoch - 3ms/step\n",
      "Epoch 1270/2500\n",
      "11/11 - 0s - loss: 0.4168 - val_loss: 0.4240 - 28ms/epoch - 3ms/step\n",
      "Epoch 1271/2500\n",
      "11/11 - 0s - loss: 0.4183 - val_loss: 0.4180 - 29ms/epoch - 3ms/step\n",
      "Epoch 1272/2500\n",
      "11/11 - 0s - loss: 0.4311 - val_loss: 0.4282 - 28ms/epoch - 3ms/step\n",
      "Epoch 1273/2500\n",
      "11/11 - 0s - loss: 0.4269 - val_loss: 0.4221 - 28ms/epoch - 3ms/step\n",
      "Epoch 1274/2500\n",
      "11/11 - 0s - loss: 0.4234 - val_loss: 0.4325 - 29ms/epoch - 3ms/step\n",
      "Epoch 1275/2500\n",
      "11/11 - 0s - loss: 0.4137 - val_loss: 0.4265 - 28ms/epoch - 3ms/step\n",
      "Epoch 1276/2500\n",
      "11/11 - 0s - loss: 0.4020 - val_loss: 0.4333 - 28ms/epoch - 3ms/step\n",
      "Epoch 1277/2500\n",
      "11/11 - 0s - loss: 0.4196 - val_loss: 0.4292 - 29ms/epoch - 3ms/step\n",
      "Epoch 1278/2500\n",
      "11/11 - 0s - loss: 0.4260 - val_loss: 0.4310 - 37ms/epoch - 3ms/step\n",
      "Epoch 1279/2500\n",
      "11/11 - 0s - loss: 0.4173 - val_loss: 0.4229 - 30ms/epoch - 3ms/step\n",
      "Epoch 1280/2500\n",
      "11/11 - 0s - loss: 0.4063 - val_loss: 0.4297 - 32ms/epoch - 3ms/step\n",
      "Epoch 1281/2500\n",
      "11/11 - 0s - loss: 0.4243 - val_loss: 0.4320 - 29ms/epoch - 3ms/step\n",
      "Epoch 1282/2500\n",
      "11/11 - 0s - loss: 0.4197 - val_loss: 0.4262 - 29ms/epoch - 3ms/step\n",
      "Epoch 1283/2500\n",
      "11/11 - 0s - loss: 0.4253 - val_loss: 0.4259 - 28ms/epoch - 3ms/step\n",
      "Epoch 1284/2500\n",
      "11/11 - 0s - loss: 0.4124 - val_loss: 0.4310 - 28ms/epoch - 3ms/step\n",
      "Epoch 1285/2500\n",
      "11/11 - 0s - loss: 0.4047 - val_loss: 0.4275 - 28ms/epoch - 3ms/step\n",
      "Epoch 1286/2500\n",
      "11/11 - 0s - loss: 0.4172 - val_loss: 0.4308 - 28ms/epoch - 3ms/step\n",
      "Epoch 1287/2500\n",
      "11/11 - 0s - loss: 0.4372 - val_loss: 0.4282 - 29ms/epoch - 3ms/step\n",
      "Epoch 1288/2500\n",
      "11/11 - 0s - loss: 0.4226 - val_loss: 0.4238 - 29ms/epoch - 3ms/step\n",
      "Epoch 1289/2500\n",
      "11/11 - 0s - loss: 0.4044 - val_loss: 0.4260 - 29ms/epoch - 3ms/step\n",
      "Epoch 1290/2500\n",
      "11/11 - 0s - loss: 0.4170 - val_loss: 0.4312 - 28ms/epoch - 3ms/step\n",
      "Epoch 1291/2500\n",
      "11/11 - 0s - loss: 0.4127 - val_loss: 0.4421 - 29ms/epoch - 3ms/step\n",
      "Epoch 1292/2500\n",
      "11/11 - 0s - loss: 0.4221 - val_loss: 0.4251 - 28ms/epoch - 3ms/step\n",
      "Epoch 1293/2500\n",
      "11/11 - 0s - loss: 0.4038 - val_loss: 0.4295 - 28ms/epoch - 3ms/step\n",
      "Epoch 1294/2500\n",
      "11/11 - 0s - loss: 0.4390 - val_loss: 0.4271 - 30ms/epoch - 3ms/step\n",
      "Epoch 1295/2500\n",
      "11/11 - 0s - loss: 0.4328 - val_loss: 0.4355 - 29ms/epoch - 3ms/step\n",
      "Epoch 1296/2500\n",
      "11/11 - 0s - loss: 0.4146 - val_loss: 0.4529 - 29ms/epoch - 3ms/step\n",
      "Epoch 1297/2500\n",
      "11/11 - 0s - loss: 0.4289 - val_loss: 0.4340 - 28ms/epoch - 3ms/step\n",
      "Epoch 1298/2500\n",
      "11/11 - 0s - loss: 0.4199 - val_loss: 0.4275 - 28ms/epoch - 3ms/step\n",
      "Epoch 1299/2500\n",
      "11/11 - 0s - loss: 0.4328 - val_loss: 0.4292 - 37ms/epoch - 3ms/step\n",
      "Epoch 1300/2500\n",
      "11/11 - 0s - loss: 0.4319 - val_loss: 0.4250 - 33ms/epoch - 3ms/step\n",
      "Epoch 1301/2500\n",
      "11/11 - 0s - loss: 0.4154 - val_loss: 0.4213 - 29ms/epoch - 3ms/step\n",
      "Epoch 1302/2500\n",
      "11/11 - 0s - loss: 0.4241 - val_loss: 0.4244 - 30ms/epoch - 3ms/step\n",
      "Epoch 1303/2500\n",
      "11/11 - 0s - loss: 0.4098 - val_loss: 0.4217 - 29ms/epoch - 3ms/step\n",
      "Epoch 1304/2500\n",
      "11/11 - 0s - loss: 0.4272 - val_loss: 0.4294 - 29ms/epoch - 3ms/step\n",
      "Epoch 1305/2500\n",
      "11/11 - 0s - loss: 0.4210 - val_loss: 0.4166 - 29ms/epoch - 3ms/step\n",
      "Epoch 1306/2500\n",
      "11/11 - 0s - loss: 0.4179 - val_loss: 0.4191 - 28ms/epoch - 3ms/step\n",
      "Epoch 1307/2500\n",
      "11/11 - 0s - loss: 0.4018 - val_loss: 0.4336 - 32ms/epoch - 3ms/step\n",
      "Epoch 1308/2500\n",
      "11/11 - 0s - loss: 0.4273 - val_loss: 0.4259 - 30ms/epoch - 3ms/step\n",
      "Epoch 1309/2500\n",
      "11/11 - 0s - loss: 0.4233 - val_loss: 0.4267 - 29ms/epoch - 3ms/step\n",
      "Epoch 1310/2500\n",
      "11/11 - 0s - loss: 0.4274 - val_loss: 0.4361 - 29ms/epoch - 3ms/step\n",
      "Epoch 1311/2500\n",
      "11/11 - 0s - loss: 0.4192 - val_loss: 0.4220 - 29ms/epoch - 3ms/step\n",
      "Epoch 1312/2500\n",
      "11/11 - 0s - loss: 0.4001 - val_loss: 0.4374 - 29ms/epoch - 3ms/step\n",
      "Epoch 1313/2500\n",
      "11/11 - 0s - loss: 0.4158 - val_loss: 0.4305 - 28ms/epoch - 3ms/step\n",
      "Epoch 1314/2500\n",
      "11/11 - 0s - loss: 0.4281 - val_loss: 0.4289 - 29ms/epoch - 3ms/step\n",
      "Epoch 1315/2500\n",
      "11/11 - 0s - loss: 0.4203 - val_loss: 0.4280 - 29ms/epoch - 3ms/step\n",
      "Epoch 1316/2500\n",
      "11/11 - 0s - loss: 0.4131 - val_loss: 0.4300 - 29ms/epoch - 3ms/step\n",
      "Epoch 1317/2500\n",
      "11/11 - 0s - loss: 0.4138 - val_loss: 0.4390 - 29ms/epoch - 3ms/step\n",
      "Epoch 1318/2500\n",
      "11/11 - 0s - loss: 0.4152 - val_loss: 0.4261 - 29ms/epoch - 3ms/step\n",
      "Epoch 1319/2500\n",
      "11/11 - 0s - loss: 0.4279 - val_loss: 0.4338 - 29ms/epoch - 3ms/step\n",
      "Epoch 1320/2500\n",
      "11/11 - 0s - loss: 0.4089 - val_loss: 0.4289 - 33ms/epoch - 3ms/step\n",
      "Epoch 1321/2500\n",
      "11/11 - 0s - loss: 0.4060 - val_loss: 0.4257 - 34ms/epoch - 3ms/step\n",
      "Epoch 1322/2500\n",
      "11/11 - 0s - loss: 0.3998 - val_loss: 0.4280 - 29ms/epoch - 3ms/step\n",
      "Epoch 1323/2500\n",
      "11/11 - 0s - loss: 0.4200 - val_loss: 0.4301 - 29ms/epoch - 3ms/step\n",
      "Epoch 1324/2500\n",
      "11/11 - 0s - loss: 0.4205 - val_loss: 0.4203 - 29ms/epoch - 3ms/step\n",
      "Epoch 1325/2500\n",
      "11/11 - 0s - loss: 0.4089 - val_loss: 0.4181 - 29ms/epoch - 3ms/step\n",
      "Epoch 1326/2500\n",
      "11/11 - 0s - loss: 0.4173 - val_loss: 0.4263 - 28ms/epoch - 3ms/step\n",
      "Epoch 1327/2500\n",
      "11/11 - 0s - loss: 0.4136 - val_loss: 0.4223 - 29ms/epoch - 3ms/step\n",
      "Epoch 1328/2500\n",
      "11/11 - 0s - loss: 0.4135 - val_loss: 0.4111 - 28ms/epoch - 3ms/step\n",
      "Epoch 1329/2500\n",
      "11/11 - 0s - loss: 0.4091 - val_loss: 0.4216 - 28ms/epoch - 3ms/step\n",
      "Epoch 1330/2500\n",
      "11/11 - 0s - loss: 0.3963 - val_loss: 0.4140 - 29ms/epoch - 3ms/step\n",
      "Epoch 1331/2500\n",
      "11/11 - 0s - loss: 0.4186 - val_loss: 0.4108 - 29ms/epoch - 3ms/step\n",
      "Epoch 1332/2500\n",
      "11/11 - 0s - loss: 0.4223 - val_loss: 0.4104 - 28ms/epoch - 3ms/step\n",
      "Epoch 1333/2500\n",
      "11/11 - 0s - loss: 0.3971 - val_loss: 0.4212 - 29ms/epoch - 3ms/step\n",
      "Epoch 1334/2500\n",
      "11/11 - 0s - loss: 0.3898 - val_loss: 0.4103 - 31ms/epoch - 3ms/step\n",
      "Epoch 1335/2500\n",
      "11/11 - 0s - loss: 0.4379 - val_loss: 0.4140 - 30ms/epoch - 3ms/step\n",
      "Epoch 1336/2500\n",
      "11/11 - 0s - loss: 0.4102 - val_loss: 0.4145 - 30ms/epoch - 3ms/step\n",
      "Epoch 1337/2500\n",
      "11/11 - 0s - loss: 0.3977 - val_loss: 0.4119 - 30ms/epoch - 3ms/step\n",
      "Epoch 1338/2500\n",
      "11/11 - 0s - loss: 0.4030 - val_loss: 0.4113 - 31ms/epoch - 3ms/step\n",
      "Epoch 1339/2500\n",
      "11/11 - 0s - loss: 0.4044 - val_loss: 0.4185 - 29ms/epoch - 3ms/step\n",
      "Epoch 1340/2500\n",
      "11/11 - 0s - loss: 0.4214 - val_loss: 0.4143 - 29ms/epoch - 3ms/step\n",
      "Epoch 1341/2500\n",
      "11/11 - 0s - loss: 0.4148 - val_loss: 0.4157 - 28ms/epoch - 3ms/step\n",
      "Epoch 1342/2500\n",
      "11/11 - 0s - loss: 0.4357 - val_loss: 0.4208 - 28ms/epoch - 3ms/step\n",
      "Epoch 1343/2500\n",
      "11/11 - 0s - loss: 0.4288 - val_loss: 0.4127 - 28ms/epoch - 3ms/step\n",
      "Epoch 1344/2500\n",
      "11/11 - 0s - loss: 0.4147 - val_loss: 0.4147 - 29ms/epoch - 3ms/step\n",
      "Epoch 1345/2500\n",
      "11/11 - 0s - loss: 0.4051 - val_loss: 0.4151 - 29ms/epoch - 3ms/step\n",
      "Epoch 1346/2500\n",
      "11/11 - 0s - loss: 0.4298 - val_loss: 0.4165 - 28ms/epoch - 3ms/step\n",
      "Epoch 1347/2500\n",
      "11/11 - 0s - loss: 0.4139 - val_loss: 0.4079 - 29ms/epoch - 3ms/step\n",
      "Epoch 1348/2500\n",
      "11/11 - 0s - loss: 0.4106 - val_loss: 0.4210 - 29ms/epoch - 3ms/step\n",
      "Epoch 1349/2500\n",
      "11/11 - 0s - loss: 0.4251 - val_loss: 0.4104 - 29ms/epoch - 3ms/step\n",
      "Epoch 1350/2500\n",
      "11/11 - 0s - loss: 0.4263 - val_loss: 0.4179 - 31ms/epoch - 3ms/step\n",
      "Epoch 1351/2500\n",
      "11/11 - 0s - loss: 0.4212 - val_loss: 0.4114 - 29ms/epoch - 3ms/step\n",
      "Epoch 1352/2500\n",
      "11/11 - 0s - loss: 0.4179 - val_loss: 0.4161 - 29ms/epoch - 3ms/step\n",
      "Epoch 1353/2500\n",
      "11/11 - 0s - loss: 0.4070 - val_loss: 0.4116 - 28ms/epoch - 3ms/step\n",
      "Epoch 1354/2500\n",
      "11/11 - 0s - loss: 0.4066 - val_loss: 0.4166 - 28ms/epoch - 3ms/step\n",
      "Epoch 1355/2500\n",
      "11/11 - 0s - loss: 0.4151 - val_loss: 0.4210 - 39ms/epoch - 4ms/step\n",
      "Epoch 1356/2500\n",
      "11/11 - 0s - loss: 0.4189 - val_loss: 0.4217 - 29ms/epoch - 3ms/step\n",
      "Epoch 1357/2500\n",
      "11/11 - 0s - loss: 0.4326 - val_loss: 0.4203 - 28ms/epoch - 3ms/step\n",
      "Epoch 1358/2500\n",
      "11/11 - 0s - loss: 0.4275 - val_loss: 0.4188 - 29ms/epoch - 3ms/step\n",
      "Epoch 1359/2500\n",
      "11/11 - 0s - loss: 0.4093 - val_loss: 0.4313 - 29ms/epoch - 3ms/step\n",
      "Epoch 1360/2500\n",
      "11/11 - 0s - loss: 0.4296 - val_loss: 0.4211 - 30ms/epoch - 3ms/step\n",
      "Epoch 1361/2500\n",
      "11/11 - 0s - loss: 0.4060 - val_loss: 0.4223 - 30ms/epoch - 3ms/step\n",
      "Epoch 1362/2500\n",
      "11/11 - 0s - loss: 0.4200 - val_loss: 0.4238 - 28ms/epoch - 3ms/step\n",
      "Epoch 1363/2500\n",
      "11/11 - 0s - loss: 0.4107 - val_loss: 0.4301 - 30ms/epoch - 3ms/step\n",
      "Epoch 1364/2500\n",
      "11/11 - 0s - loss: 0.4015 - val_loss: 0.4357 - 29ms/epoch - 3ms/step\n",
      "Epoch 1365/2500\n",
      "11/11 - 0s - loss: 0.4207 - val_loss: 0.4328 - 29ms/epoch - 3ms/step\n",
      "Epoch 1366/2500\n",
      "11/11 - 0s - loss: 0.4064 - val_loss: 0.4235 - 29ms/epoch - 3ms/step\n",
      "Epoch 1367/2500\n",
      "11/11 - 0s - loss: 0.4232 - val_loss: 0.4246 - 29ms/epoch - 3ms/step\n",
      "Epoch 1368/2500\n",
      "11/11 - 0s - loss: 0.4117 - val_loss: 0.4304 - 29ms/epoch - 3ms/step\n",
      "Epoch 1369/2500\n",
      "11/11 - 0s - loss: 0.4215 - val_loss: 0.4313 - 29ms/epoch - 3ms/step\n",
      "Epoch 1370/2500\n",
      "11/11 - 0s - loss: 0.4240 - val_loss: 0.4316 - 28ms/epoch - 3ms/step\n",
      "Epoch 1371/2500\n",
      "11/11 - 0s - loss: 0.4042 - val_loss: 0.4261 - 35ms/epoch - 3ms/step\n",
      "Epoch 1372/2500\n",
      "11/11 - 0s - loss: 0.4120 - val_loss: 0.4247 - 34ms/epoch - 3ms/step\n",
      "Epoch 1373/2500\n",
      "11/11 - 0s - loss: 0.4052 - val_loss: 0.4243 - 33ms/epoch - 3ms/step\n",
      "Epoch 1374/2500\n",
      "11/11 - 0s - loss: 0.4132 - val_loss: 0.4192 - 33ms/epoch - 3ms/step\n",
      "Epoch 1375/2500\n",
      "11/11 - 0s - loss: 0.4173 - val_loss: 0.4269 - 34ms/epoch - 3ms/step\n",
      "Epoch 1376/2500\n",
      "11/11 - 0s - loss: 0.4229 - val_loss: 0.4155 - 34ms/epoch - 3ms/step\n",
      "Epoch 1377/2500\n",
      "11/11 - 0s - loss: 0.4222 - val_loss: 0.4274 - 32ms/epoch - 3ms/step\n",
      "Epoch 1378/2500\n",
      "11/11 - 0s - loss: 0.4107 - val_loss: 0.4248 - 32ms/epoch - 3ms/step\n",
      "Epoch 1379/2500\n",
      "11/11 - 0s - loss: 0.4274 - val_loss: 0.4274 - 33ms/epoch - 3ms/step\n",
      "Epoch 1380/2500\n",
      "11/11 - 0s - loss: 0.4110 - val_loss: 0.4193 - 32ms/epoch - 3ms/step\n",
      "Epoch 1381/2500\n",
      "11/11 - 0s - loss: 0.4036 - val_loss: 0.4269 - 32ms/epoch - 3ms/step\n",
      "Epoch 1382/2500\n",
      "11/11 - 0s - loss: 0.4309 - val_loss: 0.4256 - 33ms/epoch - 3ms/step\n",
      "Epoch 1383/2500\n",
      "11/11 - 0s - loss: 0.4130 - val_loss: 0.4393 - 34ms/epoch - 3ms/step\n",
      "Epoch 1384/2500\n",
      "11/11 - 0s - loss: 0.4242 - val_loss: 0.4330 - 34ms/epoch - 3ms/step\n",
      "Epoch 1385/2500\n",
      "11/11 - 0s - loss: 0.4013 - val_loss: 0.4383 - 33ms/epoch - 3ms/step\n",
      "Epoch 1386/2500\n",
      "11/11 - 0s - loss: 0.4110 - val_loss: 0.4337 - 35ms/epoch - 3ms/step\n",
      "Epoch 1387/2500\n",
      "11/11 - 0s - loss: 0.4069 - val_loss: 0.4323 - 36ms/epoch - 3ms/step\n",
      "Epoch 1388/2500\n",
      "11/11 - 0s - loss: 0.4206 - val_loss: 0.4221 - 49ms/epoch - 4ms/step\n",
      "Epoch 1389/2500\n",
      "11/11 - 0s - loss: 0.4318 - val_loss: 0.4344 - 34ms/epoch - 3ms/step\n",
      "Epoch 1390/2500\n",
      "11/11 - 0s - loss: 0.4176 - val_loss: 0.4225 - 34ms/epoch - 3ms/step\n",
      "Epoch 1391/2500\n",
      "11/11 - 0s - loss: 0.4134 - val_loss: 0.4178 - 37ms/epoch - 3ms/step\n",
      "Epoch 1392/2500\n",
      "11/11 - 0s - loss: 0.4034 - val_loss: 0.4292 - 35ms/epoch - 3ms/step\n",
      "Epoch 1393/2500\n",
      "11/11 - 0s - loss: 0.4212 - val_loss: 0.4249 - 34ms/epoch - 3ms/step\n",
      "Epoch 1394/2500\n",
      "11/11 - 0s - loss: 0.3917 - val_loss: 0.4292 - 32ms/epoch - 3ms/step\n",
      "Epoch 1395/2500\n",
      "11/11 - 0s - loss: 0.4146 - val_loss: 0.4318 - 34ms/epoch - 3ms/step\n",
      "Epoch 1396/2500\n",
      "11/11 - 0s - loss: 0.4144 - val_loss: 0.4212 - 32ms/epoch - 3ms/step\n",
      "Epoch 1397/2500\n",
      "11/11 - 0s - loss: 0.4174 - val_loss: 0.4232 - 32ms/epoch - 3ms/step\n",
      "Epoch 1398/2500\n",
      "11/11 - 0s - loss: 0.4219 - val_loss: 0.4246 - 32ms/epoch - 3ms/step\n",
      "Epoch 1399/2500\n",
      "11/11 - 0s - loss: 0.3939 - val_loss: 0.4247 - 33ms/epoch - 3ms/step\n",
      "Epoch 1400/2500\n",
      "11/11 - 0s - loss: 0.4057 - val_loss: 0.4222 - 31ms/epoch - 3ms/step\n",
      "Epoch 1401/2500\n",
      "11/11 - 0s - loss: 0.4085 - val_loss: 0.4259 - 32ms/epoch - 3ms/step\n",
      "Epoch 1402/2500\n",
      "11/11 - 0s - loss: 0.4247 - val_loss: 0.4184 - 33ms/epoch - 3ms/step\n",
      "Epoch 1403/2500\n",
      "11/11 - 0s - loss: 0.3977 - val_loss: 0.4237 - 31ms/epoch - 3ms/step\n",
      "Epoch 1404/2500\n",
      "11/11 - 0s - loss: 0.4069 - val_loss: 0.4239 - 32ms/epoch - 3ms/step\n",
      "Epoch 1405/2500\n",
      "11/11 - 0s - loss: 0.4325 - val_loss: 0.4144 - 32ms/epoch - 3ms/step\n",
      "Epoch 1406/2500\n",
      "11/11 - 0s - loss: 0.4220 - val_loss: 0.4192 - 35ms/epoch - 3ms/step\n",
      "Epoch 1407/2500\n",
      "11/11 - 0s - loss: 0.4134 - val_loss: 0.4188 - 34ms/epoch - 3ms/step\n",
      "Epoch 1408/2500\n",
      "11/11 - 0s - loss: 0.4136 - val_loss: 0.4160 - 33ms/epoch - 3ms/step\n",
      "Epoch 1409/2500\n",
      "11/11 - 0s - loss: 0.4192 - val_loss: 0.4164 - 33ms/epoch - 3ms/step\n",
      "Epoch 1410/2500\n",
      "11/11 - 0s - loss: 0.4025 - val_loss: 0.4187 - 34ms/epoch - 3ms/step\n",
      "Epoch 1411/2500\n",
      "11/11 - 0s - loss: 0.4219 - val_loss: 0.4069 - 33ms/epoch - 3ms/step\n",
      "Epoch 1412/2500\n",
      "11/11 - 0s - loss: 0.4116 - val_loss: 0.4313 - 40ms/epoch - 4ms/step\n",
      "Epoch 1413/2500\n",
      "11/11 - 0s - loss: 0.4182 - val_loss: 0.4141 - 30ms/epoch - 3ms/step\n",
      "Epoch 1414/2500\n",
      "11/11 - 0s - loss: 0.4227 - val_loss: 0.4123 - 30ms/epoch - 3ms/step\n",
      "Epoch 1415/2500\n",
      "11/11 - 0s - loss: 0.4032 - val_loss: 0.4191 - 29ms/epoch - 3ms/step\n",
      "Epoch 1416/2500\n",
      "11/11 - 0s - loss: 0.4075 - val_loss: 0.4250 - 30ms/epoch - 3ms/step\n",
      "Epoch 1417/2500\n",
      "11/11 - 0s - loss: 0.4025 - val_loss: 0.4197 - 32ms/epoch - 3ms/step\n",
      "Epoch 1418/2500\n",
      "11/11 - 0s - loss: 0.3983 - val_loss: 0.4173 - 30ms/epoch - 3ms/step\n",
      "Epoch 1419/2500\n",
      "11/11 - 0s - loss: 0.4027 - val_loss: 0.4067 - 29ms/epoch - 3ms/step\n",
      "Epoch 1420/2500\n",
      "11/11 - 0s - loss: 0.4124 - val_loss: 0.4065 - 29ms/epoch - 3ms/step\n",
      "Epoch 1421/2500\n",
      "11/11 - 0s - loss: 0.4148 - val_loss: 0.4145 - 30ms/epoch - 3ms/step\n",
      "Epoch 1422/2500\n",
      "11/11 - 0s - loss: 0.4104 - val_loss: 0.4196 - 29ms/epoch - 3ms/step\n",
      "Epoch 1423/2500\n",
      "11/11 - 0s - loss: 0.4296 - val_loss: 0.4255 - 29ms/epoch - 3ms/step\n",
      "Epoch 1424/2500\n",
      "11/11 - 0s - loss: 0.4320 - val_loss: 0.4178 - 30ms/epoch - 3ms/step\n",
      "Epoch 1425/2500\n",
      "11/11 - 0s - loss: 0.4140 - val_loss: 0.4177 - 29ms/epoch - 3ms/step\n",
      "Epoch 1426/2500\n",
      "11/11 - 0s - loss: 0.4220 - val_loss: 0.4153 - 32ms/epoch - 3ms/step\n",
      "Epoch 1427/2500\n",
      "11/11 - 0s - loss: 0.4163 - val_loss: 0.4106 - 45ms/epoch - 4ms/step\n",
      "Epoch 1428/2500\n",
      "11/11 - 0s - loss: 0.3947 - val_loss: 0.4228 - 37ms/epoch - 3ms/step\n",
      "Epoch 1429/2500\n",
      "11/11 - 0s - loss: 0.4138 - val_loss: 0.4131 - 33ms/epoch - 3ms/step\n",
      "Epoch 1430/2500\n",
      "11/11 - 0s - loss: 0.4239 - val_loss: 0.4219 - 34ms/epoch - 3ms/step\n",
      "Epoch 1431/2500\n",
      "11/11 - 0s - loss: 0.4091 - val_loss: 0.4182 - 38ms/epoch - 3ms/step\n",
      "Epoch 1432/2500\n",
      "11/11 - 0s - loss: 0.4177 - val_loss: 0.4166 - 34ms/epoch - 3ms/step\n",
      "Epoch 1433/2500\n",
      "11/11 - 0s - loss: 0.4181 - val_loss: 0.4191 - 34ms/epoch - 3ms/step\n",
      "Epoch 1434/2500\n",
      "11/11 - 0s - loss: 0.4106 - val_loss: 0.4166 - 34ms/epoch - 3ms/step\n",
      "Epoch 1435/2500\n",
      "11/11 - 0s - loss: 0.4092 - val_loss: 0.4201 - 34ms/epoch - 3ms/step\n",
      "Epoch 1436/2500\n",
      "11/11 - 0s - loss: 0.3922 - val_loss: 0.4149 - 35ms/epoch - 3ms/step\n",
      "Epoch 1437/2500\n",
      "11/11 - 0s - loss: 0.4198 - val_loss: 0.4238 - 40ms/epoch - 4ms/step\n",
      "Epoch 1438/2500\n",
      "11/11 - 0s - loss: 0.4083 - val_loss: 0.4171 - 34ms/epoch - 3ms/step\n",
      "Epoch 1439/2500\n",
      "11/11 - 0s - loss: 0.4045 - val_loss: 0.4153 - 33ms/epoch - 3ms/step\n",
      "Epoch 1440/2500\n",
      "11/11 - 0s - loss: 0.4184 - val_loss: 0.4241 - 33ms/epoch - 3ms/step\n",
      "Epoch 1441/2500\n",
      "11/11 - 0s - loss: 0.4130 - val_loss: 0.4220 - 34ms/epoch - 3ms/step\n",
      "Epoch 1442/2500\n",
      "11/11 - 0s - loss: 0.4212 - val_loss: 0.4154 - 34ms/epoch - 3ms/step\n",
      "Epoch 1443/2500\n",
      "11/11 - 0s - loss: 0.4090 - val_loss: 0.4291 - 33ms/epoch - 3ms/step\n",
      "Epoch 1444/2500\n",
      "11/11 - 0s - loss: 0.4019 - val_loss: 0.4206 - 36ms/epoch - 3ms/step\n",
      "Epoch 1445/2500\n",
      "11/11 - 0s - loss: 0.4141 - val_loss: 0.4217 - 33ms/epoch - 3ms/step\n",
      "Epoch 1446/2500\n",
      "11/11 - 0s - loss: 0.4089 - val_loss: 0.4183 - 33ms/epoch - 3ms/step\n",
      "Epoch 1447/2500\n",
      "11/11 - 0s - loss: 0.4209 - val_loss: 0.4201 - 32ms/epoch - 3ms/step\n",
      "Epoch 1448/2500\n",
      "11/11 - 0s - loss: 0.4206 - val_loss: 0.4132 - 31ms/epoch - 3ms/step\n",
      "Epoch 1449/2500\n",
      "11/11 - 0s - loss: 0.3949 - val_loss: 0.4183 - 31ms/epoch - 3ms/step\n",
      "Epoch 1450/2500\n",
      "11/11 - 0s - loss: 0.4255 - val_loss: 0.4192 - 32ms/epoch - 3ms/step\n",
      "Epoch 1451/2500\n",
      "11/11 - 0s - loss: 0.4096 - val_loss: 0.4166 - 37ms/epoch - 3ms/step\n",
      "Epoch 1452/2500\n",
      "11/11 - 0s - loss: 0.4255 - val_loss: 0.4245 - 36ms/epoch - 3ms/step\n",
      "Epoch 1453/2500\n",
      "11/11 - 0s - loss: 0.4354 - val_loss: 0.4099 - 31ms/epoch - 3ms/step\n",
      "Epoch 1454/2500\n",
      "11/11 - 0s - loss: 0.4114 - val_loss: 0.4189 - 34ms/epoch - 3ms/step\n",
      "Epoch 1455/2500\n",
      "11/11 - 0s - loss: 0.4034 - val_loss: 0.4174 - 32ms/epoch - 3ms/step\n",
      "Epoch 1456/2500\n",
      "11/11 - 0s - loss: 0.4155 - val_loss: 0.4153 - 35ms/epoch - 3ms/step\n",
      "Epoch 1457/2500\n",
      "11/11 - 0s - loss: 0.3964 - val_loss: 0.4082 - 34ms/epoch - 3ms/step\n",
      "Epoch 1458/2500\n",
      "11/11 - 0s - loss: 0.4164 - val_loss: 0.4146 - 34ms/epoch - 3ms/step\n",
      "Epoch 1459/2500\n",
      "11/11 - 0s - loss: 0.4088 - val_loss: 0.4074 - 34ms/epoch - 3ms/step\n",
      "Epoch 1460/2500\n",
      "11/11 - 0s - loss: 0.4178 - val_loss: 0.4240 - 31ms/epoch - 3ms/step\n",
      "Epoch 1461/2500\n",
      "11/11 - 0s - loss: 0.4372 - val_loss: 0.4170 - 32ms/epoch - 3ms/step\n",
      "Epoch 1462/2500\n",
      "11/11 - 0s - loss: 0.4206 - val_loss: 0.4193 - 33ms/epoch - 3ms/step\n",
      "Epoch 1463/2500\n",
      "11/11 - 0s - loss: 0.4040 - val_loss: 0.4188 - 33ms/epoch - 3ms/step\n",
      "Epoch 1464/2500\n",
      "11/11 - 0s - loss: 0.4041 - val_loss: 0.4101 - 32ms/epoch - 3ms/step\n",
      "Epoch 1465/2500\n",
      "11/11 - 0s - loss: 0.4149 - val_loss: 0.4205 - 31ms/epoch - 3ms/step\n",
      "Epoch 1466/2500\n",
      "11/11 - 0s - loss: 0.4184 - val_loss: 0.4237 - 32ms/epoch - 3ms/step\n",
      "Epoch 1467/2500\n",
      "11/11 - 0s - loss: 0.4048 - val_loss: 0.4189 - 35ms/epoch - 3ms/step\n",
      "Epoch 1468/2500\n",
      "11/11 - 0s - loss: 0.4207 - val_loss: 0.4148 - 33ms/epoch - 3ms/step\n",
      "Epoch 1469/2500\n",
      "11/11 - 0s - loss: 0.4089 - val_loss: 0.4120 - 33ms/epoch - 3ms/step\n",
      "Epoch 1470/2500\n",
      "11/11 - 0s - loss: 0.4078 - val_loss: 0.4117 - 34ms/epoch - 3ms/step\n",
      "Epoch 1471/2500\n",
      "11/11 - 0s - loss: 0.4105 - val_loss: 0.4235 - 34ms/epoch - 3ms/step\n",
      "Epoch 1472/2500\n",
      "11/11 - 0s - loss: 0.4099 - val_loss: 0.4160 - 33ms/epoch - 3ms/step\n",
      "Epoch 1473/2500\n",
      "11/11 - 0s - loss: 0.4149 - val_loss: 0.4221 - 48ms/epoch - 4ms/step\n",
      "Epoch 1474/2500\n",
      "11/11 - 0s - loss: 0.3964 - val_loss: 0.4249 - 32ms/epoch - 3ms/step\n",
      "Epoch 1475/2500\n",
      "11/11 - 0s - loss: 0.4063 - val_loss: 0.4207 - 32ms/epoch - 3ms/step\n",
      "Epoch 1476/2500\n",
      "11/11 - 0s - loss: 0.4115 - val_loss: 0.4216 - 32ms/epoch - 3ms/step\n",
      "Epoch 1477/2500\n",
      "11/11 - 0s - loss: 0.3905 - val_loss: 0.4255 - 32ms/epoch - 3ms/step\n",
      "Epoch 1478/2500\n",
      "11/11 - 0s - loss: 0.4111 - val_loss: 0.4210 - 35ms/epoch - 3ms/step\n",
      "Epoch 1479/2500\n",
      "11/11 - 0s - loss: 0.4190 - val_loss: 0.4246 - 33ms/epoch - 3ms/step\n",
      "Epoch 1480/2500\n",
      "11/11 - 0s - loss: 0.4201 - val_loss: 0.4130 - 33ms/epoch - 3ms/step\n",
      "Epoch 1481/2500\n",
      "11/11 - 0s - loss: 0.4083 - val_loss: 0.4143 - 31ms/epoch - 3ms/step\n",
      "Epoch 1482/2500\n",
      "11/11 - 0s - loss: 0.4155 - val_loss: 0.4195 - 34ms/epoch - 3ms/step\n",
      "Epoch 1483/2500\n",
      "11/11 - 0s - loss: 0.4132 - val_loss: 0.4205 - 33ms/epoch - 3ms/step\n",
      "Epoch 1484/2500\n",
      "11/11 - 0s - loss: 0.4108 - val_loss: 0.4153 - 30ms/epoch - 3ms/step\n",
      "Epoch 1485/2500\n",
      "11/11 - 0s - loss: 0.4048 - val_loss: 0.4245 - 30ms/epoch - 3ms/step\n",
      "Epoch 1486/2500\n",
      "11/11 - 0s - loss: 0.4077 - val_loss: 0.4199 - 33ms/epoch - 3ms/step\n",
      "Epoch 1487/2500\n",
      "11/11 - 0s - loss: 0.4022 - val_loss: 0.4274 - 34ms/epoch - 3ms/step\n",
      "Epoch 1488/2500\n",
      "11/11 - 0s - loss: 0.4098 - val_loss: 0.4202 - 34ms/epoch - 3ms/step\n",
      "Epoch 1489/2500\n",
      "11/11 - 0s - loss: 0.4201 - val_loss: 0.4173 - 30ms/epoch - 3ms/step\n",
      "Epoch 1490/2500\n",
      "11/11 - 0s - loss: 0.4046 - val_loss: 0.4253 - 31ms/epoch - 3ms/step\n",
      "Epoch 1491/2500\n",
      "11/11 - 0s - loss: 0.4094 - val_loss: 0.4212 - 31ms/epoch - 3ms/step\n",
      "Epoch 1492/2500\n",
      "11/11 - 0s - loss: 0.4137 - val_loss: 0.4179 - 30ms/epoch - 3ms/step\n",
      "Epoch 1493/2500\n",
      "11/11 - 0s - loss: 0.4024 - val_loss: 0.4248 - 30ms/epoch - 3ms/step\n",
      "Epoch 1494/2500\n",
      "11/11 - 0s - loss: 0.4034 - val_loss: 0.4183 - 29ms/epoch - 3ms/step\n",
      "Epoch 1495/2500\n",
      "11/11 - 0s - loss: 0.4139 - val_loss: 0.4237 - 29ms/epoch - 3ms/step\n",
      "Epoch 1496/2500\n",
      "11/11 - 0s - loss: 0.4047 - val_loss: 0.4267 - 40ms/epoch - 4ms/step\n",
      "Epoch 1497/2500\n",
      "11/11 - 0s - loss: 0.3998 - val_loss: 0.4252 - 32ms/epoch - 3ms/step\n",
      "Epoch 1498/2500\n",
      "11/11 - 0s - loss: 0.4100 - val_loss: 0.4299 - 31ms/epoch - 3ms/step\n",
      "Epoch 1499/2500\n",
      "11/11 - 0s - loss: 0.4168 - val_loss: 0.4209 - 31ms/epoch - 3ms/step\n",
      "Epoch 1500/2500\n",
      "11/11 - 0s - loss: 0.4320 - val_loss: 0.4164 - 30ms/epoch - 3ms/step\n",
      "Epoch 1501/2500\n",
      "11/11 - 0s - loss: 0.4114 - val_loss: 0.4228 - 32ms/epoch - 3ms/step\n",
      "Epoch 1502/2500\n",
      "11/11 - 0s - loss: 0.4200 - val_loss: 0.4172 - 32ms/epoch - 3ms/step\n",
      "Epoch 1503/2500\n",
      "11/11 - 0s - loss: 0.4151 - val_loss: 0.4152 - 34ms/epoch - 3ms/step\n",
      "Epoch 1504/2500\n",
      "11/11 - 0s - loss: 0.4023 - val_loss: 0.4208 - 34ms/epoch - 3ms/step\n",
      "Epoch 1505/2500\n",
      "11/11 - 0s - loss: 0.4174 - val_loss: 0.4253 - 34ms/epoch - 3ms/step\n",
      "Epoch 1506/2500\n",
      "11/11 - 0s - loss: 0.4258 - val_loss: 0.4150 - 36ms/epoch - 3ms/step\n",
      "Epoch 1507/2500\n",
      "11/11 - 0s - loss: 0.4125 - val_loss: 0.4220 - 33ms/epoch - 3ms/step\n",
      "Epoch 1508/2500\n",
      "11/11 - 0s - loss: 0.3943 - val_loss: 0.4138 - 31ms/epoch - 3ms/step\n",
      "Epoch 1509/2500\n",
      "11/11 - 0s - loss: 0.4264 - val_loss: 0.4125 - 32ms/epoch - 3ms/step\n",
      "Epoch 1510/2500\n",
      "11/11 - 0s - loss: 0.4073 - val_loss: 0.4250 - 32ms/epoch - 3ms/step\n",
      "Epoch 1511/2500\n",
      "11/11 - 0s - loss: 0.4222 - val_loss: 0.4105 - 34ms/epoch - 3ms/step\n",
      "Epoch 1512/2500\n",
      "11/11 - 0s - loss: 0.4084 - val_loss: 0.4137 - 41ms/epoch - 4ms/step\n",
      "Epoch 1513/2500\n",
      "11/11 - 0s - loss: 0.3998 - val_loss: 0.4212 - 30ms/epoch - 3ms/step\n",
      "Epoch 1514/2500\n",
      "11/11 - 0s - loss: 0.4133 - val_loss: 0.4252 - 29ms/epoch - 3ms/step\n",
      "Epoch 1515/2500\n",
      "11/11 - 0s - loss: 0.4125 - val_loss: 0.4133 - 30ms/epoch - 3ms/step\n",
      "Epoch 1516/2500\n",
      "11/11 - 0s - loss: 0.4111 - val_loss: 0.4173 - 31ms/epoch - 3ms/step\n",
      "Epoch 1517/2500\n",
      "11/11 - 0s - loss: 0.4060 - val_loss: 0.4162 - 30ms/epoch - 3ms/step\n",
      "Epoch 1518/2500\n",
      "11/11 - 0s - loss: 0.4145 - val_loss: 0.4214 - 29ms/epoch - 3ms/step\n",
      "Epoch 1519/2500\n",
      "11/11 - 0s - loss: 0.4150 - val_loss: 0.4256 - 30ms/epoch - 3ms/step\n",
      "Epoch 1520/2500\n",
      "11/11 - 0s - loss: 0.3963 - val_loss: 0.4229 - 32ms/epoch - 3ms/step\n",
      "Epoch 1521/2500\n",
      "11/11 - 0s - loss: 0.4103 - val_loss: 0.4190 - 41ms/epoch - 4ms/step\n",
      "Epoch 1522/2500\n",
      "11/11 - 0s - loss: 0.4060 - val_loss: 0.4201 - 31ms/epoch - 3ms/step\n",
      "Epoch 1523/2500\n",
      "11/11 - 0s - loss: 0.4008 - val_loss: 0.4188 - 31ms/epoch - 3ms/step\n",
      "Epoch 1524/2500\n",
      "11/11 - 0s - loss: 0.4129 - val_loss: 0.4133 - 30ms/epoch - 3ms/step\n",
      "Epoch 1525/2500\n",
      "11/11 - 0s - loss: 0.4132 - val_loss: 0.4200 - 30ms/epoch - 3ms/step\n",
      "Epoch 1526/2500\n",
      "11/11 - 0s - loss: 0.4028 - val_loss: 0.4134 - 32ms/epoch - 3ms/step\n",
      "Epoch 1527/2500\n",
      "11/11 - 0s - loss: 0.4157 - val_loss: 0.4123 - 32ms/epoch - 3ms/step\n",
      "Epoch 1528/2500\n",
      "11/11 - 0s - loss: 0.4193 - val_loss: 0.4217 - 33ms/epoch - 3ms/step\n",
      "Epoch 1529/2500\n",
      "11/11 - 0s - loss: 0.4139 - val_loss: 0.4144 - 32ms/epoch - 3ms/step\n",
      "Epoch 1530/2500\n",
      "11/11 - 0s - loss: 0.4053 - val_loss: 0.4179 - 31ms/epoch - 3ms/step\n",
      "Epoch 1531/2500\n",
      "11/11 - 0s - loss: 0.4158 - val_loss: 0.4210 - 29ms/epoch - 3ms/step\n",
      "Epoch 1532/2500\n",
      "11/11 - 0s - loss: 0.4063 - val_loss: 0.4111 - 37ms/epoch - 3ms/step\n",
      "Epoch 1533/2500\n",
      "11/11 - 0s - loss: 0.4208 - val_loss: 0.4206 - 32ms/epoch - 3ms/step\n",
      "Epoch 1534/2500\n",
      "11/11 - 0s - loss: 0.4129 - val_loss: 0.4084 - 30ms/epoch - 3ms/step\n",
      "Epoch 1535/2500\n",
      "11/11 - 0s - loss: 0.4276 - val_loss: 0.4220 - 31ms/epoch - 3ms/step\n",
      "Epoch 1536/2500\n",
      "11/11 - 0s - loss: 0.4200 - val_loss: 0.4100 - 35ms/epoch - 3ms/step\n",
      "Epoch 1537/2500\n",
      "11/11 - 0s - loss: 0.4129 - val_loss: 0.4113 - 30ms/epoch - 3ms/step\n",
      "Epoch 1538/2500\n",
      "11/11 - 0s - loss: 0.4239 - val_loss: 0.4070 - 29ms/epoch - 3ms/step\n",
      "Epoch 1539/2500\n",
      "11/11 - 0s - loss: 0.4029 - val_loss: 0.4094 - 30ms/epoch - 3ms/step\n",
      "Epoch 1540/2500\n",
      "11/11 - 0s - loss: 0.4138 - val_loss: 0.4142 - 31ms/epoch - 3ms/step\n",
      "Epoch 1541/2500\n",
      "11/11 - 0s - loss: 0.3923 - val_loss: 0.4087 - 30ms/epoch - 3ms/step\n",
      "Epoch 1542/2500\n",
      "11/11 - 0s - loss: 0.4235 - val_loss: 0.4172 - 35ms/epoch - 3ms/step\n",
      "Epoch 1543/2500\n",
      "11/11 - 0s - loss: 0.4076 - val_loss: 0.4138 - 33ms/epoch - 3ms/step\n",
      "Epoch 1544/2500\n",
      "11/11 - 0s - loss: 0.4020 - val_loss: 0.4203 - 34ms/epoch - 3ms/step\n",
      "Epoch 1545/2500\n",
      "11/11 - 0s - loss: 0.4064 - val_loss: 0.4156 - 33ms/epoch - 3ms/step\n",
      "Epoch 1546/2500\n",
      "11/11 - 0s - loss: 0.4098 - val_loss: 0.4207 - 35ms/epoch - 3ms/step\n",
      "Epoch 1547/2500\n",
      "11/11 - 0s - loss: 0.4075 - val_loss: 0.4102 - 35ms/epoch - 3ms/step\n",
      "Epoch 1548/2500\n",
      "11/11 - 0s - loss: 0.4003 - val_loss: 0.4155 - 33ms/epoch - 3ms/step\n",
      "Epoch 1549/2500\n",
      "11/11 - 0s - loss: 0.3968 - val_loss: 0.4205 - 33ms/epoch - 3ms/step\n",
      "Epoch 1550/2500\n",
      "11/11 - 0s - loss: 0.4144 - val_loss: 0.4159 - 33ms/epoch - 3ms/step\n",
      "Epoch 1551/2500\n",
      "11/11 - 0s - loss: 0.4085 - val_loss: 0.4196 - 46ms/epoch - 4ms/step\n",
      "Epoch 1552/2500\n",
      "11/11 - 0s - loss: 0.3992 - val_loss: 0.4118 - 31ms/epoch - 3ms/step\n",
      "Epoch 1553/2500\n",
      "11/11 - 0s - loss: 0.4071 - val_loss: 0.4206 - 31ms/epoch - 3ms/step\n",
      "Epoch 1554/2500\n",
      "11/11 - 0s - loss: 0.4148 - val_loss: 0.4225 - 31ms/epoch - 3ms/step\n",
      "Epoch 1555/2500\n",
      "11/11 - 0s - loss: 0.4121 - val_loss: 0.4145 - 29ms/epoch - 3ms/step\n",
      "Epoch 1556/2500\n",
      "11/11 - 0s - loss: 0.4110 - val_loss: 0.4217 - 32ms/epoch - 3ms/step\n",
      "Epoch 1557/2500\n",
      "11/11 - 0s - loss: 0.4112 - val_loss: 0.4229 - 31ms/epoch - 3ms/step\n",
      "Epoch 1558/2500\n",
      "11/11 - 0s - loss: 0.4108 - val_loss: 0.4172 - 32ms/epoch - 3ms/step\n",
      "Epoch 1559/2500\n",
      "11/11 - 0s - loss: 0.4171 - val_loss: 0.4153 - 30ms/epoch - 3ms/step\n",
      "Epoch 1560/2500\n",
      "11/11 - 0s - loss: 0.4033 - val_loss: 0.4248 - 30ms/epoch - 3ms/step\n",
      "Epoch 1561/2500\n",
      "11/11 - 0s - loss: 0.4120 - val_loss: 0.4095 - 34ms/epoch - 3ms/step\n",
      "Epoch 1562/2500\n",
      "11/11 - 0s - loss: 0.4284 - val_loss: 0.4338 - 32ms/epoch - 3ms/step\n",
      "Epoch 1563/2500\n",
      "11/11 - 0s - loss: 0.4197 - val_loss: 0.4179 - 30ms/epoch - 3ms/step\n",
      "Epoch 1564/2500\n",
      "11/11 - 0s - loss: 0.4060 - val_loss: 0.4092 - 30ms/epoch - 3ms/step\n",
      "Epoch 1565/2500\n",
      "11/11 - 0s - loss: 0.3884 - val_loss: 0.4160 - 30ms/epoch - 3ms/step\n",
      "Epoch 1566/2500\n",
      "11/11 - 0s - loss: 0.4009 - val_loss: 0.4151 - 32ms/epoch - 3ms/step\n",
      "Epoch 1567/2500\n",
      "11/11 - 0s - loss: 0.4055 - val_loss: 0.4213 - 30ms/epoch - 3ms/step\n",
      "Epoch 1568/2500\n",
      "11/11 - 0s - loss: 0.3959 - val_loss: 0.4232 - 31ms/epoch - 3ms/step\n",
      "Epoch 1569/2500\n",
      "11/11 - 0s - loss: 0.4206 - val_loss: 0.4154 - 30ms/epoch - 3ms/step\n",
      "Epoch 1570/2500\n",
      "11/11 - 0s - loss: 0.4174 - val_loss: 0.4167 - 29ms/epoch - 3ms/step\n",
      "Epoch 1571/2500\n",
      "11/11 - 0s - loss: 0.3976 - val_loss: 0.4220 - 29ms/epoch - 3ms/step\n",
      "Epoch 1572/2500\n",
      "11/11 - 0s - loss: 0.4128 - val_loss: 0.4187 - 30ms/epoch - 3ms/step\n",
      "Epoch 1573/2500\n",
      "11/11 - 0s - loss: 0.3994 - val_loss: 0.4232 - 39ms/epoch - 4ms/step\n",
      "Epoch 1574/2500\n",
      "11/11 - 0s - loss: 0.4009 - val_loss: 0.4146 - 30ms/epoch - 3ms/step\n",
      "Epoch 1575/2500\n",
      "11/11 - 0s - loss: 0.4173 - val_loss: 0.4127 - 31ms/epoch - 3ms/step\n",
      "Epoch 1576/2500\n",
      "11/11 - 0s - loss: 0.3876 - val_loss: 0.4264 - 30ms/epoch - 3ms/step\n",
      "Epoch 1577/2500\n",
      "11/11 - 0s - loss: 0.4386 - val_loss: 0.4123 - 31ms/epoch - 3ms/step\n",
      "Epoch 1578/2500\n",
      "11/11 - 0s - loss: 0.4121 - val_loss: 0.4161 - 29ms/epoch - 3ms/step\n",
      "Epoch 1579/2500\n",
      "11/11 - 0s - loss: 0.4133 - val_loss: 0.4234 - 29ms/epoch - 3ms/step\n",
      "Epoch 1580/2500\n",
      "11/11 - 0s - loss: 0.4089 - val_loss: 0.4173 - 29ms/epoch - 3ms/step\n",
      "Epoch 1581/2500\n",
      "11/11 - 0s - loss: 0.4115 - val_loss: 0.4239 - 28ms/epoch - 3ms/step\n",
      "Epoch 1582/2500\n",
      "11/11 - 0s - loss: 0.4185 - val_loss: 0.4238 - 29ms/epoch - 3ms/step\n",
      "Epoch 1583/2500\n",
      "11/11 - 0s - loss: 0.4005 - val_loss: 0.4209 - 29ms/epoch - 3ms/step\n",
      "Epoch 1584/2500\n",
      "11/11 - 0s - loss: 0.3978 - val_loss: 0.4133 - 29ms/epoch - 3ms/step\n",
      "Epoch 1585/2500\n",
      "11/11 - 0s - loss: 0.4027 - val_loss: 0.4202 - 31ms/epoch - 3ms/step\n",
      "Epoch 1586/2500\n",
      "11/11 - 0s - loss: 0.4169 - val_loss: 0.4165 - 29ms/epoch - 3ms/step\n",
      "Epoch 1587/2500\n",
      "11/11 - 0s - loss: 0.4086 - val_loss: 0.4184 - 29ms/epoch - 3ms/step\n",
      "Epoch 1588/2500\n",
      "11/11 - 0s - loss: 0.4119 - val_loss: 0.4075 - 29ms/epoch - 3ms/step\n",
      "Epoch 1589/2500\n",
      "11/11 - 0s - loss: 0.3905 - val_loss: 0.4167 - 31ms/epoch - 3ms/step\n",
      "Epoch 1590/2500\n",
      "11/11 - 0s - loss: 0.3993 - val_loss: 0.4214 - 29ms/epoch - 3ms/step\n",
      "Epoch 1591/2500\n",
      "11/11 - 0s - loss: 0.4013 - val_loss: 0.4086 - 31ms/epoch - 3ms/step\n",
      "Epoch 1592/2500\n",
      "11/11 - 0s - loss: 0.4064 - val_loss: 0.4165 - 29ms/epoch - 3ms/step\n",
      "Epoch 1593/2500\n",
      "11/11 - 0s - loss: 0.4013 - val_loss: 0.4139 - 29ms/epoch - 3ms/step\n",
      "Epoch 1594/2500\n",
      "11/11 - 0s - loss: 0.4066 - val_loss: 0.4137 - 29ms/epoch - 3ms/step\n",
      "Epoch 1595/2500\n",
      "11/11 - 0s - loss: 0.4189 - val_loss: 0.4064 - 33ms/epoch - 3ms/step\n",
      "Epoch 1596/2500\n",
      "11/11 - 0s - loss: 0.4017 - val_loss: 0.4100 - 47ms/epoch - 4ms/step\n",
      "Epoch 1597/2500\n",
      "11/11 - 0s - loss: 0.4050 - val_loss: 0.4055 - 31ms/epoch - 3ms/step\n",
      "Epoch 1598/2500\n",
      "11/11 - 0s - loss: 0.4026 - val_loss: 0.4101 - 31ms/epoch - 3ms/step\n",
      "Epoch 1599/2500\n",
      "11/11 - 0s - loss: 0.4088 - val_loss: 0.4057 - 31ms/epoch - 3ms/step\n",
      "Epoch 1600/2500\n",
      "11/11 - 0s - loss: 0.4067 - val_loss: 0.4122 - 30ms/epoch - 3ms/step\n",
      "Epoch 1601/2500\n",
      "11/11 - 0s - loss: 0.4170 - val_loss: 0.4008 - 29ms/epoch - 3ms/step\n",
      "Epoch 1602/2500\n",
      "11/11 - 0s - loss: 0.3955 - val_loss: 0.4026 - 30ms/epoch - 3ms/step\n",
      "Epoch 1603/2500\n",
      "11/11 - 0s - loss: 0.4279 - val_loss: 0.4035 - 29ms/epoch - 3ms/step\n",
      "Epoch 1604/2500\n",
      "11/11 - 0s - loss: 0.4062 - val_loss: 0.4119 - 30ms/epoch - 3ms/step\n",
      "Epoch 1605/2500\n",
      "11/11 - 0s - loss: 0.4133 - val_loss: 0.4044 - 30ms/epoch - 3ms/step\n",
      "Epoch 1606/2500\n",
      "11/11 - 0s - loss: 0.4085 - val_loss: 0.4059 - 31ms/epoch - 3ms/step\n",
      "Epoch 1607/2500\n",
      "11/11 - 0s - loss: 0.4155 - val_loss: 0.4175 - 31ms/epoch - 3ms/step\n",
      "Epoch 1608/2500\n",
      "11/11 - 0s - loss: 0.4165 - val_loss: 0.4117 - 34ms/epoch - 3ms/step\n",
      "Epoch 1609/2500\n",
      "11/11 - 0s - loss: 0.4039 - val_loss: 0.4171 - 36ms/epoch - 3ms/step\n",
      "Epoch 1610/2500\n",
      "11/11 - 0s - loss: 0.4062 - val_loss: 0.4108 - 33ms/epoch - 3ms/step\n",
      "Epoch 1611/2500\n",
      "11/11 - 0s - loss: 0.4131 - val_loss: 0.4198 - 30ms/epoch - 3ms/step\n",
      "Epoch 1612/2500\n",
      "11/11 - 0s - loss: 0.4222 - val_loss: 0.4112 - 29ms/epoch - 3ms/step\n",
      "Epoch 1613/2500\n",
      "11/11 - 0s - loss: 0.4121 - val_loss: 0.4132 - 30ms/epoch - 3ms/step\n",
      "Epoch 1614/2500\n",
      "11/11 - 0s - loss: 0.3959 - val_loss: 0.4085 - 29ms/epoch - 3ms/step\n",
      "Epoch 1615/2500\n",
      "11/11 - 0s - loss: 0.4005 - val_loss: 0.4061 - 30ms/epoch - 3ms/step\n",
      "Epoch 1616/2500\n",
      "11/11 - 0s - loss: 0.4011 - val_loss: 0.4026 - 28ms/epoch - 3ms/step\n",
      "Epoch 1617/2500\n",
      "11/11 - 0s - loss: 0.3951 - val_loss: 0.4026 - 29ms/epoch - 3ms/step\n",
      "Epoch 1618/2500\n",
      "11/11 - 0s - loss: 0.4000 - val_loss: 0.3985 - 28ms/epoch - 3ms/step\n",
      "Epoch 1619/2500\n",
      "11/11 - 0s - loss: 0.4219 - val_loss: 0.4074 - 29ms/epoch - 3ms/step\n",
      "Epoch 1620/2500\n",
      "11/11 - 0s - loss: 0.4069 - val_loss: 0.4088 - 29ms/epoch - 3ms/step\n",
      "Epoch 1621/2500\n",
      "11/11 - 0s - loss: 0.4023 - val_loss: 0.4168 - 37ms/epoch - 3ms/step\n",
      "Epoch 1622/2500\n",
      "11/11 - 0s - loss: 0.3985 - val_loss: 0.4163 - 32ms/epoch - 3ms/step\n",
      "Epoch 1623/2500\n",
      "11/11 - 0s - loss: 0.4013 - val_loss: 0.4166 - 29ms/epoch - 3ms/step\n",
      "Epoch 1624/2500\n",
      "11/11 - 0s - loss: 0.3962 - val_loss: 0.4153 - 30ms/epoch - 3ms/step\n",
      "Epoch 1625/2500\n",
      "11/11 - 0s - loss: 0.4021 - val_loss: 0.4131 - 30ms/epoch - 3ms/step\n",
      "Epoch 1626/2500\n",
      "11/11 - 0s - loss: 0.4005 - val_loss: 0.4063 - 30ms/epoch - 3ms/step\n",
      "Epoch 1627/2500\n",
      "11/11 - 0s - loss: 0.4051 - val_loss: 0.4092 - 31ms/epoch - 3ms/step\n",
      "Epoch 1628/2500\n",
      "11/11 - 0s - loss: 0.4115 - val_loss: 0.4051 - 30ms/epoch - 3ms/step\n",
      "Epoch 1629/2500\n",
      "11/11 - 0s - loss: 0.4096 - val_loss: 0.4127 - 31ms/epoch - 3ms/step\n",
      "Epoch 1630/2500\n",
      "11/11 - 0s - loss: 0.3884 - val_loss: 0.4095 - 31ms/epoch - 3ms/step\n",
      "Epoch 1631/2500\n",
      "11/11 - 0s - loss: 0.4014 - val_loss: 0.4035 - 32ms/epoch - 3ms/step\n",
      "Epoch 1632/2500\n",
      "11/11 - 0s - loss: 0.4099 - val_loss: 0.4042 - 33ms/epoch - 3ms/step\n",
      "Epoch 1633/2500\n",
      "11/11 - 0s - loss: 0.3963 - val_loss: 0.4074 - 32ms/epoch - 3ms/step\n",
      "Epoch 1634/2500\n",
      "11/11 - 0s - loss: 0.3963 - val_loss: 0.4072 - 30ms/epoch - 3ms/step\n",
      "Epoch 1635/2500\n",
      "11/11 - 0s - loss: 0.4094 - val_loss: 0.4063 - 30ms/epoch - 3ms/step\n",
      "Epoch 1636/2500\n",
      "11/11 - 0s - loss: 0.3938 - val_loss: 0.4056 - 30ms/epoch - 3ms/step\n",
      "Epoch 1637/2500\n",
      "11/11 - 0s - loss: 0.4046 - val_loss: 0.4148 - 29ms/epoch - 3ms/step\n",
      "Epoch 1638/2500\n",
      "11/11 - 0s - loss: 0.3998 - val_loss: 0.4135 - 30ms/epoch - 3ms/step\n",
      "Epoch 1639/2500\n",
      "11/11 - 0s - loss: 0.4066 - val_loss: 0.4083 - 29ms/epoch - 3ms/step\n",
      "Epoch 1640/2500\n",
      "11/11 - 0s - loss: 0.4066 - val_loss: 0.4292 - 31ms/epoch - 3ms/step\n",
      "Epoch 1641/2500\n",
      "11/11 - 0s - loss: 0.4032 - val_loss: 0.4219 - 44ms/epoch - 4ms/step\n",
      "Epoch 1642/2500\n",
      "11/11 - 0s - loss: 0.3930 - val_loss: 0.4191 - 29ms/epoch - 3ms/step\n",
      "Epoch 1643/2500\n",
      "11/11 - 0s - loss: 0.3959 - val_loss: 0.4255 - 30ms/epoch - 3ms/step\n",
      "Epoch 1644/2500\n",
      "11/11 - 0s - loss: 0.3886 - val_loss: 0.4137 - 30ms/epoch - 3ms/step\n",
      "Epoch 1645/2500\n",
      "11/11 - 0s - loss: 0.3983 - val_loss: 0.4159 - 30ms/epoch - 3ms/step\n",
      "Epoch 1646/2500\n",
      "11/11 - 0s - loss: 0.3872 - val_loss: 0.4215 - 28ms/epoch - 3ms/step\n",
      "Epoch 1647/2500\n",
      "11/11 - 0s - loss: 0.4075 - val_loss: 0.4185 - 29ms/epoch - 3ms/step\n",
      "Epoch 1648/2500\n",
      "11/11 - 0s - loss: 0.4222 - val_loss: 0.4200 - 30ms/epoch - 3ms/step\n",
      "Epoch 1649/2500\n",
      "11/11 - 0s - loss: 0.4238 - val_loss: 0.4099 - 30ms/epoch - 3ms/step\n",
      "Epoch 1650/2500\n",
      "11/11 - 0s - loss: 0.3816 - val_loss: 0.4109 - 31ms/epoch - 3ms/step\n",
      "Epoch 1651/2500\n",
      "11/11 - 0s - loss: 0.4067 - val_loss: 0.4048 - 30ms/epoch - 3ms/step\n",
      "Epoch 1652/2500\n",
      "11/11 - 0s - loss: 0.3994 - val_loss: 0.4094 - 29ms/epoch - 3ms/step\n",
      "Epoch 1653/2500\n",
      "11/11 - 0s - loss: 0.4057 - val_loss: 0.4133 - 31ms/epoch - 3ms/step\n",
      "Epoch 1654/2500\n",
      "11/11 - 0s - loss: 0.4045 - val_loss: 0.4228 - 33ms/epoch - 3ms/step\n",
      "Epoch 1655/2500\n",
      "11/11 - 0s - loss: 0.4118 - val_loss: 0.4218 - 33ms/epoch - 3ms/step\n",
      "Epoch 1656/2500\n",
      "11/11 - 0s - loss: 0.3959 - val_loss: 0.4238 - 30ms/epoch - 3ms/step\n",
      "Epoch 1657/2500\n",
      "11/11 - 0s - loss: 0.3959 - val_loss: 0.4274 - 32ms/epoch - 3ms/step\n",
      "Epoch 1658/2500\n",
      "11/11 - 0s - loss: 0.3987 - val_loss: 0.4273 - 30ms/epoch - 3ms/step\n",
      "Epoch 1659/2500\n",
      "11/11 - 0s - loss: 0.4150 - val_loss: 0.4184 - 28ms/epoch - 3ms/step\n",
      "Epoch 1660/2500\n",
      "11/11 - 0s - loss: 0.4030 - val_loss: 0.4178 - 29ms/epoch - 3ms/step\n",
      "Epoch 1661/2500\n",
      "11/11 - 0s - loss: 0.3983 - val_loss: 0.4128 - 41ms/epoch - 4ms/step\n",
      "Epoch 1662/2500\n",
      "11/11 - 0s - loss: 0.3971 - val_loss: 0.4129 - 28ms/epoch - 3ms/step\n",
      "Epoch 1663/2500\n",
      "11/11 - 0s - loss: 0.4064 - val_loss: 0.4088 - 32ms/epoch - 3ms/step\n",
      "Epoch 1664/2500\n",
      "11/11 - 0s - loss: 0.4070 - val_loss: 0.4105 - 32ms/epoch - 3ms/step\n",
      "Epoch 1665/2500\n",
      "11/11 - 0s - loss: 0.3963 - val_loss: 0.4183 - 30ms/epoch - 3ms/step\n",
      "Epoch 1666/2500\n",
      "11/11 - 0s - loss: 0.3898 - val_loss: 0.4133 - 33ms/epoch - 3ms/step\n",
      "Epoch 1667/2500\n",
      "11/11 - 0s - loss: 0.4179 - val_loss: 0.4106 - 30ms/epoch - 3ms/step\n",
      "Epoch 1668/2500\n",
      "11/11 - 0s - loss: 0.4062 - val_loss: 0.4126 - 30ms/epoch - 3ms/step\n",
      "Epoch 1669/2500\n",
      "11/11 - 0s - loss: 0.4013 - val_loss: 0.4169 - 30ms/epoch - 3ms/step\n",
      "Epoch 1670/2500\n",
      "11/11 - 0s - loss: 0.4047 - val_loss: 0.4165 - 33ms/epoch - 3ms/step\n",
      "Epoch 1671/2500\n",
      "11/11 - 0s - loss: 0.4088 - val_loss: 0.4132 - 34ms/epoch - 3ms/step\n",
      "Epoch 1672/2500\n",
      "11/11 - 0s - loss: 0.4065 - val_loss: 0.4164 - 31ms/epoch - 3ms/step\n",
      "Epoch 1673/2500\n",
      "11/11 - 0s - loss: 0.4106 - val_loss: 0.4108 - 31ms/epoch - 3ms/step\n",
      "Epoch 1674/2500\n",
      "11/11 - 0s - loss: 0.3963 - val_loss: 0.4209 - 31ms/epoch - 3ms/step\n",
      "Epoch 1675/2500\n",
      "11/11 - 0s - loss: 0.4133 - val_loss: 0.4198 - 35ms/epoch - 3ms/step\n",
      "Epoch 1676/2500\n",
      "11/11 - 0s - loss: 0.3913 - val_loss: 0.4231 - 32ms/epoch - 3ms/step\n",
      "Epoch 1677/2500\n",
      "11/11 - 0s - loss: 0.4004 - val_loss: 0.4137 - 38ms/epoch - 3ms/step\n",
      "Epoch 1678/2500\n",
      "11/11 - 0s - loss: 0.3993 - val_loss: 0.4193 - 34ms/epoch - 3ms/step\n",
      "Epoch 1679/2500\n",
      "11/11 - 0s - loss: 0.4018 - val_loss: 0.4163 - 46ms/epoch - 4ms/step\n",
      "Epoch 1680/2500\n",
      "11/11 - 0s - loss: 0.4081 - val_loss: 0.4093 - 33ms/epoch - 3ms/step\n",
      "Epoch 1681/2500\n",
      "11/11 - 0s - loss: 0.4008 - val_loss: 0.4119 - 33ms/epoch - 3ms/step\n",
      "Epoch 1682/2500\n",
      "11/11 - 0s - loss: 0.4023 - val_loss: 0.4222 - 32ms/epoch - 3ms/step\n",
      "Epoch 1683/2500\n",
      "11/11 - 0s - loss: 0.4065 - val_loss: 0.4086 - 31ms/epoch - 3ms/step\n",
      "Epoch 1684/2500\n",
      "11/11 - 0s - loss: 0.3980 - val_loss: 0.4210 - 33ms/epoch - 3ms/step\n",
      "Epoch 1685/2500\n",
      "11/11 - 0s - loss: 0.4043 - val_loss: 0.4136 - 31ms/epoch - 3ms/step\n",
      "Epoch 1686/2500\n",
      "11/11 - 0s - loss: 0.4034 - val_loss: 0.4097 - 32ms/epoch - 3ms/step\n",
      "Epoch 1687/2500\n",
      "11/11 - 0s - loss: 0.4123 - val_loss: 0.4108 - 32ms/epoch - 3ms/step\n",
      "Epoch 1688/2500\n",
      "11/11 - 0s - loss: 0.4033 - val_loss: 0.4076 - 31ms/epoch - 3ms/step\n",
      "Epoch 1689/2500\n",
      "11/11 - 0s - loss: 0.3986 - val_loss: 0.4214 - 31ms/epoch - 3ms/step\n",
      "Epoch 1690/2500\n",
      "11/11 - 0s - loss: 0.4010 - val_loss: 0.4088 - 33ms/epoch - 3ms/step\n",
      "Epoch 1691/2500\n",
      "11/11 - 0s - loss: 0.3926 - val_loss: 0.4158 - 32ms/epoch - 3ms/step\n",
      "Epoch 1692/2500\n",
      "11/11 - 0s - loss: 0.4145 - val_loss: 0.4113 - 32ms/epoch - 3ms/step\n",
      "Epoch 1693/2500\n",
      "11/11 - 0s - loss: 0.4031 - val_loss: 0.4141 - 31ms/epoch - 3ms/step\n",
      "Epoch 1694/2500\n",
      "11/11 - 0s - loss: 0.4099 - val_loss: 0.4156 - 33ms/epoch - 3ms/step\n",
      "Epoch 1695/2500\n",
      "11/11 - 0s - loss: 0.4165 - val_loss: 0.4079 - 42ms/epoch - 4ms/step\n",
      "Epoch 1696/2500\n",
      "11/11 - 0s - loss: 0.4113 - val_loss: 0.4109 - 36ms/epoch - 3ms/step\n",
      "Epoch 1697/2500\n",
      "11/11 - 0s - loss: 0.4055 - val_loss: 0.4181 - 34ms/epoch - 3ms/step\n",
      "Epoch 1698/2500\n",
      "11/11 - 0s - loss: 0.3911 - val_loss: 0.4157 - 31ms/epoch - 3ms/step\n",
      "Epoch 1699/2500\n",
      "11/11 - 0s - loss: 0.4089 - val_loss: 0.4147 - 38ms/epoch - 3ms/step\n",
      "Epoch 1700/2500\n",
      "11/11 - 0s - loss: 0.4131 - val_loss: 0.4196 - 34ms/epoch - 3ms/step\n",
      "Epoch 1701/2500\n",
      "11/11 - 0s - loss: 0.4027 - val_loss: 0.4321 - 34ms/epoch - 3ms/step\n",
      "Epoch 1702/2500\n",
      "11/11 - 0s - loss: 0.4037 - val_loss: 0.4238 - 31ms/epoch - 3ms/step\n",
      "Epoch 1703/2500\n",
      "11/11 - 0s - loss: 0.3980 - val_loss: 0.4239 - 31ms/epoch - 3ms/step\n",
      "Epoch 1704/2500\n",
      "11/11 - 0s - loss: 0.3874 - val_loss: 0.4241 - 31ms/epoch - 3ms/step\n",
      "Epoch 1705/2500\n",
      "11/11 - 0s - loss: 0.4094 - val_loss: 0.4253 - 31ms/epoch - 3ms/step\n",
      "Epoch 1706/2500\n",
      "11/11 - 0s - loss: 0.4067 - val_loss: 0.4205 - 31ms/epoch - 3ms/step\n",
      "Epoch 1707/2500\n",
      "11/11 - 0s - loss: 0.4182 - val_loss: 0.4232 - 31ms/epoch - 3ms/step\n",
      "Epoch 1708/2500\n",
      "11/11 - 0s - loss: 0.4163 - val_loss: 0.4142 - 31ms/epoch - 3ms/step\n",
      "Epoch 1709/2500\n",
      "11/11 - 0s - loss: 0.3961 - val_loss: 0.4130 - 35ms/epoch - 3ms/step\n",
      "Epoch 1710/2500\n",
      "11/11 - 0s - loss: 0.3953 - val_loss: 0.4194 - 35ms/epoch - 3ms/step\n",
      "Epoch 1711/2500\n",
      "11/11 - 0s - loss: 0.3969 - val_loss: 0.4122 - 43ms/epoch - 4ms/step\n",
      "Epoch 1712/2500\n",
      "11/11 - 0s - loss: 0.3781 - val_loss: 0.4217 - 33ms/epoch - 3ms/step\n",
      "Epoch 1713/2500\n",
      "11/11 - 0s - loss: 0.4078 - val_loss: 0.4178 - 33ms/epoch - 3ms/step\n",
      "Epoch 1714/2500\n",
      "11/11 - 0s - loss: 0.4036 - val_loss: 0.4098 - 34ms/epoch - 3ms/step\n",
      "Epoch 1715/2500\n",
      "11/11 - 0s - loss: 0.3964 - val_loss: 0.4142 - 33ms/epoch - 3ms/step\n",
      "Epoch 1716/2500\n",
      "11/11 - 0s - loss: 0.3951 - val_loss: 0.4133 - 33ms/epoch - 3ms/step\n",
      "Epoch 1717/2500\n",
      "11/11 - 0s - loss: 0.3967 - val_loss: 0.4201 - 33ms/epoch - 3ms/step\n",
      "Epoch 1718/2500\n",
      "11/11 - 0s - loss: 0.3945 - val_loss: 0.4297 - 32ms/epoch - 3ms/step\n",
      "Epoch 1719/2500\n",
      "11/11 - 0s - loss: 0.4081 - val_loss: 0.4175 - 32ms/epoch - 3ms/step\n",
      "Epoch 1720/2500\n",
      "11/11 - 0s - loss: 0.4027 - val_loss: 0.4191 - 34ms/epoch - 3ms/step\n",
      "Epoch 1721/2500\n",
      "11/11 - 0s - loss: 0.3956 - val_loss: 0.4148 - 35ms/epoch - 3ms/step\n",
      "Epoch 1722/2500\n",
      "11/11 - 0s - loss: 0.4038 - val_loss: 0.4078 - 33ms/epoch - 3ms/step\n",
      "Epoch 1723/2500\n",
      "11/11 - 0s - loss: 0.4075 - val_loss: 0.4075 - 32ms/epoch - 3ms/step\n",
      "Epoch 1724/2500\n",
      "11/11 - 0s - loss: 0.4130 - val_loss: 0.4137 - 32ms/epoch - 3ms/step\n",
      "Epoch 1725/2500\n",
      "11/11 - 0s - loss: 0.4023 - val_loss: 0.4024 - 31ms/epoch - 3ms/step\n",
      "Epoch 1726/2500\n",
      "11/11 - 0s - loss: 0.4222 - val_loss: 0.4107 - 30ms/epoch - 3ms/step\n",
      "Epoch 1727/2500\n",
      "11/11 - 0s - loss: 0.4038 - val_loss: 0.4059 - 31ms/epoch - 3ms/step\n",
      "Epoch 1728/2500\n",
      "11/11 - 0s - loss: 0.3995 - val_loss: 0.4103 - 31ms/epoch - 3ms/step\n",
      "Epoch 1729/2500\n",
      "11/11 - 0s - loss: 0.4142 - val_loss: 0.4102 - 41ms/epoch - 4ms/step\n",
      "Epoch 1730/2500\n",
      "11/11 - 0s - loss: 0.3989 - val_loss: 0.4112 - 31ms/epoch - 3ms/step\n",
      "Epoch 1731/2500\n",
      "11/11 - 0s - loss: 0.3909 - val_loss: 0.4109 - 31ms/epoch - 3ms/step\n",
      "Epoch 1732/2500\n",
      "11/11 - 0s - loss: 0.3960 - val_loss: 0.4142 - 32ms/epoch - 3ms/step\n",
      "Epoch 1733/2500\n",
      "11/11 - 0s - loss: 0.4040 - val_loss: 0.4203 - 32ms/epoch - 3ms/step\n",
      "Epoch 1734/2500\n",
      "11/11 - 0s - loss: 0.3853 - val_loss: 0.4031 - 31ms/epoch - 3ms/step\n",
      "Epoch 1735/2500\n",
      "11/11 - 0s - loss: 0.4004 - val_loss: 0.4076 - 31ms/epoch - 3ms/step\n",
      "Epoch 1736/2500\n",
      "11/11 - 0s - loss: 0.3900 - val_loss: 0.4024 - 31ms/epoch - 3ms/step\n",
      "Epoch 1737/2500\n",
      "11/11 - 0s - loss: 0.4059 - val_loss: 0.4065 - 31ms/epoch - 3ms/step\n",
      "Epoch 1738/2500\n",
      "11/11 - 0s - loss: 0.4183 - val_loss: 0.4087 - 31ms/epoch - 3ms/step\n",
      "Epoch 1739/2500\n",
      "11/11 - 0s - loss: 0.4053 - val_loss: 0.4097 - 31ms/epoch - 3ms/step\n",
      "Epoch 1740/2500\n",
      "11/11 - 0s - loss: 0.4103 - val_loss: 0.4164 - 32ms/epoch - 3ms/step\n",
      "Epoch 1741/2500\n",
      "11/11 - 0s - loss: 0.4011 - val_loss: 0.4164 - 31ms/epoch - 3ms/step\n",
      "Epoch 1742/2500\n",
      "11/11 - 0s - loss: 0.4076 - val_loss: 0.4031 - 31ms/epoch - 3ms/step\n",
      "Epoch 1743/2500\n",
      "11/11 - 0s - loss: 0.3777 - val_loss: 0.4160 - 36ms/epoch - 3ms/step\n",
      "Epoch 1744/2500\n",
      "11/11 - 0s - loss: 0.3979 - val_loss: 0.4062 - 40ms/epoch - 4ms/step\n",
      "Epoch 1745/2500\n",
      "11/11 - 0s - loss: 0.4004 - val_loss: 0.4058 - 32ms/epoch - 3ms/step\n",
      "Epoch 1746/2500\n",
      "11/11 - 0s - loss: 0.4152 - val_loss: 0.3930 - 37ms/epoch - 3ms/step\n",
      "Epoch 1747/2500\n",
      "11/11 - 0s - loss: 0.3920 - val_loss: 0.3934 - 35ms/epoch - 3ms/step\n",
      "Epoch 1748/2500\n",
      "11/11 - 0s - loss: 0.4114 - val_loss: 0.3961 - 31ms/epoch - 3ms/step\n",
      "Epoch 1749/2500\n",
      "11/11 - 0s - loss: 0.3804 - val_loss: 0.3918 - 31ms/epoch - 3ms/step\n",
      "Epoch 1750/2500\n",
      "11/11 - 0s - loss: 0.3965 - val_loss: 0.3964 - 32ms/epoch - 3ms/step\n",
      "Epoch 1751/2500\n",
      "11/11 - 0s - loss: 0.3954 - val_loss: 0.4002 - 31ms/epoch - 3ms/step\n",
      "Epoch 1752/2500\n",
      "11/11 - 0s - loss: 0.3985 - val_loss: 0.4043 - 31ms/epoch - 3ms/step\n",
      "Epoch 1753/2500\n",
      "11/11 - 0s - loss: 0.4092 - val_loss: 0.4002 - 32ms/epoch - 3ms/step\n",
      "Epoch 1754/2500\n",
      "11/11 - 0s - loss: 0.4001 - val_loss: 0.4068 - 32ms/epoch - 3ms/step\n",
      "Epoch 1755/2500\n",
      "11/11 - 0s - loss: 0.4056 - val_loss: 0.4023 - 31ms/epoch - 3ms/step\n",
      "Epoch 1756/2500\n",
      "11/11 - 0s - loss: 0.4018 - val_loss: 0.4004 - 32ms/epoch - 3ms/step\n",
      "Epoch 1757/2500\n",
      "11/11 - 0s - loss: 0.3964 - val_loss: 0.4084 - 31ms/epoch - 3ms/step\n",
      "Epoch 1758/2500\n",
      "11/11 - 0s - loss: 0.4126 - val_loss: 0.4034 - 32ms/epoch - 3ms/step\n",
      "Epoch 1759/2500\n",
      "11/11 - 0s - loss: 0.3875 - val_loss: 0.4091 - 33ms/epoch - 3ms/step\n",
      "Epoch 1760/2500\n",
      "11/11 - 0s - loss: 0.4168 - val_loss: 0.4133 - 32ms/epoch - 3ms/step\n",
      "Epoch 1761/2500\n",
      "11/11 - 0s - loss: 0.3951 - val_loss: 0.4152 - 31ms/epoch - 3ms/step\n",
      "Epoch 1762/2500\n",
      "11/11 - 0s - loss: 0.4011 - val_loss: 0.4094 - 31ms/epoch - 3ms/step\n",
      "Epoch 1763/2500\n",
      "11/11 - 0s - loss: 0.4130 - val_loss: 0.4098 - 33ms/epoch - 3ms/step\n",
      "Epoch 1764/2500\n",
      "11/11 - 0s - loss: 0.3980 - val_loss: 0.4065 - 43ms/epoch - 4ms/step\n",
      "Epoch 1765/2500\n",
      "11/11 - 0s - loss: 0.3904 - val_loss: 0.4108 - 32ms/epoch - 3ms/step\n",
      "Epoch 1766/2500\n",
      "11/11 - 0s - loss: 0.3991 - val_loss: 0.4174 - 35ms/epoch - 3ms/step\n",
      "Epoch 1767/2500\n",
      "11/11 - 0s - loss: 0.3907 - val_loss: 0.4117 - 31ms/epoch - 3ms/step\n",
      "Epoch 1768/2500\n",
      "11/11 - 0s - loss: 0.3888 - val_loss: 0.4119 - 32ms/epoch - 3ms/step\n",
      "Epoch 1769/2500\n",
      "11/11 - 0s - loss: 0.4032 - val_loss: 0.4141 - 31ms/epoch - 3ms/step\n",
      "Epoch 1770/2500\n",
      "11/11 - 0s - loss: 0.3993 - val_loss: 0.4038 - 32ms/epoch - 3ms/step\n",
      "Epoch 1771/2500\n",
      "11/11 - 0s - loss: 0.3906 - val_loss: 0.4041 - 31ms/epoch - 3ms/step\n",
      "Epoch 1772/2500\n",
      "11/11 - 0s - loss: 0.3982 - val_loss: 0.4116 - 32ms/epoch - 3ms/step\n",
      "Epoch 1773/2500\n",
      "11/11 - 0s - loss: 0.3946 - val_loss: 0.4056 - 31ms/epoch - 3ms/step\n",
      "Epoch 1774/2500\n",
      "11/11 - 0s - loss: 0.4008 - val_loss: 0.4234 - 31ms/epoch - 3ms/step\n",
      "Epoch 1775/2500\n",
      "11/11 - 0s - loss: 0.4005 - val_loss: 0.4077 - 32ms/epoch - 3ms/step\n",
      "Epoch 1776/2500\n",
      "11/11 - 0s - loss: 0.4146 - val_loss: 0.4105 - 31ms/epoch - 3ms/step\n",
      "Epoch 1777/2500\n",
      "11/11 - 0s - loss: 0.4097 - val_loss: 0.4107 - 31ms/epoch - 3ms/step\n",
      "Epoch 1778/2500\n",
      "11/11 - 0s - loss: 0.4099 - val_loss: 0.4126 - 32ms/epoch - 3ms/step\n",
      "Epoch 1779/2500\n",
      "11/11 - 0s - loss: 0.3844 - val_loss: 0.4055 - 31ms/epoch - 3ms/step\n",
      "Epoch 1780/2500\n",
      "11/11 - 0s - loss: 0.4003 - val_loss: 0.4065 - 31ms/epoch - 3ms/step\n",
      "Epoch 1781/2500\n",
      "11/11 - 0s - loss: 0.3815 - val_loss: 0.4106 - 32ms/epoch - 3ms/step\n",
      "Epoch 1782/2500\n",
      "11/11 - 0s - loss: 0.4046 - val_loss: 0.4085 - 31ms/epoch - 3ms/step\n",
      "Epoch 1783/2500\n",
      "11/11 - 0s - loss: 0.3975 - val_loss: 0.4148 - 44ms/epoch - 4ms/step\n",
      "Epoch 1784/2500\n",
      "11/11 - 0s - loss: 0.3945 - val_loss: 0.4059 - 31ms/epoch - 3ms/step\n",
      "Epoch 1785/2500\n",
      "11/11 - 0s - loss: 0.4001 - val_loss: 0.4072 - 36ms/epoch - 3ms/step\n",
      "Epoch 1786/2500\n",
      "11/11 - 0s - loss: 0.4089 - val_loss: 0.4066 - 31ms/epoch - 3ms/step\n",
      "Epoch 1787/2500\n",
      "11/11 - 0s - loss: 0.3960 - val_loss: 0.4042 - 32ms/epoch - 3ms/step\n",
      "Epoch 1788/2500\n",
      "11/11 - 0s - loss: 0.4027 - val_loss: 0.4091 - 34ms/epoch - 3ms/step\n",
      "Epoch 1789/2500\n",
      "11/11 - 0s - loss: 0.3936 - val_loss: 0.4128 - 32ms/epoch - 3ms/step\n",
      "Epoch 1790/2500\n",
      "11/11 - 0s - loss: 0.3937 - val_loss: 0.4050 - 32ms/epoch - 3ms/step\n",
      "Epoch 1791/2500\n",
      "11/11 - 0s - loss: 0.3948 - val_loss: 0.4082 - 32ms/epoch - 3ms/step\n",
      "Epoch 1792/2500\n",
      "11/11 - 0s - loss: 0.4183 - val_loss: 0.4017 - 31ms/epoch - 3ms/step\n",
      "Epoch 1793/2500\n",
      "11/11 - 0s - loss: 0.3801 - val_loss: 0.4181 - 31ms/epoch - 3ms/step\n",
      "Epoch 1794/2500\n",
      "11/11 - 0s - loss: 0.4098 - val_loss: 0.4134 - 32ms/epoch - 3ms/step\n",
      "Epoch 1795/2500\n",
      "11/11 - 0s - loss: 0.4167 - val_loss: 0.4113 - 37ms/epoch - 3ms/step\n",
      "Epoch 1796/2500\n",
      "11/11 - 0s - loss: 0.4028 - val_loss: 0.4110 - 31ms/epoch - 3ms/step\n",
      "Epoch 1797/2500\n",
      "11/11 - 0s - loss: 0.4011 - val_loss: 0.3988 - 32ms/epoch - 3ms/step\n",
      "Epoch 1798/2500\n",
      "11/11 - 0s - loss: 0.3968 - val_loss: 0.4053 - 31ms/epoch - 3ms/step\n",
      "Epoch 1799/2500\n",
      "11/11 - 0s - loss: 0.4118 - val_loss: 0.4074 - 31ms/epoch - 3ms/step\n",
      "Epoch 1800/2500\n",
      "11/11 - 0s - loss: 0.4048 - val_loss: 0.4121 - 30ms/epoch - 3ms/step\n",
      "Epoch 1801/2500\n",
      "11/11 - 0s - loss: 0.4148 - val_loss: 0.4052 - 31ms/epoch - 3ms/step\n",
      "Epoch 1802/2500\n",
      "11/11 - 0s - loss: 0.3871 - val_loss: 0.4050 - 43ms/epoch - 4ms/step\n",
      "Epoch 1803/2500\n",
      "11/11 - 0s - loss: 0.4075 - val_loss: 0.4047 - 33ms/epoch - 3ms/step\n",
      "Epoch 1804/2500\n",
      "11/11 - 0s - loss: 0.3968 - val_loss: 0.4072 - 34ms/epoch - 3ms/step\n",
      "Epoch 1805/2500\n",
      "11/11 - 0s - loss: 0.4015 - val_loss: 0.4013 - 32ms/epoch - 3ms/step\n",
      "Epoch 1806/2500\n",
      "11/11 - 0s - loss: 0.3869 - val_loss: 0.4155 - 32ms/epoch - 3ms/step\n",
      "Epoch 1807/2500\n",
      "11/11 - 0s - loss: 0.4081 - val_loss: 0.4067 - 30ms/epoch - 3ms/step\n",
      "Epoch 1808/2500\n",
      "11/11 - 0s - loss: 0.3950 - val_loss: 0.4077 - 32ms/epoch - 3ms/step\n",
      "Epoch 1809/2500\n",
      "11/11 - 0s - loss: 0.4016 - val_loss: 0.3986 - 33ms/epoch - 3ms/step\n",
      "Epoch 1810/2500\n",
      "11/11 - 0s - loss: 0.3901 - val_loss: 0.4083 - 33ms/epoch - 3ms/step\n",
      "Epoch 1811/2500\n",
      "11/11 - 0s - loss: 0.4096 - val_loss: 0.4004 - 31ms/epoch - 3ms/step\n",
      "Epoch 1812/2500\n",
      "11/11 - 0s - loss: 0.4028 - val_loss: 0.4048 - 31ms/epoch - 3ms/step\n",
      "Epoch 1813/2500\n",
      "11/11 - 0s - loss: 0.3976 - val_loss: 0.4146 - 31ms/epoch - 3ms/step\n",
      "Epoch 1814/2500\n",
      "11/11 - 0s - loss: 0.3914 - val_loss: 0.4099 - 32ms/epoch - 3ms/step\n",
      "Epoch 1815/2500\n",
      "11/11 - 0s - loss: 0.3887 - val_loss: 0.4188 - 32ms/epoch - 3ms/step\n",
      "Epoch 1816/2500\n",
      "11/11 - 0s - loss: 0.3945 - val_loss: 0.4060 - 40ms/epoch - 4ms/step\n",
      "Epoch 1817/2500\n",
      "11/11 - 0s - loss: 0.3980 - val_loss: 0.4095 - 38ms/epoch - 3ms/step\n",
      "Epoch 1818/2500\n",
      "11/11 - 0s - loss: 0.4132 - val_loss: 0.4080 - 32ms/epoch - 3ms/step\n",
      "Epoch 1819/2500\n",
      "11/11 - 0s - loss: 0.3941 - val_loss: 0.4069 - 31ms/epoch - 3ms/step\n",
      "Epoch 1820/2500\n",
      "11/11 - 0s - loss: 0.4068 - val_loss: 0.4016 - 32ms/epoch - 3ms/step\n",
      "Epoch 1821/2500\n",
      "11/11 - 0s - loss: 0.3945 - val_loss: 0.4155 - 42ms/epoch - 4ms/step\n",
      "Epoch 1822/2500\n",
      "11/11 - 0s - loss: 0.3839 - val_loss: 0.4097 - 31ms/epoch - 3ms/step\n",
      "Epoch 1823/2500\n",
      "11/11 - 0s - loss: 0.3996 - val_loss: 0.4045 - 31ms/epoch - 3ms/step\n",
      "Epoch 1824/2500\n",
      "11/11 - 0s - loss: 0.3931 - val_loss: 0.4006 - 30ms/epoch - 3ms/step\n",
      "Epoch 1825/2500\n",
      "11/11 - 0s - loss: 0.3948 - val_loss: 0.4027 - 31ms/epoch - 3ms/step\n",
      "Epoch 1826/2500\n",
      "11/11 - 0s - loss: 0.3958 - val_loss: 0.4046 - 31ms/epoch - 3ms/step\n",
      "Epoch 1827/2500\n",
      "11/11 - 0s - loss: 0.4005 - val_loss: 0.4061 - 31ms/epoch - 3ms/step\n",
      "Epoch 1828/2500\n",
      "11/11 - 0s - loss: 0.4042 - val_loss: 0.4034 - 31ms/epoch - 3ms/step\n",
      "Epoch 1829/2500\n",
      "11/11 - 0s - loss: 0.3979 - val_loss: 0.4003 - 34ms/epoch - 3ms/step\n",
      "Epoch 1830/2500\n",
      "11/11 - 0s - loss: 0.4072 - val_loss: 0.3969 - 33ms/epoch - 3ms/step\n",
      "Epoch 1831/2500\n",
      "11/11 - 0s - loss: 0.3935 - val_loss: 0.4042 - 29ms/epoch - 3ms/step\n",
      "Epoch 1832/2500\n",
      "11/11 - 0s - loss: 0.3958 - val_loss: 0.4097 - 29ms/epoch - 3ms/step\n",
      "Epoch 1833/2500\n",
      "11/11 - 0s - loss: 0.4180 - val_loss: 0.4110 - 28ms/epoch - 3ms/step\n",
      "Epoch 1834/2500\n",
      "11/11 - 0s - loss: 0.4049 - val_loss: 0.4144 - 28ms/epoch - 3ms/step\n",
      "Epoch 1835/2500\n",
      "11/11 - 0s - loss: 0.4064 - val_loss: 0.4166 - 31ms/epoch - 3ms/step\n",
      "Epoch 1836/2500\n",
      "11/11 - 0s - loss: 0.4048 - val_loss: 0.4221 - 29ms/epoch - 3ms/step\n",
      "Epoch 1837/2500\n",
      "11/11 - 0s - loss: 0.4074 - val_loss: 0.4155 - 28ms/epoch - 3ms/step\n",
      "Epoch 1838/2500\n",
      "11/11 - 0s - loss: 0.4015 - val_loss: 0.4141 - 28ms/epoch - 3ms/step\n",
      "Epoch 1839/2500\n",
      "11/11 - 0s - loss: 0.4083 - val_loss: 0.4080 - 29ms/epoch - 3ms/step\n",
      "Epoch 1840/2500\n",
      "11/11 - 0s - loss: 0.3993 - val_loss: 0.4037 - 38ms/epoch - 3ms/step\n",
      "Epoch 1841/2500\n",
      "11/11 - 0s - loss: 0.3850 - val_loss: 0.4094 - 30ms/epoch - 3ms/step\n",
      "Epoch 1842/2500\n",
      "11/11 - 0s - loss: 0.3967 - val_loss: 0.4049 - 29ms/epoch - 3ms/step\n",
      "Epoch 1843/2500\n",
      "11/11 - 0s - loss: 0.4088 - val_loss: 0.3995 - 29ms/epoch - 3ms/step\n",
      "Epoch 1844/2500\n",
      "11/11 - 0s - loss: 0.3927 - val_loss: 0.4019 - 29ms/epoch - 3ms/step\n",
      "Epoch 1845/2500\n",
      "11/11 - 0s - loss: 0.3967 - val_loss: 0.4022 - 28ms/epoch - 3ms/step\n",
      "Epoch 1846/2500\n",
      "11/11 - 0s - loss: 0.3864 - val_loss: 0.3961 - 28ms/epoch - 3ms/step\n",
      "Epoch 1847/2500\n",
      "11/11 - 0s - loss: 0.3919 - val_loss: 0.3974 - 28ms/epoch - 3ms/step\n",
      "Epoch 1848/2500\n",
      "11/11 - 0s - loss: 0.4135 - val_loss: 0.4110 - 28ms/epoch - 3ms/step\n",
      "Epoch 1849/2500\n",
      "11/11 - 0s - loss: 0.3937 - val_loss: 0.4013 - 29ms/epoch - 3ms/step\n",
      "Epoch 1850/2500\n",
      "11/11 - 0s - loss: 0.4113 - val_loss: 0.4107 - 29ms/epoch - 3ms/step\n",
      "Epoch 1851/2500\n",
      "11/11 - 0s - loss: 0.3959 - val_loss: 0.4132 - 30ms/epoch - 3ms/step\n",
      "Epoch 1852/2500\n",
      "11/11 - 0s - loss: 0.3812 - val_loss: 0.4206 - 29ms/epoch - 3ms/step\n",
      "Epoch 1853/2500\n",
      "11/11 - 0s - loss: 0.3997 - val_loss: 0.4217 - 28ms/epoch - 3ms/step\n",
      "Epoch 1854/2500\n",
      "11/11 - 0s - loss: 0.4022 - val_loss: 0.4188 - 29ms/epoch - 3ms/step\n",
      "Epoch 1855/2500\n",
      "11/11 - 0s - loss: 0.3872 - val_loss: 0.4174 - 30ms/epoch - 3ms/step\n",
      "Epoch 1856/2500\n",
      "11/11 - 0s - loss: 0.4159 - val_loss: 0.4231 - 30ms/epoch - 3ms/step\n",
      "Epoch 1857/2500\n",
      "11/11 - 0s - loss: 0.3875 - val_loss: 0.4105 - 29ms/epoch - 3ms/step\n",
      "Epoch 1858/2500\n",
      "11/11 - 0s - loss: 0.3848 - val_loss: 0.4166 - 30ms/epoch - 3ms/step\n",
      "Epoch 1859/2500\n",
      "11/11 - 0s - loss: 0.3915 - val_loss: 0.4089 - 39ms/epoch - 4ms/step\n",
      "Epoch 1860/2500\n",
      "11/11 - 0s - loss: 0.4019 - val_loss: 0.4067 - 29ms/epoch - 3ms/step\n",
      "Epoch 1861/2500\n",
      "11/11 - 0s - loss: 0.3799 - val_loss: 0.4170 - 29ms/epoch - 3ms/step\n",
      "Epoch 1862/2500\n",
      "11/11 - 0s - loss: 0.3976 - val_loss: 0.4181 - 28ms/epoch - 3ms/step\n",
      "Epoch 1863/2500\n",
      "11/11 - 0s - loss: 0.4029 - val_loss: 0.4174 - 28ms/epoch - 3ms/step\n",
      "Epoch 1864/2500\n",
      "11/11 - 0s - loss: 0.3912 - val_loss: 0.4123 - 29ms/epoch - 3ms/step\n",
      "Epoch 1865/2500\n",
      "11/11 - 0s - loss: 0.3866 - val_loss: 0.4166 - 29ms/epoch - 3ms/step\n",
      "Epoch 1866/2500\n",
      "11/11 - 0s - loss: 0.3810 - val_loss: 0.4152 - 28ms/epoch - 3ms/step\n",
      "Epoch 1867/2500\n",
      "11/11 - 0s - loss: 0.4047 - val_loss: 0.4089 - 28ms/epoch - 3ms/step\n",
      "Epoch 1868/2500\n",
      "11/11 - 0s - loss: 0.3986 - val_loss: 0.4105 - 28ms/epoch - 3ms/step\n",
      "Epoch 1869/2500\n",
      "11/11 - 0s - loss: 0.4129 - val_loss: 0.4202 - 29ms/epoch - 3ms/step\n",
      "Epoch 1870/2500\n",
      "11/11 - 0s - loss: 0.4154 - val_loss: 0.4114 - 29ms/epoch - 3ms/step\n",
      "Epoch 1871/2500\n",
      "11/11 - 0s - loss: 0.3927 - val_loss: 0.4107 - 29ms/epoch - 3ms/step\n",
      "Epoch 1872/2500\n",
      "11/11 - 0s - loss: 0.3865 - val_loss: 0.4071 - 30ms/epoch - 3ms/step\n",
      "Epoch 1873/2500\n",
      "11/11 - 0s - loss: 0.3902 - val_loss: 0.4124 - 30ms/epoch - 3ms/step\n",
      "Epoch 1874/2500\n",
      "11/11 - 0s - loss: 0.4119 - val_loss: 0.4099 - 29ms/epoch - 3ms/step\n",
      "Epoch 1875/2500\n",
      "11/11 - 0s - loss: 0.4002 - val_loss: 0.4104 - 28ms/epoch - 3ms/step\n",
      "Epoch 1876/2500\n",
      "11/11 - 0s - loss: 0.4018 - val_loss: 0.4129 - 29ms/epoch - 3ms/step\n",
      "Epoch 1877/2500\n",
      "11/11 - 0s - loss: 0.3808 - val_loss: 0.4071 - 29ms/epoch - 3ms/step\n",
      "Epoch 1878/2500\n",
      "11/11 - 0s - loss: 0.4079 - val_loss: 0.4092 - 36ms/epoch - 3ms/step\n",
      "Epoch 1879/2500\n",
      "11/11 - 0s - loss: 0.3823 - val_loss: 0.4127 - 28ms/epoch - 3ms/step\n",
      "Epoch 1880/2500\n",
      "11/11 - 0s - loss: 0.3964 - val_loss: 0.4221 - 28ms/epoch - 3ms/step\n",
      "Epoch 1881/2500\n",
      "11/11 - 0s - loss: 0.3996 - val_loss: 0.4161 - 28ms/epoch - 3ms/step\n",
      "Epoch 1882/2500\n",
      "11/11 - 0s - loss: 0.3977 - val_loss: 0.4132 - 28ms/epoch - 3ms/step\n",
      "Epoch 1883/2500\n",
      "11/11 - 0s - loss: 0.4165 - val_loss: 0.4144 - 28ms/epoch - 3ms/step\n",
      "Epoch 1884/2500\n",
      "11/11 - 0s - loss: 0.4069 - val_loss: 0.4171 - 28ms/epoch - 3ms/step\n",
      "Epoch 1885/2500\n",
      "11/11 - 0s - loss: 0.3932 - val_loss: 0.4123 - 28ms/epoch - 3ms/step\n",
      "Epoch 1886/2500\n",
      "11/11 - 0s - loss: 0.3904 - val_loss: 0.4041 - 28ms/epoch - 3ms/step\n",
      "Epoch 1887/2500\n",
      "11/11 - 0s - loss: 0.4119 - val_loss: 0.4034 - 29ms/epoch - 3ms/step\n",
      "Epoch 1888/2500\n",
      "11/11 - 0s - loss: 0.4042 - val_loss: 0.3990 - 29ms/epoch - 3ms/step\n",
      "Epoch 1889/2500\n",
      "11/11 - 0s - loss: 0.4025 - val_loss: 0.4028 - 28ms/epoch - 3ms/step\n",
      "Epoch 1890/2500\n",
      "11/11 - 0s - loss: 0.4011 - val_loss: 0.4014 - 28ms/epoch - 3ms/step\n",
      "Epoch 1891/2500\n",
      "11/11 - 0s - loss: 0.3862 - val_loss: 0.4093 - 27ms/epoch - 2ms/step\n",
      "Epoch 1892/2500\n",
      "11/11 - 0s - loss: 0.3988 - val_loss: 0.4016 - 28ms/epoch - 3ms/step\n",
      "Epoch 1893/2500\n",
      "11/11 - 0s - loss: 0.3886 - val_loss: 0.4074 - 29ms/epoch - 3ms/step\n",
      "Epoch 1894/2500\n",
      "11/11 - 0s - loss: 0.4018 - val_loss: 0.4069 - 30ms/epoch - 3ms/step\n",
      "Epoch 1895/2500\n",
      "11/11 - 0s - loss: 0.3848 - val_loss: 0.4098 - 28ms/epoch - 3ms/step\n",
      "Epoch 1896/2500\n",
      "11/11 - 0s - loss: 0.3910 - val_loss: 0.4015 - 28ms/epoch - 3ms/step\n",
      "Epoch 1897/2500\n",
      "11/11 - 0s - loss: 0.4042 - val_loss: 0.4020 - 36ms/epoch - 3ms/step\n",
      "Epoch 1898/2500\n",
      "11/11 - 0s - loss: 0.4057 - val_loss: 0.4038 - 28ms/epoch - 3ms/step\n",
      "Epoch 1899/2500\n",
      "11/11 - 0s - loss: 0.3946 - val_loss: 0.4138 - 29ms/epoch - 3ms/step\n",
      "Epoch 1900/2500\n",
      "11/11 - 0s - loss: 0.4050 - val_loss: 0.4044 - 28ms/epoch - 3ms/step\n",
      "Epoch 1901/2500\n",
      "11/11 - 0s - loss: 0.3965 - val_loss: 0.4006 - 29ms/epoch - 3ms/step\n",
      "Epoch 1902/2500\n",
      "11/11 - 0s - loss: 0.3958 - val_loss: 0.4017 - 29ms/epoch - 3ms/step\n",
      "Epoch 1903/2500\n",
      "11/11 - 0s - loss: 0.3975 - val_loss: 0.4038 - 29ms/epoch - 3ms/step\n",
      "Epoch 1904/2500\n",
      "11/11 - 0s - loss: 0.4032 - val_loss: 0.4096 - 27ms/epoch - 2ms/step\n",
      "Epoch 1905/2500\n",
      "11/11 - 0s - loss: 0.4135 - val_loss: 0.4134 - 28ms/epoch - 3ms/step\n",
      "Epoch 1906/2500\n",
      "11/11 - 0s - loss: 0.4010 - val_loss: 0.4124 - 28ms/epoch - 3ms/step\n",
      "Epoch 1907/2500\n",
      "11/11 - 0s - loss: 0.3922 - val_loss: 0.4144 - 28ms/epoch - 3ms/step\n",
      "Epoch 1908/2500\n",
      "11/11 - 0s - loss: 0.3935 - val_loss: 0.4121 - 28ms/epoch - 3ms/step\n",
      "Epoch 1909/2500\n",
      "11/11 - 0s - loss: 0.4099 - val_loss: 0.4070 - 28ms/epoch - 3ms/step\n",
      "Epoch 1910/2500\n",
      "11/11 - 0s - loss: 0.4099 - val_loss: 0.4071 - 28ms/epoch - 3ms/step\n",
      "Epoch 1911/2500\n",
      "11/11 - 0s - loss: 0.3907 - val_loss: 0.4114 - 28ms/epoch - 3ms/step\n",
      "Epoch 1912/2500\n",
      "11/11 - 0s - loss: 0.3950 - val_loss: 0.4141 - 28ms/epoch - 3ms/step\n",
      "Epoch 1913/2500\n",
      "11/11 - 0s - loss: 0.3995 - val_loss: 0.4085 - 28ms/epoch - 3ms/step\n",
      "Epoch 1914/2500\n",
      "11/11 - 0s - loss: 0.3944 - val_loss: 0.4063 - 30ms/epoch - 3ms/step\n",
      "Epoch 1915/2500\n",
      "11/11 - 0s - loss: 0.3879 - val_loss: 0.4118 - 30ms/epoch - 3ms/step\n",
      "Epoch 1916/2500\n",
      "11/11 - 0s - loss: 0.3938 - val_loss: 0.4100 - 36ms/epoch - 3ms/step\n",
      "Epoch 1917/2500\n",
      "11/11 - 0s - loss: 0.4039 - val_loss: 0.4064 - 29ms/epoch - 3ms/step\n",
      "Epoch 1918/2500\n",
      "11/11 - 0s - loss: 0.4021 - val_loss: 0.4113 - 28ms/epoch - 3ms/step\n",
      "Epoch 1919/2500\n",
      "11/11 - 0s - loss: 0.3955 - val_loss: 0.4182 - 28ms/epoch - 3ms/step\n",
      "Epoch 1920/2500\n",
      "11/11 - 0s - loss: 0.3922 - val_loss: 0.4086 - 28ms/epoch - 3ms/step\n",
      "Epoch 1921/2500\n",
      "11/11 - 0s - loss: 0.4045 - val_loss: 0.4213 - 29ms/epoch - 3ms/step\n",
      "Epoch 1922/2500\n",
      "11/11 - 0s - loss: 0.3952 - val_loss: 0.4046 - 28ms/epoch - 3ms/step\n",
      "Epoch 1923/2500\n",
      "11/11 - 0s - loss: 0.4131 - val_loss: 0.4052 - 28ms/epoch - 3ms/step\n",
      "Epoch 1924/2500\n",
      "11/11 - 0s - loss: 0.4050 - val_loss: 0.3989 - 28ms/epoch - 3ms/step\n",
      "Epoch 1925/2500\n",
      "11/11 - 0s - loss: 0.3834 - val_loss: 0.4079 - 29ms/epoch - 3ms/step\n",
      "Epoch 1926/2500\n",
      "11/11 - 0s - loss: 0.4137 - val_loss: 0.4036 - 29ms/epoch - 3ms/step\n",
      "Epoch 1927/2500\n",
      "11/11 - 0s - loss: 0.3984 - val_loss: 0.4010 - 29ms/epoch - 3ms/step\n",
      "Epoch 1928/2500\n",
      "11/11 - 0s - loss: 0.3901 - val_loss: 0.4018 - 28ms/epoch - 3ms/step\n",
      "Epoch 1929/2500\n",
      "11/11 - 0s - loss: 0.4048 - val_loss: 0.4057 - 28ms/epoch - 3ms/step\n",
      "Epoch 1930/2500\n",
      "11/11 - 0s - loss: 0.3942 - val_loss: 0.4091 - 28ms/epoch - 3ms/step\n",
      "Epoch 1931/2500\n",
      "11/11 - 0s - loss: 0.4025 - val_loss: 0.4050 - 27ms/epoch - 2ms/step\n",
      "Epoch 1932/2500\n",
      "11/11 - 0s - loss: 0.4029 - val_loss: 0.4042 - 28ms/epoch - 3ms/step\n",
      "Epoch 1933/2500\n",
      "11/11 - 0s - loss: 0.3922 - val_loss: 0.4079 - 31ms/epoch - 3ms/step\n",
      "Epoch 1934/2500\n",
      "11/11 - 0s - loss: 0.3885 - val_loss: 0.4089 - 31ms/epoch - 3ms/step\n",
      "Epoch 1935/2500\n",
      "11/11 - 0s - loss: 0.3894 - val_loss: 0.4087 - 31ms/epoch - 3ms/step\n",
      "Epoch 1936/2500\n",
      "11/11 - 0s - loss: 0.4069 - val_loss: 0.4032 - 29ms/epoch - 3ms/step\n",
      "Epoch 1937/2500\n",
      "11/11 - 0s - loss: 0.4127 - val_loss: 0.4037 - 28ms/epoch - 3ms/step\n",
      "Epoch 1938/2500\n",
      "11/11 - 0s - loss: 0.3959 - val_loss: 0.3972 - 28ms/epoch - 3ms/step\n",
      "Epoch 1939/2500\n",
      "11/11 - 0s - loss: 0.3974 - val_loss: 0.3884 - 28ms/epoch - 3ms/step\n",
      "Epoch 1940/2500\n",
      "11/11 - 0s - loss: 0.3892 - val_loss: 0.3904 - 28ms/epoch - 3ms/step\n",
      "Epoch 1941/2500\n",
      "11/11 - 0s - loss: 0.3919 - val_loss: 0.3954 - 28ms/epoch - 3ms/step\n",
      "Epoch 1942/2500\n",
      "11/11 - 0s - loss: 0.3997 - val_loss: 0.3977 - 28ms/epoch - 3ms/step\n",
      "Epoch 1943/2500\n",
      "11/11 - 0s - loss: 0.4019 - val_loss: 0.3989 - 29ms/epoch - 3ms/step\n",
      "Epoch 1944/2500\n",
      "11/11 - 0s - loss: 0.3861 - val_loss: 0.3945 - 29ms/epoch - 3ms/step\n",
      "Epoch 1945/2500\n",
      "11/11 - 0s - loss: 0.4037 - val_loss: 0.3978 - 28ms/epoch - 3ms/step\n",
      "Epoch 1946/2500\n",
      "11/11 - 0s - loss: 0.3908 - val_loss: 0.4025 - 28ms/epoch - 3ms/step\n",
      "Epoch 1947/2500\n",
      "11/11 - 0s - loss: 0.4012 - val_loss: 0.4010 - 29ms/epoch - 3ms/step\n",
      "Epoch 1948/2500\n",
      "11/11 - 0s - loss: 0.4092 - val_loss: 0.4038 - 29ms/epoch - 3ms/step\n",
      "Epoch 1949/2500\n",
      "11/11 - 0s - loss: 0.3966 - val_loss: 0.4128 - 28ms/epoch - 3ms/step\n",
      "Epoch 1950/2500\n",
      "11/11 - 0s - loss: 0.3973 - val_loss: 0.4119 - 28ms/epoch - 3ms/step\n",
      "Epoch 1951/2500\n",
      "11/11 - 0s - loss: 0.4020 - val_loss: 0.4055 - 37ms/epoch - 3ms/step\n",
      "Epoch 1952/2500\n",
      "11/11 - 0s - loss: 0.3969 - val_loss: 0.4098 - 28ms/epoch - 3ms/step\n",
      "Epoch 1953/2500\n",
      "11/11 - 0s - loss: 0.3990 - val_loss: 0.4066 - 28ms/epoch - 3ms/step\n",
      "Epoch 1954/2500\n",
      "11/11 - 0s - loss: 0.3818 - val_loss: 0.4030 - 28ms/epoch - 3ms/step\n",
      "Epoch 1955/2500\n",
      "11/11 - 0s - loss: 0.3902 - val_loss: 0.3984 - 30ms/epoch - 3ms/step\n",
      "Epoch 1956/2500\n",
      "11/11 - 0s - loss: 0.3911 - val_loss: 0.3970 - 28ms/epoch - 3ms/step\n",
      "Epoch 1957/2500\n",
      "11/11 - 0s - loss: 0.4039 - val_loss: 0.4010 - 28ms/epoch - 3ms/step\n",
      "Epoch 1958/2500\n",
      "11/11 - 0s - loss: 0.3992 - val_loss: 0.3977 - 28ms/epoch - 3ms/step\n",
      "Epoch 1959/2500\n",
      "11/11 - 0s - loss: 0.3968 - val_loss: 0.4031 - 28ms/epoch - 3ms/step\n",
      "Epoch 1960/2500\n",
      "11/11 - 0s - loss: 0.3929 - val_loss: 0.4152 - 28ms/epoch - 3ms/step\n",
      "Epoch 1961/2500\n",
      "11/11 - 0s - loss: 0.3966 - val_loss: 0.4052 - 28ms/epoch - 3ms/step\n",
      "Epoch 1962/2500\n",
      "11/11 - 0s - loss: 0.3843 - val_loss: 0.4054 - 28ms/epoch - 3ms/step\n",
      "Epoch 1963/2500\n",
      "11/11 - 0s - loss: 0.4057 - val_loss: 0.4107 - 28ms/epoch - 3ms/step\n",
      "Epoch 1964/2500\n",
      "11/11 - 0s - loss: 0.3907 - val_loss: 0.4077 - 28ms/epoch - 3ms/step\n",
      "Epoch 1965/2500\n",
      "11/11 - 0s - loss: 0.4009 - val_loss: 0.4138 - 28ms/epoch - 3ms/step\n",
      "Epoch 1966/2500\n",
      "11/11 - 0s - loss: 0.3913 - val_loss: 0.4056 - 28ms/epoch - 3ms/step\n",
      "Epoch 1967/2500\n",
      "11/11 - 0s - loss: 0.3973 - val_loss: 0.4034 - 29ms/epoch - 3ms/step\n",
      "Epoch 1968/2500\n",
      "11/11 - 0s - loss: 0.4155 - val_loss: 0.4073 - 37ms/epoch - 3ms/step\n",
      "Epoch 1969/2500\n",
      "11/11 - 0s - loss: 0.4057 - val_loss: 0.4018 - 29ms/epoch - 3ms/step\n",
      "Epoch 1970/2500\n",
      "11/11 - 0s - loss: 0.4039 - val_loss: 0.4021 - 29ms/epoch - 3ms/step\n",
      "Epoch 1971/2500\n",
      "11/11 - 0s - loss: 0.4031 - val_loss: 0.4072 - 29ms/epoch - 3ms/step\n",
      "Epoch 1972/2500\n",
      "11/11 - 0s - loss: 0.3955 - val_loss: 0.3987 - 29ms/epoch - 3ms/step\n",
      "Epoch 1973/2500\n",
      "11/11 - 0s - loss: 0.3905 - val_loss: 0.4011 - 29ms/epoch - 3ms/step\n",
      "Epoch 1974/2500\n",
      "11/11 - 0s - loss: 0.3833 - val_loss: 0.4036 - 28ms/epoch - 3ms/step\n",
      "Epoch 1975/2500\n",
      "11/11 - 0s - loss: 0.3984 - val_loss: 0.4094 - 30ms/epoch - 3ms/step\n",
      "Epoch 1976/2500\n",
      "11/11 - 0s - loss: 0.4035 - val_loss: 0.4131 - 30ms/epoch - 3ms/step\n",
      "Epoch 1977/2500\n",
      "11/11 - 0s - loss: 0.3927 - val_loss: 0.4095 - 29ms/epoch - 3ms/step\n",
      "Epoch 1978/2500\n",
      "11/11 - 0s - loss: 0.3841 - val_loss: 0.4089 - 28ms/epoch - 3ms/step\n",
      "Epoch 1979/2500\n",
      "11/11 - 0s - loss: 0.3851 - val_loss: 0.4034 - 28ms/epoch - 3ms/step\n",
      "Epoch 1980/2500\n",
      "11/11 - 0s - loss: 0.3962 - val_loss: 0.4080 - 28ms/epoch - 3ms/step\n",
      "Epoch 1981/2500\n",
      "11/11 - 0s - loss: 0.3851 - val_loss: 0.4109 - 28ms/epoch - 3ms/step\n",
      "Epoch 1982/2500\n",
      "11/11 - 0s - loss: 0.4002 - val_loss: 0.4076 - 28ms/epoch - 3ms/step\n",
      "Epoch 1983/2500\n",
      "11/11 - 0s - loss: 0.3893 - val_loss: 0.4069 - 28ms/epoch - 3ms/step\n",
      "Epoch 1984/2500\n",
      "11/11 - 0s - loss: 0.3982 - val_loss: 0.4048 - 28ms/epoch - 3ms/step\n",
      "Epoch 1985/2500\n",
      "11/11 - 0s - loss: 0.3901 - val_loss: 0.4066 - 39ms/epoch - 4ms/step\n",
      "Epoch 1986/2500\n",
      "11/11 - 0s - loss: 0.3928 - val_loss: 0.4101 - 28ms/epoch - 3ms/step\n",
      "Epoch 1987/2500\n",
      "11/11 - 0s - loss: 0.3898 - val_loss: 0.4025 - 29ms/epoch - 3ms/step\n",
      "Epoch 1988/2500\n",
      "11/11 - 0s - loss: 0.3940 - val_loss: 0.4103 - 28ms/epoch - 3ms/step\n",
      "Epoch 1989/2500\n",
      "11/11 - 0s - loss: 0.4035 - val_loss: 0.4024 - 29ms/epoch - 3ms/step\n",
      "Epoch 1990/2500\n",
      "11/11 - 0s - loss: 0.3976 - val_loss: 0.4064 - 28ms/epoch - 3ms/step\n",
      "Epoch 1991/2500\n",
      "11/11 - 0s - loss: 0.3943 - val_loss: 0.4128 - 28ms/epoch - 3ms/step\n",
      "Epoch 1992/2500\n",
      "11/11 - 0s - loss: 0.3928 - val_loss: 0.4168 - 28ms/epoch - 3ms/step\n",
      "Epoch 1993/2500\n",
      "11/11 - 0s - loss: 0.4047 - val_loss: 0.4177 - 28ms/epoch - 3ms/step\n",
      "Epoch 1994/2500\n",
      "11/11 - 0s - loss: 0.3913 - val_loss: 0.4066 - 28ms/epoch - 3ms/step\n",
      "Epoch 1995/2500\n",
      "11/11 - 0s - loss: 0.3968 - val_loss: 0.4064 - 29ms/epoch - 3ms/step\n",
      "Epoch 1996/2500\n",
      "11/11 - 0s - loss: 0.4002 - val_loss: 0.4018 - 30ms/epoch - 3ms/step\n",
      "Epoch 1997/2500\n",
      "11/11 - 0s - loss: 0.4024 - val_loss: 0.4096 - 28ms/epoch - 3ms/step\n",
      "Epoch 1998/2500\n",
      "11/11 - 0s - loss: 0.3809 - val_loss: 0.4052 - 28ms/epoch - 3ms/step\n",
      "Epoch 1999/2500\n",
      "11/11 - 0s - loss: 0.3890 - val_loss: 0.4165 - 29ms/epoch - 3ms/step\n",
      "Epoch 2000/2500\n",
      "11/11 - 0s - loss: 0.4062 - val_loss: 0.4092 - 28ms/epoch - 3ms/step\n",
      "Epoch 2001/2500\n",
      "11/11 - 0s - loss: 0.3972 - val_loss: 0.4130 - 29ms/epoch - 3ms/step\n",
      "Epoch 2002/2500\n",
      "11/11 - 0s - loss: 0.3882 - val_loss: 0.4181 - 37ms/epoch - 3ms/step\n",
      "Epoch 2003/2500\n",
      "11/11 - 0s - loss: 0.3934 - val_loss: 0.4164 - 29ms/epoch - 3ms/step\n",
      "Epoch 2004/2500\n",
      "11/11 - 0s - loss: 0.3932 - val_loss: 0.4214 - 28ms/epoch - 3ms/step\n",
      "Epoch 2005/2500\n",
      "11/11 - 0s - loss: 0.3934 - val_loss: 0.4152 - 29ms/epoch - 3ms/step\n",
      "Epoch 2006/2500\n",
      "11/11 - 0s - loss: 0.3962 - val_loss: 0.4167 - 29ms/epoch - 3ms/step\n",
      "Epoch 2007/2500\n",
      "11/11 - 0s - loss: 0.3952 - val_loss: 0.4183 - 28ms/epoch - 3ms/step\n",
      "Epoch 2008/2500\n",
      "11/11 - 0s - loss: 0.3927 - val_loss: 0.4154 - 28ms/epoch - 3ms/step\n",
      "Epoch 2009/2500\n",
      "11/11 - 0s - loss: 0.3933 - val_loss: 0.4108 - 28ms/epoch - 3ms/step\n",
      "Epoch 2010/2500\n",
      "11/11 - 0s - loss: 0.3917 - val_loss: 0.4075 - 29ms/epoch - 3ms/step\n",
      "Epoch 2011/2500\n",
      "11/11 - 0s - loss: 0.3952 - val_loss: 0.4117 - 29ms/epoch - 3ms/step\n",
      "Epoch 2012/2500\n",
      "11/11 - 0s - loss: 0.3937 - val_loss: 0.4087 - 29ms/epoch - 3ms/step\n",
      "Epoch 2013/2500\n",
      "11/11 - 0s - loss: 0.3850 - val_loss: 0.4074 - 28ms/epoch - 3ms/step\n",
      "Epoch 2014/2500\n",
      "11/11 - 0s - loss: 0.3789 - val_loss: 0.4086 - 28ms/epoch - 3ms/step\n",
      "Epoch 2015/2500\n",
      "11/11 - 0s - loss: 0.3855 - val_loss: 0.4164 - 30ms/epoch - 3ms/step\n",
      "Epoch 2016/2500\n",
      "11/11 - 0s - loss: 0.3923 - val_loss: 0.4122 - 29ms/epoch - 3ms/step\n",
      "Epoch 2017/2500\n",
      "11/11 - 0s - loss: 0.3946 - val_loss: 0.4154 - 28ms/epoch - 3ms/step\n",
      "Epoch 2018/2500\n",
      "11/11 - 0s - loss: 0.3959 - val_loss: 0.4044 - 28ms/epoch - 3ms/step\n",
      "Epoch 2019/2500\n",
      "11/11 - 0s - loss: 0.4020 - val_loss: 0.4150 - 29ms/epoch - 3ms/step\n",
      "Epoch 2020/2500\n",
      "11/11 - 0s - loss: 0.3984 - val_loss: 0.4038 - 28ms/epoch - 3ms/step\n",
      "Epoch 2021/2500\n",
      "11/11 - 0s - loss: 0.3950 - val_loss: 0.4049 - 27ms/epoch - 2ms/step\n",
      "Epoch 2022/2500\n",
      "11/11 - 0s - loss: 0.3916 - val_loss: 0.4060 - 28ms/epoch - 3ms/step\n",
      "Epoch 2023/2500\n",
      "11/11 - 0s - loss: 0.3936 - val_loss: 0.4128 - 28ms/epoch - 3ms/step\n",
      "Epoch 2024/2500\n",
      "11/11 - 0s - loss: 0.4012 - val_loss: 0.4156 - 28ms/epoch - 3ms/step\n",
      "Epoch 2025/2500\n",
      "11/11 - 0s - loss: 0.3825 - val_loss: 0.4126 - 28ms/epoch - 3ms/step\n",
      "Epoch 2026/2500\n",
      "11/11 - 0s - loss: 0.3858 - val_loss: 0.4128 - 28ms/epoch - 3ms/step\n",
      "Epoch 2027/2500\n",
      "11/11 - 0s - loss: 0.3972 - val_loss: 0.4137 - 27ms/epoch - 2ms/step\n",
      "Epoch 2028/2500\n",
      "11/11 - 0s - loss: 0.4089 - val_loss: 0.4168 - 28ms/epoch - 3ms/step\n",
      "Epoch 2029/2500\n",
      "11/11 - 0s - loss: 0.3977 - val_loss: 0.4152 - 28ms/epoch - 3ms/step\n",
      "Epoch 2030/2500\n",
      "11/11 - 0s - loss: 0.3971 - val_loss: 0.4020 - 28ms/epoch - 3ms/step\n",
      "Epoch 2031/2500\n",
      "11/11 - 0s - loss: 0.3904 - val_loss: 0.4017 - 28ms/epoch - 3ms/step\n",
      "Epoch 2032/2500\n",
      "11/11 - 0s - loss: 0.3978 - val_loss: 0.4075 - 29ms/epoch - 3ms/step\n",
      "Epoch 2033/2500\n",
      "11/11 - 0s - loss: 0.3935 - val_loss: 0.4207 - 36ms/epoch - 3ms/step\n",
      "Epoch 2034/2500\n",
      "11/11 - 0s - loss: 0.3888 - val_loss: 0.4194 - 28ms/epoch - 3ms/step\n",
      "Epoch 2035/2500\n",
      "11/11 - 0s - loss: 0.3917 - val_loss: 0.4162 - 29ms/epoch - 3ms/step\n",
      "Epoch 2036/2500\n",
      "11/11 - 0s - loss: 0.3921 - val_loss: 0.4174 - 31ms/epoch - 3ms/step\n",
      "Epoch 2037/2500\n",
      "11/11 - 0s - loss: 0.3924 - val_loss: 0.4161 - 29ms/epoch - 3ms/step\n",
      "Epoch 2038/2500\n",
      "11/11 - 0s - loss: 0.4102 - val_loss: 0.4166 - 28ms/epoch - 3ms/step\n",
      "Epoch 2039/2500\n",
      "11/11 - 0s - loss: 0.3882 - val_loss: 0.4149 - 29ms/epoch - 3ms/step\n",
      "Epoch 2040/2500\n",
      "11/11 - 0s - loss: 0.3921 - val_loss: 0.4276 - 28ms/epoch - 3ms/step\n",
      "Epoch 2041/2500\n",
      "11/11 - 0s - loss: 0.4021 - val_loss: 0.4203 - 28ms/epoch - 3ms/step\n",
      "Epoch 2042/2500\n",
      "11/11 - 0s - loss: 0.4038 - val_loss: 0.4163 - 28ms/epoch - 3ms/step\n",
      "Epoch 2043/2500\n",
      "11/11 - 0s - loss: 0.3956 - val_loss: 0.4136 - 29ms/epoch - 3ms/step\n",
      "Epoch 2044/2500\n",
      "11/11 - 0s - loss: 0.3746 - val_loss: 0.4115 - 28ms/epoch - 3ms/step\n",
      "Epoch 2045/2500\n",
      "11/11 - 0s - loss: 0.3873 - val_loss: 0.4118 - 28ms/epoch - 3ms/step\n",
      "Epoch 2046/2500\n",
      "11/11 - 0s - loss: 0.3962 - val_loss: 0.4110 - 28ms/epoch - 3ms/step\n",
      "Epoch 2047/2500\n",
      "11/11 - 0s - loss: 0.3902 - val_loss: 0.4056 - 28ms/epoch - 3ms/step\n",
      "Epoch 2048/2500\n",
      "11/11 - 0s - loss: 0.3941 - val_loss: 0.4044 - 28ms/epoch - 3ms/step\n",
      "Epoch 2049/2500\n",
      "11/11 - 0s - loss: 0.3921 - val_loss: 0.4056 - 28ms/epoch - 3ms/step\n",
      "Epoch 2050/2500\n",
      "11/11 - 0s - loss: 0.3980 - val_loss: 0.4106 - 33ms/epoch - 3ms/step\n",
      "Epoch 2051/2500\n",
      "11/11 - 0s - loss: 0.3912 - val_loss: 0.4109 - 30ms/epoch - 3ms/step\n",
      "Epoch 2052/2500\n",
      "11/11 - 0s - loss: 0.3870 - val_loss: 0.4056 - 29ms/epoch - 3ms/step\n",
      "Epoch 2053/2500\n",
      "11/11 - 0s - loss: 0.3881 - val_loss: 0.4005 - 28ms/epoch - 3ms/step\n",
      "Epoch 2054/2500\n",
      "11/11 - 0s - loss: 0.4037 - val_loss: 0.3964 - 28ms/epoch - 3ms/step\n",
      "Epoch 2055/2500\n",
      "11/11 - 0s - loss: 0.3856 - val_loss: 0.3961 - 29ms/epoch - 3ms/step\n",
      "Epoch 2056/2500\n",
      "11/11 - 0s - loss: 0.3881 - val_loss: 0.4015 - 30ms/epoch - 3ms/step\n",
      "Epoch 2057/2500\n",
      "11/11 - 0s - loss: 0.3920 - val_loss: 0.4050 - 28ms/epoch - 3ms/step\n",
      "Epoch 2058/2500\n",
      "11/11 - 0s - loss: 0.3993 - val_loss: 0.4047 - 28ms/epoch - 3ms/step\n",
      "Epoch 2059/2500\n",
      "11/11 - 0s - loss: 0.4009 - val_loss: 0.4191 - 28ms/epoch - 3ms/step\n",
      "Epoch 2060/2500\n",
      "11/11 - 0s - loss: 0.3926 - val_loss: 0.4113 - 29ms/epoch - 3ms/step\n",
      "Epoch 2061/2500\n",
      "11/11 - 0s - loss: 0.3976 - val_loss: 0.4071 - 29ms/epoch - 3ms/step\n",
      "Epoch 2062/2500\n",
      "11/11 - 0s - loss: 0.3902 - val_loss: 0.4055 - 29ms/epoch - 3ms/step\n",
      "Epoch 2063/2500\n",
      "11/11 - 0s - loss: 0.4169 - val_loss: 0.4253 - 28ms/epoch - 3ms/step\n",
      "Epoch 2064/2500\n",
      "11/11 - 0s - loss: 0.3916 - val_loss: 0.4177 - 28ms/epoch - 3ms/step\n",
      "Epoch 2065/2500\n",
      "11/11 - 0s - loss: 0.3817 - val_loss: 0.4113 - 35ms/epoch - 3ms/step\n",
      "Epoch 2066/2500\n",
      "11/11 - 0s - loss: 0.4094 - val_loss: 0.4056 - 37ms/epoch - 3ms/step\n",
      "Epoch 2067/2500\n",
      "11/11 - 0s - loss: 0.3949 - val_loss: 0.4031 - 31ms/epoch - 3ms/step\n",
      "Epoch 2068/2500\n",
      "11/11 - 0s - loss: 0.4075 - val_loss: 0.4081 - 29ms/epoch - 3ms/step\n",
      "Epoch 2069/2500\n",
      "11/11 - 0s - loss: 0.3783 - val_loss: 0.4034 - 28ms/epoch - 3ms/step\n",
      "Epoch 2070/2500\n",
      "11/11 - 0s - loss: 0.3895 - val_loss: 0.4028 - 28ms/epoch - 3ms/step\n",
      "Epoch 2071/2500\n",
      "11/11 - 0s - loss: 0.3873 - val_loss: 0.3971 - 28ms/epoch - 3ms/step\n",
      "Epoch 2072/2500\n",
      "11/11 - 0s - loss: 0.3881 - val_loss: 0.4150 - 28ms/epoch - 3ms/step\n",
      "Epoch 2073/2500\n",
      "11/11 - 0s - loss: 0.3902 - val_loss: 0.4014 - 29ms/epoch - 3ms/step\n",
      "Epoch 2074/2500\n",
      "11/11 - 0s - loss: 0.3906 - val_loss: 0.4058 - 30ms/epoch - 3ms/step\n",
      "Epoch 2075/2500\n",
      "11/11 - 0s - loss: 0.3979 - val_loss: 0.4121 - 30ms/epoch - 3ms/step\n",
      "Epoch 2076/2500\n",
      "11/11 - 0s - loss: 0.3955 - val_loss: 0.4101 - 29ms/epoch - 3ms/step\n",
      "Epoch 2077/2500\n",
      "11/11 - 0s - loss: 0.4020 - val_loss: 0.4073 - 28ms/epoch - 3ms/step\n",
      "Epoch 2078/2500\n",
      "11/11 - 0s - loss: 0.3927 - val_loss: 0.4156 - 28ms/epoch - 3ms/step\n",
      "Epoch 2079/2500\n",
      "11/11 - 0s - loss: 0.4012 - val_loss: 0.4117 - 28ms/epoch - 3ms/step\n",
      "Epoch 2080/2500\n",
      "11/11 - 0s - loss: 0.3914 - val_loss: 0.4112 - 28ms/epoch - 3ms/step\n",
      "Epoch 2081/2500\n",
      "11/11 - 0s - loss: 0.4037 - val_loss: 0.4101 - 28ms/epoch - 3ms/step\n",
      "Epoch 2082/2500\n",
      "11/11 - 0s - loss: 0.4011 - val_loss: 0.4065 - 39ms/epoch - 4ms/step\n",
      "Epoch 2083/2500\n",
      "11/11 - 0s - loss: 0.3760 - val_loss: 0.4073 - 29ms/epoch - 3ms/step\n",
      "Epoch 2084/2500\n",
      "11/11 - 0s - loss: 0.3911 - val_loss: 0.4059 - 28ms/epoch - 3ms/step\n",
      "Epoch 2085/2500\n",
      "11/11 - 0s - loss: 0.3846 - val_loss: 0.4094 - 29ms/epoch - 3ms/step\n",
      "Epoch 2086/2500\n",
      "11/11 - 0s - loss: 0.3860 - val_loss: 0.4044 - 29ms/epoch - 3ms/step\n",
      "Epoch 2087/2500\n",
      "11/11 - 0s - loss: 0.4081 - val_loss: 0.4022 - 28ms/epoch - 3ms/step\n",
      "Epoch 2088/2500\n",
      "11/11 - 0s - loss: 0.3869 - val_loss: 0.4039 - 28ms/epoch - 3ms/step\n",
      "Epoch 2089/2500\n",
      "11/11 - 0s - loss: 0.3830 - val_loss: 0.4019 - 29ms/epoch - 3ms/step\n",
      "Epoch 2090/2500\n",
      "11/11 - 0s - loss: 0.3928 - val_loss: 0.4033 - 29ms/epoch - 3ms/step\n",
      "Epoch 2091/2500\n",
      "11/11 - 0s - loss: 0.3984 - val_loss: 0.3974 - 28ms/epoch - 3ms/step\n",
      "Epoch 2092/2500\n",
      "11/11 - 0s - loss: 0.4029 - val_loss: 0.3970 - 28ms/epoch - 3ms/step\n",
      "Epoch 2093/2500\n",
      "11/11 - 0s - loss: 0.3917 - val_loss: 0.4025 - 33ms/epoch - 3ms/step\n",
      "Epoch 2094/2500\n",
      "11/11 - 0s - loss: 0.3940 - val_loss: 0.3994 - 30ms/epoch - 3ms/step\n",
      "Epoch 2095/2500\n",
      "11/11 - 0s - loss: 0.3966 - val_loss: 0.4036 - 28ms/epoch - 3ms/step\n",
      "Epoch 2096/2500\n",
      "11/11 - 0s - loss: 0.3845 - val_loss: 0.3978 - 29ms/epoch - 3ms/step\n",
      "Epoch 2097/2500\n",
      "11/11 - 0s - loss: 0.3831 - val_loss: 0.3956 - 35ms/epoch - 3ms/step\n",
      "Epoch 2098/2500\n",
      "11/11 - 0s - loss: 0.3987 - val_loss: 0.3979 - 30ms/epoch - 3ms/step\n",
      "Epoch 2099/2500\n",
      "11/11 - 0s - loss: 0.3868 - val_loss: 0.3976 - 29ms/epoch - 3ms/step\n",
      "Epoch 2100/2500\n",
      "11/11 - 0s - loss: 0.4022 - val_loss: 0.3964 - 29ms/epoch - 3ms/step\n",
      "Epoch 2101/2500\n",
      "11/11 - 0s - loss: 0.3799 - val_loss: 0.3986 - 29ms/epoch - 3ms/step\n",
      "Epoch 2102/2500\n",
      "11/11 - 0s - loss: 0.3896 - val_loss: 0.3949 - 28ms/epoch - 3ms/step\n",
      "Epoch 2103/2500\n",
      "11/11 - 0s - loss: 0.3940 - val_loss: 0.3939 - 28ms/epoch - 3ms/step\n",
      "Epoch 2104/2500\n",
      "11/11 - 0s - loss: 0.3861 - val_loss: 0.3965 - 29ms/epoch - 3ms/step\n",
      "Epoch 2105/2500\n",
      "11/11 - 0s - loss: 0.4279 - val_loss: 0.3965 - 28ms/epoch - 3ms/step\n",
      "Epoch 2106/2500\n",
      "11/11 - 0s - loss: 0.3875 - val_loss: 0.4116 - 28ms/epoch - 3ms/step\n",
      "Epoch 2107/2500\n",
      "11/11 - 0s - loss: 0.4088 - val_loss: 0.4031 - 29ms/epoch - 3ms/step\n",
      "Epoch 2108/2500\n",
      "11/11 - 0s - loss: 0.3965 - val_loss: 0.4062 - 28ms/epoch - 3ms/step\n",
      "Epoch 2109/2500\n",
      "11/11 - 0s - loss: 0.3934 - val_loss: 0.4100 - 28ms/epoch - 3ms/step\n",
      "Epoch 2110/2500\n",
      "11/11 - 0s - loss: 0.3880 - val_loss: 0.4090 - 27ms/epoch - 2ms/step\n",
      "Epoch 2111/2500\n",
      "11/11 - 0s - loss: 0.4018 - val_loss: 0.4227 - 29ms/epoch - 3ms/step\n",
      "Epoch 2112/2500\n",
      "11/11 - 0s - loss: 0.3941 - val_loss: 0.4138 - 30ms/epoch - 3ms/step\n",
      "Epoch 2113/2500\n",
      "11/11 - 0s - loss: 0.3976 - val_loss: 0.4074 - 29ms/epoch - 3ms/step\n",
      "Epoch 2114/2500\n",
      "11/11 - 0s - loss: 0.3927 - val_loss: 0.4178 - 28ms/epoch - 3ms/step\n",
      "Epoch 2115/2500\n",
      "11/11 - 0s - loss: 0.3948 - val_loss: 0.4085 - 37ms/epoch - 3ms/step\n",
      "Epoch 2116/2500\n",
      "11/11 - 0s - loss: 0.3888 - val_loss: 0.4119 - 28ms/epoch - 3ms/step\n",
      "Epoch 2117/2500\n",
      "11/11 - 0s - loss: 0.3910 - val_loss: 0.4110 - 28ms/epoch - 3ms/step\n",
      "Epoch 2118/2500\n",
      "11/11 - 0s - loss: 0.3760 - val_loss: 0.4091 - 29ms/epoch - 3ms/step\n",
      "Epoch 2119/2500\n",
      "11/11 - 0s - loss: 0.3841 - val_loss: 0.4121 - 28ms/epoch - 3ms/step\n",
      "Epoch 2120/2500\n",
      "11/11 - 0s - loss: 0.3915 - val_loss: 0.4176 - 27ms/epoch - 2ms/step\n",
      "Epoch 2121/2500\n",
      "11/11 - 0s - loss: 0.3994 - val_loss: 0.4129 - 28ms/epoch - 3ms/step\n",
      "Epoch 2122/2500\n",
      "11/11 - 0s - loss: 0.3870 - val_loss: 0.4119 - 28ms/epoch - 3ms/step\n",
      "Epoch 2123/2500\n",
      "11/11 - 0s - loss: 0.4041 - val_loss: 0.4104 - 28ms/epoch - 3ms/step\n",
      "Epoch 2124/2500\n",
      "11/11 - 0s - loss: 0.3922 - val_loss: 0.4103 - 29ms/epoch - 3ms/step\n",
      "Epoch 2125/2500\n",
      "11/11 - 0s - loss: 0.3964 - val_loss: 0.4014 - 29ms/epoch - 3ms/step\n",
      "Epoch 2126/2500\n",
      "11/11 - 0s - loss: 0.3952 - val_loss: 0.4037 - 29ms/epoch - 3ms/step\n",
      "Epoch 2127/2500\n",
      "11/11 - 0s - loss: 0.3954 - val_loss: 0.4038 - 28ms/epoch - 3ms/step\n",
      "Epoch 2128/2500\n",
      "11/11 - 0s - loss: 0.3833 - val_loss: 0.4058 - 29ms/epoch - 3ms/step\n",
      "Epoch 2129/2500\n",
      "11/11 - 0s - loss: 0.3928 - val_loss: 0.4095 - 28ms/epoch - 3ms/step\n",
      "Epoch 2130/2500\n",
      "11/11 - 0s - loss: 0.3915 - val_loss: 0.4060 - 28ms/epoch - 3ms/step\n",
      "Epoch 2131/2500\n",
      "11/11 - 0s - loss: 0.3876 - val_loss: 0.4044 - 28ms/epoch - 3ms/step\n",
      "Epoch 2132/2500\n",
      "11/11 - 0s - loss: 0.3850 - val_loss: 0.4089 - 40ms/epoch - 4ms/step\n",
      "Epoch 2133/2500\n",
      "11/11 - 0s - loss: 0.3954 - val_loss: 0.4096 - 28ms/epoch - 3ms/step\n",
      "Epoch 2134/2500\n",
      "11/11 - 0s - loss: 0.3810 - val_loss: 0.4107 - 29ms/epoch - 3ms/step\n",
      "Epoch 2135/2500\n",
      "11/11 - 0s - loss: 0.3838 - val_loss: 0.4102 - 28ms/epoch - 3ms/step\n",
      "Epoch 2136/2500\n",
      "11/11 - 0s - loss: 0.4017 - val_loss: 0.4223 - 28ms/epoch - 3ms/step\n",
      "Epoch 2137/2500\n",
      "11/11 - 0s - loss: 0.3952 - val_loss: 0.4169 - 28ms/epoch - 3ms/step\n",
      "Epoch 2138/2500\n",
      "11/11 - 0s - loss: 0.4018 - val_loss: 0.4226 - 28ms/epoch - 3ms/step\n",
      "Epoch 2139/2500\n",
      "11/11 - 0s - loss: 0.4081 - val_loss: 0.4072 - 29ms/epoch - 3ms/step\n",
      "Epoch 2140/2500\n",
      "11/11 - 0s - loss: 0.3931 - val_loss: 0.4054 - 28ms/epoch - 3ms/step\n",
      "Epoch 2141/2500\n",
      "11/11 - 0s - loss: 0.3919 - val_loss: 0.4068 - 28ms/epoch - 3ms/step\n",
      "Epoch 2142/2500\n",
      "11/11 - 0s - loss: 0.3760 - val_loss: 0.4087 - 29ms/epoch - 3ms/step\n",
      "Epoch 2143/2500\n",
      "11/11 - 0s - loss: 0.4043 - val_loss: 0.4115 - 28ms/epoch - 3ms/step\n",
      "Epoch 2144/2500\n",
      "11/11 - 0s - loss: 0.3994 - val_loss: 0.4131 - 28ms/epoch - 3ms/step\n",
      "Epoch 2145/2500\n",
      "11/11 - 0s - loss: 0.4052 - val_loss: 0.4157 - 29ms/epoch - 3ms/step\n",
      "Epoch 2146/2500\n",
      "11/11 - 0s - loss: 0.3989 - val_loss: 0.4154 - 31ms/epoch - 3ms/step\n",
      "Epoch 2147/2500\n",
      "11/11 - 0s - loss: 0.3910 - val_loss: 0.4131 - 29ms/epoch - 3ms/step\n",
      "Epoch 2148/2500\n",
      "11/11 - 0s - loss: 0.4093 - val_loss: 0.4094 - 28ms/epoch - 3ms/step\n",
      "Epoch 2149/2500\n",
      "11/11 - 0s - loss: 0.3887 - val_loss: 0.4077 - 29ms/epoch - 3ms/step\n",
      "Epoch 2150/2500\n",
      "11/11 - 0s - loss: 0.3764 - val_loss: 0.4109 - 28ms/epoch - 3ms/step\n",
      "Epoch 2151/2500\n",
      "11/11 - 0s - loss: 0.4109 - val_loss: 0.4143 - 34ms/epoch - 3ms/step\n",
      "Epoch 2152/2500\n",
      "11/11 - 0s - loss: 0.3774 - val_loss: 0.4349 - 36ms/epoch - 3ms/step\n",
      "Epoch 2153/2500\n",
      "11/11 - 0s - loss: 0.3870 - val_loss: 0.4129 - 31ms/epoch - 3ms/step\n",
      "Epoch 2154/2500\n",
      "11/11 - 0s - loss: 0.3885 - val_loss: 0.4082 - 28ms/epoch - 3ms/step\n",
      "Epoch 2155/2500\n",
      "11/11 - 0s - loss: 0.4089 - val_loss: 0.4142 - 31ms/epoch - 3ms/step\n",
      "Epoch 2156/2500\n",
      "11/11 - 0s - loss: 0.3825 - val_loss: 0.4150 - 28ms/epoch - 3ms/step\n",
      "Epoch 2157/2500\n",
      "11/11 - 0s - loss: 0.3774 - val_loss: 0.4151 - 28ms/epoch - 3ms/step\n",
      "Epoch 2158/2500\n",
      "11/11 - 0s - loss: 0.3790 - val_loss: 0.4069 - 28ms/epoch - 3ms/step\n",
      "Epoch 2159/2500\n",
      "11/11 - 0s - loss: 0.3875 - val_loss: 0.4040 - 28ms/epoch - 3ms/step\n",
      "Epoch 2160/2500\n",
      "11/11 - 0s - loss: 0.3903 - val_loss: 0.4120 - 28ms/epoch - 3ms/step\n",
      "Epoch 2161/2500\n",
      "11/11 - 0s - loss: 0.4028 - val_loss: 0.3977 - 33ms/epoch - 3ms/step\n",
      "Epoch 2162/2500\n",
      "11/11 - 0s - loss: 0.3799 - val_loss: 0.4070 - 32ms/epoch - 3ms/step\n",
      "Epoch 2163/2500\n",
      "11/11 - 0s - loss: 0.3798 - val_loss: 0.4081 - 29ms/epoch - 3ms/step\n",
      "Epoch 2164/2500\n",
      "11/11 - 0s - loss: 0.3845 - val_loss: 0.4118 - 29ms/epoch - 3ms/step\n",
      "Epoch 2165/2500\n",
      "11/11 - 0s - loss: 0.3779 - val_loss: 0.4130 - 29ms/epoch - 3ms/step\n",
      "Epoch 2166/2500\n",
      "11/11 - 0s - loss: 0.4007 - val_loss: 0.4108 - 29ms/epoch - 3ms/step\n",
      "Epoch 2167/2500\n",
      "11/11 - 0s - loss: 0.3990 - val_loss: 0.4069 - 28ms/epoch - 3ms/step\n",
      "Epoch 2168/2500\n",
      "11/11 - 0s - loss: 0.3848 - val_loss: 0.4030 - 28ms/epoch - 3ms/step\n",
      "Epoch 2169/2500\n",
      "11/11 - 0s - loss: 0.3930 - val_loss: 0.4044 - 28ms/epoch - 3ms/step\n",
      "Epoch 2170/2500\n",
      "11/11 - 0s - loss: 0.4075 - val_loss: 0.4007 - 30ms/epoch - 3ms/step\n",
      "Epoch 2171/2500\n",
      "11/11 - 0s - loss: 0.4009 - val_loss: 0.4017 - 29ms/epoch - 3ms/step\n",
      "Epoch 2172/2500\n",
      "11/11 - 0s - loss: 0.3852 - val_loss: 0.4022 - 29ms/epoch - 3ms/step\n",
      "Epoch 2173/2500\n",
      "11/11 - 0s - loss: 0.3764 - val_loss: 0.4083 - 28ms/epoch - 3ms/step\n",
      "Epoch 2174/2500\n",
      "11/11 - 0s - loss: 0.3911 - val_loss: 0.4094 - 29ms/epoch - 3ms/step\n",
      "Epoch 2175/2500\n",
      "11/11 - 0s - loss: 0.3990 - val_loss: 0.4150 - 28ms/epoch - 3ms/step\n",
      "Epoch 2176/2500\n",
      "11/11 - 0s - loss: 0.3888 - val_loss: 0.4130 - 29ms/epoch - 3ms/step\n",
      "Epoch 2177/2500\n",
      "11/11 - 0s - loss: 0.3790 - val_loss: 0.4102 - 29ms/epoch - 3ms/step\n",
      "Epoch 2178/2500\n",
      "11/11 - 0s - loss: 0.3942 - val_loss: 0.4096 - 39ms/epoch - 4ms/step\n",
      "Epoch 2179/2500\n",
      "11/11 - 0s - loss: 0.3910 - val_loss: 0.4106 - 30ms/epoch - 3ms/step\n",
      "Epoch 2180/2500\n",
      "11/11 - 0s - loss: 0.4064 - val_loss: 0.4112 - 29ms/epoch - 3ms/step\n",
      "Epoch 2181/2500\n",
      "11/11 - 0s - loss: 0.3897 - val_loss: 0.4076 - 28ms/epoch - 3ms/step\n",
      "Epoch 2182/2500\n",
      "11/11 - 0s - loss: 0.3831 - val_loss: 0.4016 - 29ms/epoch - 3ms/step\n",
      "Epoch 2183/2500\n",
      "11/11 - 0s - loss: 0.4015 - val_loss: 0.4015 - 28ms/epoch - 3ms/step\n",
      "Epoch 2184/2500\n",
      "11/11 - 0s - loss: 0.3890 - val_loss: 0.4034 - 29ms/epoch - 3ms/step\n",
      "Epoch 2185/2500\n",
      "11/11 - 0s - loss: 0.3753 - val_loss: 0.4075 - 29ms/epoch - 3ms/step\n",
      "Epoch 2186/2500\n",
      "11/11 - 0s - loss: 0.3756 - val_loss: 0.4109 - 28ms/epoch - 3ms/step\n",
      "Epoch 2187/2500\n",
      "11/11 - 0s - loss: 0.3933 - val_loss: 0.4092 - 28ms/epoch - 3ms/step\n",
      "Epoch 2188/2500\n",
      "11/11 - 0s - loss: 0.3847 - val_loss: 0.4068 - 28ms/epoch - 3ms/step\n",
      "Epoch 2189/2500\n",
      "11/11 - 0s - loss: 0.3801 - val_loss: 0.4092 - 31ms/epoch - 3ms/step\n",
      "Epoch 2190/2500\n",
      "11/11 - 0s - loss: 0.3972 - val_loss: 0.4126 - 28ms/epoch - 3ms/step\n",
      "Epoch 2191/2500\n",
      "11/11 - 0s - loss: 0.4009 - val_loss: 0.4110 - 28ms/epoch - 3ms/step\n",
      "Epoch 2192/2500\n",
      "11/11 - 0s - loss: 0.3932 - val_loss: 0.4125 - 28ms/epoch - 3ms/step\n",
      "Epoch 2193/2500\n",
      "11/11 - 0s - loss: 0.4005 - val_loss: 0.4169 - 28ms/epoch - 3ms/step\n",
      "Epoch 2194/2500\n",
      "11/11 - 0s - loss: 0.3901 - val_loss: 0.4198 - 28ms/epoch - 3ms/step\n",
      "Epoch 2195/2500\n",
      "11/11 - 0s - loss: 0.3697 - val_loss: 0.4177 - 29ms/epoch - 3ms/step\n",
      "Epoch 2196/2500\n",
      "11/11 - 0s - loss: 0.4054 - val_loss: 0.4173 - 28ms/epoch - 3ms/step\n",
      "Epoch 2197/2500\n",
      "11/11 - 0s - loss: 0.3818 - val_loss: 0.4137 - 38ms/epoch - 3ms/step\n",
      "Epoch 2198/2500\n",
      "11/11 - 0s - loss: 0.3958 - val_loss: 0.4128 - 29ms/epoch - 3ms/step\n",
      "Epoch 2199/2500\n",
      "11/11 - 0s - loss: 0.3831 - val_loss: 0.4130 - 28ms/epoch - 3ms/step\n",
      "Epoch 2200/2500\n",
      "11/11 - 0s - loss: 0.3866 - val_loss: 0.4039 - 28ms/epoch - 3ms/step\n",
      "Epoch 2201/2500\n",
      "11/11 - 0s - loss: 0.3852 - val_loss: 0.4079 - 28ms/epoch - 3ms/step\n",
      "Epoch 2202/2500\n",
      "11/11 - 0s - loss: 0.4070 - val_loss: 0.4048 - 28ms/epoch - 3ms/step\n",
      "Epoch 2203/2500\n",
      "11/11 - 0s - loss: 0.3912 - val_loss: 0.4052 - 28ms/epoch - 3ms/step\n",
      "Epoch 2204/2500\n",
      "11/11 - 0s - loss: 0.3986 - val_loss: 0.4146 - 29ms/epoch - 3ms/step\n",
      "Epoch 2205/2500\n",
      "11/11 - 0s - loss: 0.3957 - val_loss: 0.4104 - 29ms/epoch - 3ms/step\n",
      "Epoch 2206/2500\n",
      "11/11 - 0s - loss: 0.3956 - val_loss: 0.4083 - 29ms/epoch - 3ms/step\n",
      "Epoch 2207/2500\n",
      "11/11 - 0s - loss: 0.3819 - val_loss: 0.4080 - 30ms/epoch - 3ms/step\n",
      "Epoch 2208/2500\n",
      "11/11 - 0s - loss: 0.3874 - val_loss: 0.4039 - 30ms/epoch - 3ms/step\n",
      "Epoch 2209/2500\n",
      "11/11 - 0s - loss: 0.3803 - val_loss: 0.4003 - 34ms/epoch - 3ms/step\n",
      "Epoch 2210/2500\n",
      "11/11 - 0s - loss: 0.3855 - val_loss: 0.4012 - 28ms/epoch - 3ms/step\n",
      "Epoch 2211/2500\n",
      "11/11 - 0s - loss: 0.4032 - val_loss: 0.4059 - 29ms/epoch - 3ms/step\n",
      "Epoch 2212/2500\n",
      "11/11 - 0s - loss: 0.3931 - val_loss: 0.4014 - 28ms/epoch - 3ms/step\n",
      "Epoch 2213/2500\n",
      "11/11 - 0s - loss: 0.3935 - val_loss: 0.4057 - 28ms/epoch - 3ms/step\n",
      "Epoch 2214/2500\n",
      "11/11 - 0s - loss: 0.3940 - val_loss: 0.4078 - 28ms/epoch - 3ms/step\n",
      "Epoch 2215/2500\n",
      "11/11 - 0s - loss: 0.3993 - val_loss: 0.4091 - 28ms/epoch - 3ms/step\n",
      "Epoch 2216/2500\n",
      "11/11 - 0s - loss: 0.3930 - val_loss: 0.4114 - 36ms/epoch - 3ms/step\n",
      "Epoch 2217/2500\n",
      "11/11 - 0s - loss: 0.3891 - val_loss: 0.4023 - 28ms/epoch - 3ms/step\n",
      "Epoch 2218/2500\n",
      "11/11 - 0s - loss: 0.4015 - val_loss: 0.4046 - 29ms/epoch - 3ms/step\n",
      "Epoch 2219/2500\n",
      "11/11 - 0s - loss: 0.4059 - val_loss: 0.4074 - 28ms/epoch - 3ms/step\n",
      "Epoch 2220/2500\n",
      "11/11 - 0s - loss: 0.3938 - val_loss: 0.4064 - 28ms/epoch - 3ms/step\n",
      "Epoch 2221/2500\n",
      "11/11 - 0s - loss: 0.3947 - val_loss: 0.4060 - 28ms/epoch - 3ms/step\n",
      "Epoch 2222/2500\n",
      "11/11 - 0s - loss: 0.3882 - val_loss: 0.4009 - 29ms/epoch - 3ms/step\n",
      "Epoch 2223/2500\n",
      "11/11 - 0s - loss: 0.3999 - val_loss: 0.4155 - 28ms/epoch - 3ms/step\n",
      "Epoch 2224/2500\n",
      "11/11 - 0s - loss: 0.3885 - val_loss: 0.4144 - 28ms/epoch - 3ms/step\n",
      "Epoch 2225/2500\n",
      "11/11 - 0s - loss: 0.3888 - val_loss: 0.4139 - 29ms/epoch - 3ms/step\n",
      "Epoch 2226/2500\n",
      "11/11 - 0s - loss: 0.3825 - val_loss: 0.4114 - 30ms/epoch - 3ms/step\n",
      "Epoch 2227/2500\n",
      "11/11 - 0s - loss: 0.4014 - val_loss: 0.4184 - 28ms/epoch - 3ms/step\n",
      "Epoch 2228/2500\n",
      "11/11 - 0s - loss: 0.3981 - val_loss: 0.4079 - 28ms/epoch - 3ms/step\n",
      "Epoch 2229/2500\n",
      "11/11 - 0s - loss: 0.3942 - val_loss: 0.4125 - 28ms/epoch - 3ms/step\n",
      "Epoch 2230/2500\n",
      "11/11 - 0s - loss: 0.3762 - val_loss: 0.4026 - 28ms/epoch - 3ms/step\n",
      "Epoch 2231/2500\n",
      "11/11 - 0s - loss: 0.3888 - val_loss: 0.3993 - 27ms/epoch - 2ms/step\n",
      "Epoch 2232/2500\n",
      "11/11 - 0s - loss: 0.3918 - val_loss: 0.3985 - 39ms/epoch - 4ms/step\n",
      "Epoch 2233/2500\n",
      "11/11 - 0s - loss: 0.3868 - val_loss: 0.3978 - 29ms/epoch - 3ms/step\n",
      "Epoch 2234/2500\n",
      "11/11 - 0s - loss: 0.3793 - val_loss: 0.3987 - 28ms/epoch - 3ms/step\n",
      "Epoch 2235/2500\n",
      "11/11 - 0s - loss: 0.3914 - val_loss: 0.4045 - 28ms/epoch - 3ms/step\n",
      "Epoch 2236/2500\n",
      "11/11 - 0s - loss: 0.3829 - val_loss: 0.4043 - 28ms/epoch - 3ms/step\n",
      "Epoch 2237/2500\n",
      "11/11 - 0s - loss: 0.3882 - val_loss: 0.4070 - 28ms/epoch - 3ms/step\n",
      "Epoch 2238/2500\n",
      "11/11 - 0s - loss: 0.4017 - val_loss: 0.4010 - 28ms/epoch - 3ms/step\n",
      "Epoch 2239/2500\n",
      "11/11 - 0s - loss: 0.3979 - val_loss: 0.4027 - 29ms/epoch - 3ms/step\n",
      "Epoch 2240/2500\n",
      "11/11 - 0s - loss: 0.3974 - val_loss: 0.4002 - 28ms/epoch - 3ms/step\n",
      "Epoch 2241/2500\n",
      "11/11 - 0s - loss: 0.3854 - val_loss: 0.4065 - 28ms/epoch - 3ms/step\n",
      "Epoch 2242/2500\n",
      "11/11 - 0s - loss: 0.3998 - val_loss: 0.4212 - 28ms/epoch - 3ms/step\n",
      "Epoch 2243/2500\n",
      "11/11 - 0s - loss: 0.3951 - val_loss: 0.4198 - 29ms/epoch - 3ms/step\n",
      "Epoch 2244/2500\n",
      "11/11 - 0s - loss: 0.4032 - val_loss: 0.4109 - 31ms/epoch - 3ms/step\n",
      "Epoch 2245/2500\n",
      "11/11 - 0s - loss: 0.3978 - val_loss: 0.4127 - 28ms/epoch - 3ms/step\n",
      "Epoch 2246/2500\n",
      "11/11 - 0s - loss: 0.3797 - val_loss: 0.4108 - 28ms/epoch - 3ms/step\n",
      "Epoch 2247/2500\n",
      "11/11 - 0s - loss: 0.3969 - val_loss: 0.4132 - 35ms/epoch - 3ms/step\n",
      "Epoch 2248/2500\n",
      "11/11 - 0s - loss: 0.3698 - val_loss: 0.4113 - 30ms/epoch - 3ms/step\n",
      "Epoch 2249/2500\n",
      "11/11 - 0s - loss: 0.3854 - val_loss: 0.4142 - 28ms/epoch - 3ms/step\n",
      "Epoch 2250/2500\n",
      "11/11 - 0s - loss: 0.3799 - val_loss: 0.4136 - 28ms/epoch - 3ms/step\n",
      "Epoch 2251/2500\n",
      "11/11 - 0s - loss: 0.3920 - val_loss: 0.4086 - 28ms/epoch - 3ms/step\n",
      "Epoch 2252/2500\n",
      "11/11 - 0s - loss: 0.3849 - val_loss: 0.4211 - 28ms/epoch - 3ms/step\n",
      "Epoch 2253/2500\n",
      "11/11 - 0s - loss: 0.3921 - val_loss: 0.4150 - 28ms/epoch - 3ms/step\n",
      "Epoch 2254/2500\n",
      "11/11 - 0s - loss: 0.4247 - val_loss: 0.4118 - 28ms/epoch - 3ms/step\n",
      "Epoch 2255/2500\n",
      "11/11 - 0s - loss: 0.3951 - val_loss: 0.4185 - 28ms/epoch - 3ms/step\n",
      "Epoch 2256/2500\n",
      "11/11 - 0s - loss: 0.3998 - val_loss: 0.4161 - 28ms/epoch - 3ms/step\n",
      "Epoch 2257/2500\n",
      "11/11 - 0s - loss: 0.3856 - val_loss: 0.4072 - 28ms/epoch - 3ms/step\n",
      "Epoch 2258/2500\n",
      "11/11 - 0s - loss: 0.3935 - val_loss: 0.4061 - 29ms/epoch - 3ms/step\n",
      "Epoch 2259/2500\n",
      "11/11 - 0s - loss: 0.3903 - val_loss: 0.4051 - 27ms/epoch - 2ms/step\n",
      "Epoch 2260/2500\n",
      "11/11 - 0s - loss: 0.3847 - val_loss: 0.4046 - 29ms/epoch - 3ms/step\n",
      "Epoch 2261/2500\n",
      "11/11 - 0s - loss: 0.4038 - val_loss: 0.4197 - 28ms/epoch - 3ms/step\n",
      "Epoch 2262/2500\n",
      "11/11 - 0s - loss: 0.4068 - val_loss: 0.4030 - 37ms/epoch - 3ms/step\n",
      "Epoch 2263/2500\n",
      "11/11 - 0s - loss: 0.3924 - val_loss: 0.3986 - 33ms/epoch - 3ms/step\n",
      "Epoch 2264/2500\n",
      "11/11 - 0s - loss: 0.3972 - val_loss: 0.4003 - 33ms/epoch - 3ms/step\n",
      "Epoch 2265/2500\n",
      "11/11 - 0s - loss: 0.3998 - val_loss: 0.4148 - 28ms/epoch - 3ms/step\n",
      "Epoch 2266/2500\n",
      "11/11 - 0s - loss: 0.3827 - val_loss: 0.4108 - 28ms/epoch - 3ms/step\n",
      "Epoch 2267/2500\n",
      "11/11 - 0s - loss: 0.3831 - val_loss: 0.4089 - 27ms/epoch - 2ms/step\n",
      "Epoch 2268/2500\n",
      "11/11 - 0s - loss: 0.4055 - val_loss: 0.4035 - 28ms/epoch - 3ms/step\n",
      "Epoch 2269/2500\n",
      "11/11 - 0s - loss: 0.3945 - val_loss: 0.4082 - 28ms/epoch - 3ms/step\n",
      "Epoch 2270/2500\n",
      "11/11 - 0s - loss: 0.4068 - val_loss: 0.4072 - 28ms/epoch - 3ms/step\n",
      "Epoch 2271/2500\n",
      "11/11 - 0s - loss: 0.3827 - val_loss: 0.4131 - 28ms/epoch - 3ms/step\n",
      "Epoch 2272/2500\n",
      "11/11 - 0s - loss: 0.3865 - val_loss: 0.4148 - 28ms/epoch - 3ms/step\n",
      "Epoch 2273/2500\n",
      "11/11 - 0s - loss: 0.3912 - val_loss: 0.4138 - 28ms/epoch - 3ms/step\n",
      "Epoch 2274/2500\n",
      "11/11 - 0s - loss: 0.3759 - val_loss: 0.4130 - 28ms/epoch - 3ms/step\n",
      "Epoch 2275/2500\n",
      "11/11 - 0s - loss: 0.3870 - val_loss: 0.4053 - 29ms/epoch - 3ms/step\n",
      "Epoch 2276/2500\n",
      "11/11 - 0s - loss: 0.3926 - val_loss: 0.4035 - 29ms/epoch - 3ms/step\n",
      "Epoch 2277/2500\n",
      "11/11 - 0s - loss: 0.3954 - val_loss: 0.4028 - 29ms/epoch - 3ms/step\n",
      "Epoch 2278/2500\n",
      "11/11 - 0s - loss: 0.3806 - val_loss: 0.3997 - 28ms/epoch - 3ms/step\n",
      "Epoch 2279/2500\n",
      "11/11 - 0s - loss: 0.3913 - val_loss: 0.3934 - 31ms/epoch - 3ms/step\n",
      "Epoch 2280/2500\n",
      "11/11 - 0s - loss: 0.3903 - val_loss: 0.3971 - 33ms/epoch - 3ms/step\n",
      "Epoch 2281/2500\n",
      "11/11 - 0s - loss: 0.3908 - val_loss: 0.4000 - 29ms/epoch - 3ms/step\n",
      "Epoch 2282/2500\n",
      "11/11 - 0s - loss: 0.4023 - val_loss: 0.4035 - 29ms/epoch - 3ms/step\n",
      "Epoch 2283/2500\n",
      "11/11 - 0s - loss: 0.3816 - val_loss: 0.3990 - 28ms/epoch - 3ms/step\n",
      "Epoch 2284/2500\n",
      "11/11 - 0s - loss: 0.3889 - val_loss: 0.4000 - 27ms/epoch - 2ms/step\n",
      "Epoch 2285/2500\n",
      "11/11 - 0s - loss: 0.3921 - val_loss: 0.3995 - 28ms/epoch - 3ms/step\n",
      "Epoch 2286/2500\n",
      "11/11 - 0s - loss: 0.3877 - val_loss: 0.4038 - 28ms/epoch - 3ms/step\n",
      "Epoch 2287/2500\n",
      "11/11 - 0s - loss: 0.3826 - val_loss: 0.3987 - 28ms/epoch - 3ms/step\n",
      "Epoch 2288/2500\n",
      "11/11 - 0s - loss: 0.3840 - val_loss: 0.4010 - 28ms/epoch - 3ms/step\n",
      "Epoch 2289/2500\n",
      "11/11 - 0s - loss: 0.3850 - val_loss: 0.4018 - 28ms/epoch - 3ms/step\n",
      "Epoch 2290/2500\n",
      "11/11 - 0s - loss: 0.3944 - val_loss: 0.4039 - 28ms/epoch - 3ms/step\n",
      "Epoch 2291/2500\n",
      "11/11 - 0s - loss: 0.3980 - val_loss: 0.4058 - 27ms/epoch - 2ms/step\n",
      "Epoch 2292/2500\n",
      "11/11 - 0s - loss: 0.3812 - val_loss: 0.4068 - 28ms/epoch - 3ms/step\n",
      "Epoch 2293/2500\n",
      "11/11 - 0s - loss: 0.3826 - val_loss: 0.4116 - 28ms/epoch - 3ms/step\n",
      "Epoch 2294/2500\n",
      "11/11 - 0s - loss: 0.3766 - val_loss: 0.4098 - 37ms/epoch - 3ms/step\n",
      "Epoch 2295/2500\n",
      "11/11 - 0s - loss: 0.4044 - val_loss: 0.4117 - 28ms/epoch - 3ms/step\n",
      "Epoch 2296/2500\n",
      "11/11 - 0s - loss: 0.3737 - val_loss: 0.4069 - 32ms/epoch - 3ms/step\n",
      "Epoch 2297/2500\n",
      "11/11 - 0s - loss: 0.3949 - val_loss: 0.4020 - 29ms/epoch - 3ms/step\n",
      "Epoch 2298/2500\n",
      "11/11 - 0s - loss: 0.3961 - val_loss: 0.4126 - 30ms/epoch - 3ms/step\n",
      "Epoch 2299/2500\n",
      "11/11 - 0s - loss: 0.3925 - val_loss: 0.4086 - 30ms/epoch - 3ms/step\n",
      "Epoch 2300/2500\n",
      "11/11 - 0s - loss: 0.3907 - val_loss: 0.4082 - 28ms/epoch - 3ms/step\n",
      "Epoch 2301/2500\n",
      "11/11 - 0s - loss: 0.3928 - val_loss: 0.4063 - 29ms/epoch - 3ms/step\n",
      "Epoch 2302/2500\n",
      "11/11 - 0s - loss: 0.3858 - val_loss: 0.4058 - 28ms/epoch - 3ms/step\n",
      "Epoch 2303/2500\n",
      "11/11 - 0s - loss: 0.3958 - val_loss: 0.4021 - 28ms/epoch - 3ms/step\n",
      "Epoch 2304/2500\n",
      "11/11 - 0s - loss: 0.3824 - val_loss: 0.4052 - 28ms/epoch - 3ms/step\n",
      "Epoch 2305/2500\n",
      "11/11 - 0s - loss: 0.3882 - val_loss: 0.4050 - 32ms/epoch - 3ms/step\n",
      "Epoch 2306/2500\n",
      "11/11 - 0s - loss: 0.3885 - val_loss: 0.4067 - 32ms/epoch - 3ms/step\n",
      "Epoch 2307/2500\n",
      "11/11 - 0s - loss: 0.3888 - val_loss: 0.4092 - 31ms/epoch - 3ms/step\n",
      "Epoch 2308/2500\n",
      "11/11 - 0s - loss: 0.3828 - val_loss: 0.4075 - 32ms/epoch - 3ms/step\n",
      "Epoch 2309/2500\n",
      "11/11 - 0s - loss: 0.3928 - val_loss: 0.4093 - 32ms/epoch - 3ms/step\n",
      "Epoch 2310/2500\n",
      "11/11 - 0s - loss: 0.3917 - val_loss: 0.4101 - 32ms/epoch - 3ms/step\n",
      "Epoch 2311/2500\n",
      "11/11 - 0s - loss: 0.3879 - val_loss: 0.4193 - 32ms/epoch - 3ms/step\n",
      "Epoch 2312/2500\n",
      "11/11 - 0s - loss: 0.3913 - val_loss: 0.4098 - 35ms/epoch - 3ms/step\n",
      "Epoch 2313/2500\n",
      "11/11 - 0s - loss: 0.3843 - val_loss: 0.4101 - 48ms/epoch - 4ms/step\n",
      "Epoch 2314/2500\n",
      "11/11 - 0s - loss: 0.3905 - val_loss: 0.4163 - 33ms/epoch - 3ms/step\n",
      "Epoch 2315/2500\n",
      "11/11 - 0s - loss: 0.3965 - val_loss: 0.4131 - 33ms/epoch - 3ms/step\n",
      "Epoch 2316/2500\n",
      "11/11 - 0s - loss: 0.3910 - val_loss: 0.4233 - 34ms/epoch - 3ms/step\n",
      "Epoch 2317/2500\n",
      "11/11 - 0s - loss: 0.3949 - val_loss: 0.4181 - 36ms/epoch - 3ms/step\n",
      "Epoch 2318/2500\n",
      "11/11 - 0s - loss: 0.3888 - val_loss: 0.4112 - 32ms/epoch - 3ms/step\n",
      "Epoch 2319/2500\n",
      "11/11 - 0s - loss: 0.3965 - val_loss: 0.4128 - 31ms/epoch - 3ms/step\n",
      "Epoch 2320/2500\n",
      "11/11 - 0s - loss: 0.3880 - val_loss: 0.4136 - 32ms/epoch - 3ms/step\n",
      "Epoch 2321/2500\n",
      "11/11 - 0s - loss: 0.3826 - val_loss: 0.4176 - 31ms/epoch - 3ms/step\n",
      "Epoch 2322/2500\n",
      "11/11 - 0s - loss: 0.3794 - val_loss: 0.4150 - 32ms/epoch - 3ms/step\n",
      "Epoch 2323/2500\n",
      "11/11 - 0s - loss: 0.3790 - val_loss: 0.4139 - 31ms/epoch - 3ms/step\n",
      "Epoch 2324/2500\n",
      "11/11 - 0s - loss: 0.3972 - val_loss: 0.4109 - 31ms/epoch - 3ms/step\n",
      "Epoch 2325/2500\n",
      "11/11 - 0s - loss: 0.3842 - val_loss: 0.4115 - 32ms/epoch - 3ms/step\n",
      "Epoch 2326/2500\n",
      "11/11 - 0s - loss: 0.3978 - val_loss: 0.4081 - 33ms/epoch - 3ms/step\n",
      "Epoch 2327/2500\n",
      "11/11 - 0s - loss: 0.3788 - val_loss: 0.4044 - 33ms/epoch - 3ms/step\n",
      "Epoch 2328/2500\n",
      "11/11 - 0s - loss: 0.3829 - val_loss: 0.4084 - 34ms/epoch - 3ms/step\n",
      "Epoch 2329/2500\n",
      "11/11 - 0s - loss: 0.3797 - val_loss: 0.4105 - 47ms/epoch - 4ms/step\n",
      "Epoch 2330/2500\n",
      "11/11 - 0s - loss: 0.3854 - val_loss: 0.4091 - 33ms/epoch - 3ms/step\n",
      "Epoch 2331/2500\n",
      "11/11 - 0s - loss: 0.4069 - val_loss: 0.4058 - 37ms/epoch - 3ms/step\n",
      "Epoch 2332/2500\n",
      "11/11 - 0s - loss: 0.3947 - val_loss: 0.4143 - 33ms/epoch - 3ms/step\n",
      "Epoch 2333/2500\n",
      "11/11 - 0s - loss: 0.3938 - val_loss: 0.4063 - 33ms/epoch - 3ms/step\n",
      "Epoch 2334/2500\n",
      "11/11 - 0s - loss: 0.3900 - val_loss: 0.4086 - 36ms/epoch - 3ms/step\n",
      "Epoch 2335/2500\n",
      "11/11 - 0s - loss: 0.3952 - val_loss: 0.4155 - 32ms/epoch - 3ms/step\n",
      "Epoch 2336/2500\n",
      "11/11 - 0s - loss: 0.3887 - val_loss: 0.4129 - 31ms/epoch - 3ms/step\n",
      "Epoch 2337/2500\n",
      "11/11 - 0s - loss: 0.3960 - val_loss: 0.4061 - 30ms/epoch - 3ms/step\n",
      "Epoch 2338/2500\n",
      "11/11 - 0s - loss: 0.3839 - val_loss: 0.4110 - 30ms/epoch - 3ms/step\n",
      "Epoch 2339/2500\n",
      "11/11 - 0s - loss: 0.3955 - val_loss: 0.4025 - 28ms/epoch - 3ms/step\n",
      "Epoch 2340/2500\n",
      "11/11 - 0s - loss: 0.4088 - val_loss: 0.4052 - 30ms/epoch - 3ms/step\n",
      "Epoch 2341/2500\n",
      "11/11 - 0s - loss: 0.3948 - val_loss: 0.3989 - 30ms/epoch - 3ms/step\n",
      "Epoch 2342/2500\n",
      "11/11 - 0s - loss: 0.3945 - val_loss: 0.3982 - 29ms/epoch - 3ms/step\n",
      "Epoch 2343/2500\n",
      "11/11 - 0s - loss: 0.3822 - val_loss: 0.4036 - 28ms/epoch - 3ms/step\n",
      "Epoch 2344/2500\n",
      "11/11 - 0s - loss: 0.3844 - val_loss: 0.4080 - 35ms/epoch - 3ms/step\n",
      "Epoch 2345/2500\n",
      "11/11 - 0s - loss: 0.3801 - val_loss: 0.4049 - 31ms/epoch - 3ms/step\n",
      "Epoch 2346/2500\n",
      "11/11 - 0s - loss: 0.3774 - val_loss: 0.4020 - 29ms/epoch - 3ms/step\n",
      "Epoch 2347/2500\n",
      "11/11 - 0s - loss: 0.3798 - val_loss: 0.4032 - 30ms/epoch - 3ms/step\n",
      "Epoch 2348/2500\n",
      "11/11 - 0s - loss: 0.3767 - val_loss: 0.4050 - 29ms/epoch - 3ms/step\n",
      "Epoch 2349/2500\n",
      "11/11 - 0s - loss: 0.3970 - val_loss: 0.4028 - 29ms/epoch - 3ms/step\n",
      "Epoch 2350/2500\n",
      "11/11 - 0s - loss: 0.3903 - val_loss: 0.4065 - 28ms/epoch - 3ms/step\n",
      "Epoch 2351/2500\n",
      "11/11 - 0s - loss: 0.3982 - val_loss: 0.4024 - 30ms/epoch - 3ms/step\n",
      "Epoch 2352/2500\n",
      "11/11 - 0s - loss: 0.3903 - val_loss: 0.3986 - 29ms/epoch - 3ms/step\n",
      "Epoch 2353/2500\n",
      "11/11 - 0s - loss: 0.3903 - val_loss: 0.3949 - 28ms/epoch - 3ms/step\n",
      "Epoch 2354/2500\n",
      "11/11 - 0s - loss: 0.3868 - val_loss: 0.3954 - 28ms/epoch - 3ms/step\n",
      "Epoch 2355/2500\n",
      "11/11 - 0s - loss: 0.3941 - val_loss: 0.4028 - 28ms/epoch - 3ms/step\n",
      "Epoch 2356/2500\n",
      "11/11 - 0s - loss: 0.3882 - val_loss: 0.3948 - 27ms/epoch - 2ms/step\n",
      "Epoch 2357/2500\n",
      "11/11 - 0s - loss: 0.3982 - val_loss: 0.3976 - 28ms/epoch - 3ms/step\n",
      "Epoch 2358/2500\n",
      "11/11 - 0s - loss: 0.3913 - val_loss: 0.4086 - 35ms/epoch - 3ms/step\n",
      "Epoch 2359/2500\n",
      "11/11 - 0s - loss: 0.3798 - val_loss: 0.4078 - 31ms/epoch - 3ms/step\n",
      "Epoch 2360/2500\n",
      "11/11 - 0s - loss: 0.3838 - val_loss: 0.4082 - 28ms/epoch - 3ms/step\n",
      "Epoch 2361/2500\n",
      "11/11 - 0s - loss: 0.3728 - val_loss: 0.4068 - 32ms/epoch - 3ms/step\n",
      "Epoch 2362/2500\n",
      "11/11 - 0s - loss: 0.3991 - val_loss: 0.4058 - 35ms/epoch - 3ms/step\n",
      "Epoch 2363/2500\n",
      "11/11 - 0s - loss: 0.3864 - val_loss: 0.4071 - 32ms/epoch - 3ms/step\n",
      "Epoch 2364/2500\n",
      "11/11 - 0s - loss: 0.3934 - val_loss: 0.4196 - 31ms/epoch - 3ms/step\n",
      "Epoch 2365/2500\n",
      "11/11 - 0s - loss: 0.3879 - val_loss: 0.4174 - 32ms/epoch - 3ms/step\n",
      "Epoch 2366/2500\n",
      "11/11 - 0s - loss: 0.3798 - val_loss: 0.4210 - 31ms/epoch - 3ms/step\n",
      "Epoch 2367/2500\n",
      "11/11 - 0s - loss: 0.3867 - val_loss: 0.4208 - 30ms/epoch - 3ms/step\n",
      "Epoch 2368/2500\n",
      "11/11 - 0s - loss: 0.3846 - val_loss: 0.4147 - 29ms/epoch - 3ms/step\n",
      "Epoch 2369/2500\n",
      "11/11 - 0s - loss: 0.3743 - val_loss: 0.4128 - 33ms/epoch - 3ms/step\n",
      "Epoch 2370/2500\n",
      "11/11 - 0s - loss: 0.3814 - val_loss: 0.4156 - 29ms/epoch - 3ms/step\n",
      "Epoch 2371/2500\n",
      "11/11 - 0s - loss: 0.3795 - val_loss: 0.4131 - 29ms/epoch - 3ms/step\n",
      "Epoch 2372/2500\n",
      "11/11 - 0s - loss: 0.3833 - val_loss: 0.4142 - 29ms/epoch - 3ms/step\n",
      "Epoch 2373/2500\n",
      "11/11 - 0s - loss: 0.3834 - val_loss: 0.4213 - 29ms/epoch - 3ms/step\n",
      "Epoch 2374/2500\n",
      "11/11 - 0s - loss: 0.3864 - val_loss: 0.4174 - 29ms/epoch - 3ms/step\n",
      "Epoch 2375/2500\n",
      "11/11 - 0s - loss: 0.3828 - val_loss: 0.4131 - 29ms/epoch - 3ms/step\n",
      "Epoch 2376/2500\n",
      "11/11 - 0s - loss: 0.3850 - val_loss: 0.4138 - 30ms/epoch - 3ms/step\n",
      "Epoch 2377/2500\n",
      "11/11 - 0s - loss: 0.3800 - val_loss: 0.4207 - 29ms/epoch - 3ms/step\n",
      "Epoch 2378/2500\n",
      "11/11 - 0s - loss: 0.3913 - val_loss: 0.4196 - 29ms/epoch - 3ms/step\n",
      "Epoch 2379/2500\n",
      "11/11 - 0s - loss: 0.3935 - val_loss: 0.4120 - 31ms/epoch - 3ms/step\n",
      "Epoch 2380/2500\n",
      "11/11 - 0s - loss: 0.3933 - val_loss: 0.4036 - 28ms/epoch - 3ms/step\n",
      "Epoch 2381/2500\n",
      "11/11 - 0s - loss: 0.3952 - val_loss: 0.4001 - 29ms/epoch - 3ms/step\n",
      "Epoch 2382/2500\n",
      "11/11 - 0s - loss: 0.3757 - val_loss: 0.4009 - 29ms/epoch - 3ms/step\n",
      "Epoch 2383/2500\n",
      "11/11 - 0s - loss: 0.3847 - val_loss: 0.4144 - 29ms/epoch - 3ms/step\n",
      "Epoch 2384/2500\n",
      "11/11 - 0s - loss: 0.3892 - val_loss: 0.4043 - 29ms/epoch - 3ms/step\n",
      "Epoch 2385/2500\n",
      "11/11 - 0s - loss: 0.3851 - val_loss: 0.4149 - 30ms/epoch - 3ms/step\n",
      "Epoch 2386/2500\n",
      "11/11 - 0s - loss: 0.3957 - val_loss: 0.4209 - 34ms/epoch - 3ms/step\n",
      "Epoch 2387/2500\n",
      "11/11 - 0s - loss: 0.3817 - val_loss: 0.4200 - 30ms/epoch - 3ms/step\n",
      "Epoch 2388/2500\n",
      "11/11 - 0s - loss: 0.3853 - val_loss: 0.4191 - 29ms/epoch - 3ms/step\n",
      "Epoch 2389/2500\n",
      "11/11 - 0s - loss: 0.3875 - val_loss: 0.4154 - 36ms/epoch - 3ms/step\n",
      "Epoch 2390/2500\n",
      "11/11 - 0s - loss: 0.4001 - val_loss: 0.4179 - 34ms/epoch - 3ms/step\n",
      "Epoch 2391/2500\n",
      "11/11 - 0s - loss: 0.3835 - val_loss: 0.4170 - 32ms/epoch - 3ms/step\n",
      "Epoch 2392/2500\n",
      "11/11 - 0s - loss: 0.3747 - val_loss: 0.4153 - 33ms/epoch - 3ms/step\n",
      "Epoch 2393/2500\n",
      "11/11 - 0s - loss: 0.3839 - val_loss: 0.4076 - 33ms/epoch - 3ms/step\n",
      "Epoch 2394/2500\n",
      "11/11 - 0s - loss: 0.3947 - val_loss: 0.4090 - 32ms/epoch - 3ms/step\n",
      "Epoch 2395/2500\n",
      "11/11 - 0s - loss: 0.3866 - val_loss: 0.4127 - 33ms/epoch - 3ms/step\n",
      "Epoch 2396/2500\n",
      "11/11 - 0s - loss: 0.3860 - val_loss: 0.4131 - 31ms/epoch - 3ms/step\n",
      "Epoch 2397/2500\n",
      "11/11 - 0s - loss: 0.3814 - val_loss: 0.4146 - 31ms/epoch - 3ms/step\n",
      "Epoch 2398/2500\n",
      "11/11 - 0s - loss: 0.3704 - val_loss: 0.4125 - 30ms/epoch - 3ms/step\n",
      "Epoch 2399/2500\n",
      "11/11 - 0s - loss: 0.3823 - val_loss: 0.4105 - 30ms/epoch - 3ms/step\n",
      "Epoch 2400/2500\n",
      "11/11 - 0s - loss: 0.3854 - val_loss: 0.4120 - 29ms/epoch - 3ms/step\n",
      "Epoch 2401/2500\n",
      "11/11 - 0s - loss: 0.4006 - val_loss: 0.4098 - 29ms/epoch - 3ms/step\n",
      "Epoch 2402/2500\n",
      "11/11 - 0s - loss: 0.3817 - val_loss: 0.4112 - 31ms/epoch - 3ms/step\n",
      "Epoch 2403/2500\n",
      "11/11 - 0s - loss: 0.3792 - val_loss: 0.4091 - 33ms/epoch - 3ms/step\n",
      "Epoch 2404/2500\n",
      "11/11 - 0s - loss: 0.3922 - val_loss: 0.4104 - 42ms/epoch - 4ms/step\n",
      "Epoch 2405/2500\n",
      "11/11 - 0s - loss: 0.3830 - val_loss: 0.4091 - 29ms/epoch - 3ms/step\n",
      "Epoch 2406/2500\n",
      "11/11 - 0s - loss: 0.3827 - val_loss: 0.4032 - 30ms/epoch - 3ms/step\n",
      "Epoch 2407/2500\n",
      "11/11 - 0s - loss: 0.3817 - val_loss: 0.4120 - 29ms/epoch - 3ms/step\n",
      "Epoch 2408/2500\n",
      "11/11 - 0s - loss: 0.3808 - val_loss: 0.4169 - 29ms/epoch - 3ms/step\n",
      "Epoch 2409/2500\n",
      "11/11 - 0s - loss: 0.3855 - val_loss: 0.4057 - 29ms/epoch - 3ms/step\n",
      "Epoch 2410/2500\n",
      "11/11 - 0s - loss: 0.3951 - val_loss: 0.4099 - 29ms/epoch - 3ms/step\n",
      "Epoch 2411/2500\n",
      "11/11 - 0s - loss: 0.3893 - val_loss: 0.4025 - 30ms/epoch - 3ms/step\n",
      "Epoch 2412/2500\n",
      "11/11 - 0s - loss: 0.3848 - val_loss: 0.4042 - 29ms/epoch - 3ms/step\n",
      "Epoch 2413/2500\n",
      "11/11 - 0s - loss: 0.3864 - val_loss: 0.3993 - 29ms/epoch - 3ms/step\n",
      "Epoch 2414/2500\n",
      "11/11 - 0s - loss: 0.3988 - val_loss: 0.4057 - 28ms/epoch - 3ms/step\n",
      "Epoch 2415/2500\n",
      "11/11 - 0s - loss: 0.3894 - val_loss: 0.4062 - 30ms/epoch - 3ms/step\n",
      "Epoch 2416/2500\n",
      "11/11 - 0s - loss: 0.3787 - val_loss: 0.4016 - 29ms/epoch - 3ms/step\n",
      "Epoch 2417/2500\n",
      "11/11 - 0s - loss: 0.3861 - val_loss: 0.4033 - 29ms/epoch - 3ms/step\n",
      "Epoch 2418/2500\n",
      "11/11 - 0s - loss: 0.3882 - val_loss: 0.4073 - 32ms/epoch - 3ms/step\n",
      "Epoch 2419/2500\n",
      "11/11 - 0s - loss: 0.3808 - val_loss: 0.4116 - 30ms/epoch - 3ms/step\n",
      "Epoch 2420/2500\n",
      "11/11 - 0s - loss: 0.3895 - val_loss: 0.4098 - 35ms/epoch - 3ms/step\n",
      "Epoch 2421/2500\n",
      "11/11 - 0s - loss: 0.3904 - val_loss: 0.4137 - 34ms/epoch - 3ms/step\n",
      "Epoch 2422/2500\n",
      "11/11 - 0s - loss: 0.3776 - val_loss: 0.4066 - 32ms/epoch - 3ms/step\n",
      "Epoch 2423/2500\n",
      "11/11 - 0s - loss: 0.3953 - val_loss: 0.4120 - 43ms/epoch - 4ms/step\n",
      "Epoch 2424/2500\n",
      "11/11 - 0s - loss: 0.3823 - val_loss: 0.4046 - 32ms/epoch - 3ms/step\n",
      "Epoch 2425/2500\n",
      "11/11 - 0s - loss: 0.3895 - val_loss: 0.4029 - 29ms/epoch - 3ms/step\n",
      "Epoch 2426/2500\n",
      "11/11 - 0s - loss: 0.3871 - val_loss: 0.4088 - 31ms/epoch - 3ms/step\n",
      "Epoch 2427/2500\n",
      "11/11 - 0s - loss: 0.3745 - val_loss: 0.4058 - 29ms/epoch - 3ms/step\n",
      "Epoch 2428/2500\n",
      "11/11 - 0s - loss: 0.3916 - val_loss: 0.4119 - 29ms/epoch - 3ms/step\n",
      "Epoch 2429/2500\n",
      "11/11 - 0s - loss: 0.3723 - val_loss: 0.4074 - 29ms/epoch - 3ms/step\n",
      "Epoch 2430/2500\n",
      "11/11 - 0s - loss: 0.3879 - val_loss: 0.4001 - 29ms/epoch - 3ms/step\n",
      "Epoch 2431/2500\n",
      "11/11 - 0s - loss: 0.3985 - val_loss: 0.4115 - 29ms/epoch - 3ms/step\n",
      "Epoch 2432/2500\n",
      "11/11 - 0s - loss: 0.3954 - val_loss: 0.4067 - 30ms/epoch - 3ms/step\n",
      "Epoch 2433/2500\n",
      "11/11 - 0s - loss: 0.3806 - val_loss: 0.4030 - 29ms/epoch - 3ms/step\n",
      "Epoch 2434/2500\n",
      "11/11 - 0s - loss: 0.3799 - val_loss: 0.4043 - 29ms/epoch - 3ms/step\n",
      "Epoch 2435/2500\n",
      "11/11 - 0s - loss: 0.3899 - val_loss: 0.4138 - 30ms/epoch - 3ms/step\n",
      "Epoch 2436/2500\n",
      "11/11 - 0s - loss: 0.3849 - val_loss: 0.3998 - 28ms/epoch - 3ms/step\n",
      "Epoch 2437/2500\n",
      "11/11 - 0s - loss: 0.3845 - val_loss: 0.4095 - 33ms/epoch - 3ms/step\n",
      "Epoch 2438/2500\n",
      "11/11 - 0s - loss: 0.3899 - val_loss: 0.4076 - 31ms/epoch - 3ms/step\n",
      "Epoch 2439/2500\n",
      "11/11 - 0s - loss: 0.3941 - val_loss: 0.4077 - 29ms/epoch - 3ms/step\n",
      "Epoch 2440/2500\n",
      "11/11 - 0s - loss: 0.3913 - val_loss: 0.4035 - 29ms/epoch - 3ms/step\n",
      "Epoch 2441/2500\n",
      "11/11 - 0s - loss: 0.3895 - val_loss: 0.4102 - 30ms/epoch - 3ms/step\n",
      "Epoch 2442/2500\n",
      "11/11 - 0s - loss: 0.3717 - val_loss: 0.4010 - 30ms/epoch - 3ms/step\n",
      "Epoch 2443/2500\n",
      "11/11 - 0s - loss: 0.3759 - val_loss: 0.4005 - 29ms/epoch - 3ms/step\n",
      "Epoch 2444/2500\n",
      "11/11 - 0s - loss: 0.3873 - val_loss: 0.4049 - 29ms/epoch - 3ms/step\n",
      "Epoch 2445/2500\n",
      "11/11 - 0s - loss: 0.3818 - val_loss: 0.4050 - 28ms/epoch - 3ms/step\n",
      "Epoch 2446/2500\n",
      "11/11 - 0s - loss: 0.3797 - val_loss: 0.4081 - 30ms/epoch - 3ms/step\n",
      "Epoch 2447/2500\n",
      "11/11 - 0s - loss: 0.3828 - val_loss: 0.4103 - 39ms/epoch - 4ms/step\n",
      "Epoch 2448/2500\n",
      "11/11 - 0s - loss: 0.3880 - val_loss: 0.4009 - 29ms/epoch - 3ms/step\n",
      "Epoch 2449/2500\n",
      "11/11 - 0s - loss: 0.3963 - val_loss: 0.4048 - 28ms/epoch - 3ms/step\n",
      "Epoch 2450/2500\n",
      "11/11 - 0s - loss: 0.3878 - val_loss: 0.4013 - 29ms/epoch - 3ms/step\n",
      "Epoch 2451/2500\n",
      "11/11 - 0s - loss: 0.3852 - val_loss: 0.4069 - 29ms/epoch - 3ms/step\n",
      "Epoch 2452/2500\n",
      "11/11 - 0s - loss: 0.3863 - val_loss: 0.4073 - 30ms/epoch - 3ms/step\n",
      "Epoch 2453/2500\n",
      "11/11 - 0s - loss: 0.3786 - val_loss: 0.4062 - 32ms/epoch - 3ms/step\n",
      "Epoch 2454/2500\n",
      "11/11 - 0s - loss: 0.3832 - val_loss: 0.4097 - 34ms/epoch - 3ms/step\n",
      "Epoch 2455/2500\n",
      "11/11 - 0s - loss: 0.3814 - val_loss: 0.4101 - 32ms/epoch - 3ms/step\n",
      "Epoch 2456/2500\n",
      "11/11 - 0s - loss: 0.3763 - val_loss: 0.4122 - 30ms/epoch - 3ms/step\n",
      "Epoch 2457/2500\n",
      "11/11 - 0s - loss: 0.3838 - val_loss: 0.4148 - 30ms/epoch - 3ms/step\n",
      "Epoch 2458/2500\n",
      "11/11 - 0s - loss: 0.3752 - val_loss: 0.4167 - 30ms/epoch - 3ms/step\n",
      "Epoch 2459/2500\n",
      "11/11 - 0s - loss: 0.3838 - val_loss: 0.4145 - 31ms/epoch - 3ms/step\n",
      "Epoch 2460/2500\n",
      "11/11 - 0s - loss: 0.3883 - val_loss: 0.4090 - 30ms/epoch - 3ms/step\n",
      "Epoch 2461/2500\n",
      "11/11 - 0s - loss: 0.3906 - val_loss: 0.4070 - 29ms/epoch - 3ms/step\n",
      "Epoch 2462/2500\n",
      "11/11 - 0s - loss: 0.3796 - val_loss: 0.4026 - 30ms/epoch - 3ms/step\n",
      "Epoch 2463/2500\n",
      "11/11 - 0s - loss: 0.3824 - val_loss: 0.4039 - 29ms/epoch - 3ms/step\n",
      "Epoch 2464/2500\n",
      "11/11 - 0s - loss: 0.3787 - val_loss: 0.4057 - 30ms/epoch - 3ms/step\n",
      "Epoch 2465/2500\n",
      "11/11 - 0s - loss: 0.4035 - val_loss: 0.4015 - 33ms/epoch - 3ms/step\n",
      "Epoch 2466/2500\n",
      "11/11 - 0s - loss: 0.3785 - val_loss: 0.4055 - 34ms/epoch - 3ms/step\n",
      "Epoch 2467/2500\n",
      "11/11 - 0s - loss: 0.3956 - val_loss: 0.4013 - 30ms/epoch - 3ms/step\n",
      "Epoch 2468/2500\n",
      "11/11 - 0s - loss: 0.3845 - val_loss: 0.4001 - 30ms/epoch - 3ms/step\n",
      "Epoch 2469/2500\n",
      "11/11 - 0s - loss: 0.3716 - val_loss: 0.3979 - 29ms/epoch - 3ms/step\n",
      "Epoch 2470/2500\n",
      "11/11 - 0s - loss: 0.3792 - val_loss: 0.4082 - 30ms/epoch - 3ms/step\n",
      "Epoch 2471/2500\n",
      "11/11 - 0s - loss: 0.3970 - val_loss: 0.4104 - 33ms/epoch - 3ms/step\n",
      "Epoch 2472/2500\n",
      "11/11 - 0s - loss: 0.3804 - val_loss: 0.4111 - 32ms/epoch - 3ms/step\n",
      "Epoch 2473/2500\n",
      "11/11 - 0s - loss: 0.3856 - val_loss: 0.4039 - 30ms/epoch - 3ms/step\n",
      "Epoch 2474/2500\n",
      "11/11 - 0s - loss: 0.3893 - val_loss: 0.4027 - 31ms/epoch - 3ms/step\n",
      "Epoch 2475/2500\n",
      "11/11 - 0s - loss: 0.3930 - val_loss: 0.4031 - 34ms/epoch - 3ms/step\n",
      "Epoch 2476/2500\n",
      "11/11 - 0s - loss: 0.3881 - val_loss: 0.4037 - 29ms/epoch - 3ms/step\n",
      "Epoch 2477/2500\n",
      "11/11 - 0s - loss: 0.3816 - val_loss: 0.3973 - 30ms/epoch - 3ms/step\n",
      "Epoch 2478/2500\n",
      "11/11 - 0s - loss: 0.3800 - val_loss: 0.3973 - 29ms/epoch - 3ms/step\n",
      "Epoch 2479/2500\n",
      "11/11 - 0s - loss: 0.3822 - val_loss: 0.4010 - 29ms/epoch - 3ms/step\n",
      "Epoch 2480/2500\n",
      "11/11 - 0s - loss: 0.3899 - val_loss: 0.3954 - 29ms/epoch - 3ms/step\n",
      "Epoch 2481/2500\n",
      "11/11 - 0s - loss: 0.3853 - val_loss: 0.3979 - 30ms/epoch - 3ms/step\n",
      "Epoch 2482/2500\n",
      "11/11 - 0s - loss: 0.3775 - val_loss: 0.3991 - 30ms/epoch - 3ms/step\n",
      "Epoch 2483/2500\n",
      "11/11 - 0s - loss: 0.3724 - val_loss: 0.4054 - 30ms/epoch - 3ms/step\n",
      "Epoch 2484/2500\n",
      "11/11 - 0s - loss: 0.3890 - val_loss: 0.3970 - 29ms/epoch - 3ms/step\n",
      "Epoch 2485/2500\n",
      "11/11 - 0s - loss: 0.3942 - val_loss: 0.4157 - 30ms/epoch - 3ms/step\n",
      "Epoch 2486/2500\n",
      "11/11 - 0s - loss: 0.3768 - val_loss: 0.3986 - 29ms/epoch - 3ms/step\n",
      "Epoch 2487/2500\n",
      "11/11 - 0s - loss: 0.3977 - val_loss: 0.3974 - 29ms/epoch - 3ms/step\n",
      "Epoch 2488/2500\n",
      "11/11 - 0s - loss: 0.3845 - val_loss: 0.4029 - 29ms/epoch - 3ms/step\n",
      "Epoch 2489/2500\n",
      "11/11 - 0s - loss: 0.3848 - val_loss: 0.4021 - 49ms/epoch - 4ms/step\n",
      "Epoch 2490/2500\n",
      "11/11 - 0s - loss: 0.3852 - val_loss: 0.4017 - 29ms/epoch - 3ms/step\n",
      "Epoch 2491/2500\n",
      "11/11 - 0s - loss: 0.3922 - val_loss: 0.4022 - 30ms/epoch - 3ms/step\n",
      "Epoch 2492/2500\n",
      "11/11 - 0s - loss: 0.3910 - val_loss: 0.4004 - 30ms/epoch - 3ms/step\n",
      "Epoch 2493/2500\n",
      "11/11 - 0s - loss: 0.3883 - val_loss: 0.3990 - 29ms/epoch - 3ms/step\n",
      "Epoch 2494/2500\n",
      "11/11 - 0s - loss: 0.3860 - val_loss: 0.3958 - 29ms/epoch - 3ms/step\n",
      "Epoch 2495/2500\n",
      "11/11 - 0s - loss: 0.3928 - val_loss: 0.3984 - 29ms/epoch - 3ms/step\n",
      "Epoch 2496/2500\n",
      "11/11 - 0s - loss: 0.4046 - val_loss: 0.3995 - 29ms/epoch - 3ms/step\n",
      "Epoch 2497/2500\n",
      "11/11 - 0s - loss: 0.3663 - val_loss: 0.3991 - 30ms/epoch - 3ms/step\n",
      "Epoch 2498/2500\n",
      "11/11 - 0s - loss: 0.3763 - val_loss: 0.4014 - 29ms/epoch - 3ms/step\n",
      "Epoch 2499/2500\n",
      "11/11 - 0s - loss: 0.3865 - val_loss: 0.3960 - 29ms/epoch - 3ms/step\n",
      "Epoch 2500/2500\n",
      "11/11 - 0s - loss: 0.3839 - val_loss: 0.3959 - 30ms/epoch - 3ms/step\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=2500, validation_data=(X_test, y_test), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Learning Curves')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n",
      "MAE: 0.3959464055458001\n",
      "MSE: 0.36476997993659477\n",
      "RMSE: 0.6039619027195298\n",
      "MAPE: 0.1634207410162327\n",
      "R2: 0.7172075289252993\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "\n",
    "# MAE, MSE, RMSE\n",
    "print(\"MAE: {}\".format(mean_absolute_error(y_test, predictions)))\n",
    "print(\"MSE: {}\".format(mean_squared_error(y_test, predictions)))\n",
    "print(\"RMSE: {}\".format(mean_squared_error(y_test, predictions, squared=False)))\n",
    "print(\"MAPE: {}\".format(mean_absolute_percentage_error(y_test, predictions)))\n",
    "print(\"R2: {}\".format(r2_score(y_test, predictions)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "328543c14e67749527378fd9d598798d406739103cb7dff262233cddae2d7f33"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
